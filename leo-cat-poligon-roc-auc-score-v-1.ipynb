{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom phik.report import plot_correlation_matrix\nfrom catboost import CatBoostClassifier, Pool\nfrom sklearn.model_selection import train_test_split, StratifiedKFold\nfrom sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, \\\n    classification_report\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.metrics import f1_score\nimport optuna\nfrom sklearn.metrics import roc_auc_score, average_precision_score\nfrom optuna.pruners import MedianPruner\nfrom sklearn.metrics import f1_score\nfrom tqdm import tqdm\n# pd.set_option('display.max_rows', None)\n# pd.set_option('display.max_columns', None)","metadata":{"execution":{"iopub.status.busy":"2023-10-31T11:08:12.107507Z","iopub.execute_input":"2023-10-31T11:08:12.107936Z","iopub.status.idle":"2023-10-31T11:08:12.115115Z","shell.execute_reply.started":"2023-10-31T11:08:12.107905Z","shell.execute_reply":"2023-10-31T11:08:12.114307Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"df_raw = pd.read_csv('/kaggle/input/leopard-challenge-classification/train.csv')\ntest = pd.read_csv(r'/kaggle/input/leopard-challenge-classification/test.csv')\ndf_raw.shape, test.shape","metadata":{"execution":{"iopub.status.busy":"2023-10-31T16:58:08.024649Z","iopub.execute_input":"2023-10-31T16:58:08.025058Z","iopub.status.idle":"2023-10-31T16:58:08.127774Z","shell.execute_reply.started":"2023-10-31T16:58:08.025029Z","shell.execute_reply":"2023-10-31T16:58:08.126630Z"},"trusted":true},"execution_count":240,"outputs":[{"execution_count":240,"output_type":"execute_result","data":{"text/plain":"((13863, 26), (5942, 25))"},"metadata":{}}]},{"cell_type":"code","source":"test_cv = test.drop(['oral', 'ID'], axis = 1).copy()\ntest_cv['tartar'] = test_cv['tartar'].apply(lambda x: 1 if x == 'Y' else 0)\nmerged_data = df_raw.drop(['oral', 'ID'], axis=1).copy()\nmerged_data['tartar'] = merged_data['tartar'].apply(lambda x: 1 if x == 'Y' else 0)\nmerged_data.shape, test_cv.shape","metadata":{"execution":{"iopub.status.busy":"2023-10-31T16:58:08.284501Z","iopub.execute_input":"2023-10-31T16:58:08.285536Z","iopub.status.idle":"2023-10-31T16:58:08.321236Z","shell.execute_reply.started":"2023-10-31T16:58:08.285492Z","shell.execute_reply":"2023-10-31T16:58:08.320407Z"},"trusted":true},"execution_count":241,"outputs":[{"execution_count":241,"output_type":"execute_result","data":{"text/plain":"((13863, 24), (5942, 23))"},"metadata":{}}]},{"cell_type":"code","source":"merged_data['BMI'] = merged_data['weight(kg)'] / ((merged_data['height(cm)'] / 100) ** 2)\nmerged_data['Chol_HDL_ratio'] = merged_data['Cholesterol'] / merged_data['HDL']\nmerged_data['ldl_hdl'] = merged_data['LDL'] / merged_data['HDL']\nmerged_data['map'] = (merged_data['systolic'] + (2 * merged_data['relaxation'])) / 3\nmerged_data['Waist_Height_ratio'] = merged_data['waist(cm)'] / merged_data['height(cm)']\nmerged_data['height_nin_110'] = (merged_data['height(cm)'] - 110) / merged_data['weight(kg)']\nmerged_data['Average_hearing'] = (merged_data['hearing(left)'] + merged_data['hearing(right)']) / 2\nmerged_data['Average_eyesight'] = (merged_data['eyesight(left)'] + merged_data['eyesight(right)']) / 2\nmerged_data['ast_alt'] = merged_data['AST'] / merged_data['ALT']\nmerged_data['Systolic_Diastolic_ratio'] = merged_data['systolic'] / merged_data['relaxation']\nmerged_data['Atherogenic_coefficient'] = (merged_data['Cholesterol'] - merged_data['HDL']) / merged_data['HDL']\nmerged_data['BMI_to_age'] = merged_data['BMI'] / merged_data['age']\nmerged_data['Glucose_to_Cholesterol'] = merged_data['fasting blood sugar'] / merged_data['Cholesterol']\nmerged_data['Triglycerides_to_HDL'] = merged_data['triglyceride'] / merged_data['HDL']\nmerged_data['Systolic_to_age'] = merged_data['systolic'] / merged_data['age']\nmerged_data['Diastolic_to_age'] = merged_data['relaxation'] / merged_data['age']\nmerged_data['Hemoglobin_to_age'] = merged_data['hemoglobin'] / merged_data['age']\nmerged_data['GTP_to_age'] = merged_data['Gtp'] / merged_data['age']\nmerged_data['GTP_to_AST_ALT'] = merged_data['Gtp'] / (merged_data['AST'] + merged_data['ALT'])\nmerged_data['GTP_to_Cholesterol'] = merged_data['Gtp'] / merged_data['Cholesterol']\nmerged_data['GTP_index'] = merged_data['Gtp'] / (merged_data['Cholesterol'] + merged_data['triglyceride'])\n\nmerged_data['age_normal'] = (merged_data['age'] < 62.5).astype(int)\nmerged_data['weight(kg)_normal'] = (merged_data['weight(kg)'] < 52.5).astype(int)\nmerged_data['waist(cm)_normal'] = (merged_data['waist(cm)'] < 94.05).astype(int)\nmerged_data['eyesight(left)_normal'] = (merged_data['eyesight(left)'] < 0.35).astype(int)\nmerged_data['eyesight(right)_normal'] = (merged_data['eyesight(right)'] < 1.55).astype(int)\nmerged_data['systolic_normal'] = (merged_data['systolic'] < 140.5).astype(int)\nmerged_data['relaxation_normal'] = (merged_data['relaxation'] < 69.5).astype(int)\nmerged_data['fasting_blood_sugar_normal'] = (merged_data['fasting blood sugar'] < 238.5).astype(int)\nmerged_data['Cholesterol_normal'] = (merged_data['Cholesterol'] < 316.5).astype(int)\nmerged_data['triglyceride_normal'] = (merged_data['triglyceride'] < 114.5).astype(int)\nmerged_data['HDL_normal'] = (merged_data['HDL'] < 50.5).astype(int)\nmerged_data['LDL_normal'] = (merged_data['LDL'] < 88.5).astype(int)\nmerged_data['hemoglobin_normal'] = (merged_data['hemoglobin'] < 16.45).astype(int)\nmerged_data['Urine_protein_normal'] = (merged_data['Urine protein'] < 1.5).astype(int)\nmerged_data['serum_creatinine_normal'] = (merged_data['serum creatinine'] < 0.75).astype(int)\nmerged_data['AST_normal'] = (merged_data['AST'] < 45.5).astype(int)\nmerged_data['ALT_normal'] = (merged_data['ALT'] < 29.5).astype(int)\nmerged_data['Gtp_normal'] = (merged_data['Gtp'] < 43.5).astype(int)\nmerged_data['BMI_normal'] = (merged_data['BMI'] < 19.8).astype(int)\nmerged_data['Chol_HDL_ratio_normal'] = (merged_data['Chol_HDL_ratio'] < 4.46).astype(int)\nmerged_data['ldl_hdl_normal'] = (merged_data['ldl_hdl'] < 0.71).astype(int)\nmerged_data['map_normal'] = (merged_data['map'] < 134.3).astype(int)\nmerged_data['Waist_Height_ratio_normal'] = (merged_data['Waist_Height_ratio'] < 0.41).astype(int)\nmerged_data['height_nin_110_normal'] = (merged_data['height_nin_110'] < 1.08).astype(int)\nmerged_data['Average_hearing_normal'] = (merged_data['Average_hearing'] < 1.25).astype(int)\nmerged_data['Average_eyesight_normal'] = (merged_data['Average_eyesight'] < 0.325).astype(int)\nmerged_data['ast_alt_normal'] = (merged_data['ast_alt'] < 2.81).astype(int)\nmerged_data['Systolic_Diastolic_ratio_normal'] = (merged_data['Systolic_Diastolic_ratio'] < 1.67).astype(int) \nmerged_data['Atherogenic_coefficient_normal'] = (merged_data['Atherogenic_coefficient'] < 3.456).astype(int)\nmerged_data['BMI_to_age_normal'] = (merged_data['BMI_to_age'] < 0.797).astype(int)\nmerged_data['Glucose_to_Cholesterol_normal'] = (merged_data['Glucose_to_Cholesterol'] < 0.64897).astype(int)\nmerged_data['Triglycerides_to_HDL_normal'] = (merged_data['Triglycerides_to_HDL'] < 2.85857).astype(int)\nmerged_data['Systolic_to_age_normal'] = (merged_data['Systolic_to_age'] < 1.986).astype(int)\nmerged_data['Diastolic_to_age_normal'] = (merged_data['Diastolic_to_age'] < 1.1679).astype(int)\nmerged_data['Hemoglobin_to_age_normal'] = (merged_data['Hemoglobin_to_age'] < 0.253).astype(int)\nmerged_data['GTP_to_age_normal'] = (merged_data['GTP_to_age'] < 1.15).astype(int)\nmerged_data['GTP_to_AST_ALT_normal'] = (merged_data['GTP_to_AST_ALT'] < 0.76).astype(int)\nmerged_data['GTP_to_Cholesterol_normal'] = (merged_data['GTP_to_Cholesterol'] < 0.19).astype(int)\nmerged_data['GTP_index_normal'] = (merged_data['GTP_index'] < 0.123).astype(int)\n\nmerged_data.shape","metadata":{"execution":{"iopub.status.busy":"2023-10-31T17:58:10.358732Z","iopub.execute_input":"2023-10-31T17:58:10.359098Z","iopub.status.idle":"2023-10-31T17:58:10.449086Z","shell.execute_reply.started":"2023-10-31T17:58:10.359070Z","shell.execute_reply":"2023-10-31T17:58:10.448244Z"},"trusted":true},"execution_count":263,"outputs":[{"execution_count":263,"output_type":"execute_result","data":{"text/plain":"(13863, 84)"},"metadata":{}}]},{"cell_type":"code","source":"test_cv['BMI'] = test_cv['weight(kg)'] / ((test_cv['height(cm)'] / 100) ** 2)\ntest_cv['Chol_HDL_ratio'] = test_cv['Cholesterol'] / test_cv['HDL']\ntest_cv['ldl_hdl'] = test_cv['LDL'] / test_cv['HDL']\ntest_cv['map'] = (test_cv['systolic'] + (2 * test_cv['relaxation'])) / 3\ntest_cv['Waist_Height_ratio'] = test_cv['waist(cm)'] / test_cv['height(cm)']\ntest_cv['height_nin_110'] = (test_cv['height(cm)'] - 110) / test_cv['weight(kg)']\ntest_cv['Average_hearing'] = (test_cv['hearing(left)'] + test_cv['hearing(right)']) / 2\ntest_cv['Average_eyesight'] = (test_cv['eyesight(left)'] + test_cv['eyesight(right)']) / 2\ntest_cv['ast_alt'] = test_cv['AST'] / test_cv['ALT']\ntest_cv['Systolic_Diastolic_ratio'] = test_cv['systolic'] / test_cv['relaxation']\ntest_cv['Atherogenic_coefficient'] = (test_cv['Cholesterol'] - test_cv['HDL']) / test_cv['HDL']\ntest_cv['BMI_to_age'] = test_cv['BMI'] / test_cv['age']\ntest_cv['Glucose_to_Cholesterol'] = test_cv['fasting blood sugar'] / test_cv['Cholesterol']\ntest_cv['Triglycerides_to_HDL'] = test_cv['triglyceride'] / test_cv['HDL']\ntest_cv['Systolic_to_age'] = test_cv['systolic'] / test_cv['age']\ntest_cv['Diastolic_to_age'] = test_cv['relaxation'] / test_cv['age']\ntest_cv['Hemoglobin_to_age'] = test_cv['hemoglobin'] / test_cv['age']\ntest_cv['GTP_to_age'] = test_cv['Gtp'] / test_cv['age']\ntest_cv['GTP_to_AST_ALT'] = test_cv['Gtp'] / (test_cv['AST'] + test_cv['ALT'])\ntest_cv['GTP_to_Cholesterol'] = test_cv['Gtp'] / test_cv['Cholesterol']\ntest_cv['GTP_index'] = test_cv['Gtp'] / (test_cv['Cholesterol'] + test_cv['triglyceride'])\n\ntest_cv['age_normal'] = (test_cv['age'] < 62.5).astype(int)\ntest_cv['weight(kg)_normal'] = (test_cv['weight(kg)'] < 52.5).astype(int)\ntest_cv['waist(cm)_normal'] = (test_cv['waist(cm)'] < 94.05).astype(int)\ntest_cv['eyesight(left)_normal'] = (test_cv['eyesight(left)'] < 0.35).astype(int)\ntest_cv['eyesight(right)_normal'] = (test_cv['eyesight(right)'] < 1.55).astype(int)\ntest_cv['systolic_normal'] = (test_cv['systolic'] < 140.5).astype(int)\ntest_cv['relaxation_normal'] = (test_cv['relaxation'] < 69.5).astype(int)\ntest_cv['fasting_blood_sugar_normal'] = (test_cv['fasting blood sugar'] < 238.5).astype(int)\ntest_cv['Cholesterol_normal'] = (test_cv['Cholesterol'] < 316.5).astype(int)\ntest_cv['triglyceride_normal'] = (test_cv['triglyceride'] < 114.5).astype(int)\ntest_cv['HDL_normal'] = (test_cv['HDL'] < 50.5).astype(int)\ntest_cv['LDL_normal'] = (test_cv['LDL'] < 88.5).astype(int)\ntest_cv['hemoglobin_normal'] = (test_cv['hemoglobin'] < 16.45).astype(int)\ntest_cv['Urine_protein_normal'] = (test_cv['Urine protein'] < 1.5).astype(int)\ntest_cv['serum_creatinine_normal'] = (test_cv['serum creatinine'] < 0.75).astype(int)\ntest_cv['AST_normal'] = (test_cv['AST'] < 45.5).astype(int)\ntest_cv['ALT_normal'] = (test_cv['ALT'] < 29.5).astype(int)\ntest_cv['Gtp_normal'] = (test_cv['Gtp'] < 43.5).astype(int)\ntest_cv['BMI_normal'] = (test_cv['BMI'] < 19.8).astype(int)\ntest_cv['Chol_HDL_ratio_normal'] = (test_cv['Chol_HDL_ratio'] < 4.46).astype(int)\ntest_cv['ldl_hdl_normal'] = (test_cv['ldl_hdl'] < 0.71).astype(int)\ntest_cv['map_normal'] = (test_cv['map'] < 134.3).astype(int)\ntest_cv['Waist_Height_ratio_normal'] = (test_cv['Waist_Height_ratio'] < 0.41).astype(int)\ntest_cv['height_nin_110_normal'] = (test_cv['height_nin_110'] < 1.08).astype(int)\ntest_cv['Average_hearing_normal'] = (test_cv['Average_hearing'] < 1.25).astype(int)\ntest_cv['Average_eyesight_normal'] = (test_cv['Average_eyesight'] < 0.325).astype(int)\ntest_cv['ast_alt_normal'] = (test_cv['ast_alt'] < 2.81).astype(int)\ntest_cv['Systolic_Diastolic_ratio_normal'] = (test_cv['Systolic_Diastolic_ratio'] < 1.67).astype(int) \ntest_cv['Atherogenic_coefficient_normal'] = (test_cv['Atherogenic_coefficient'] < 3.456).astype(int)\ntest_cv['BMI_to_age_normal'] = (test_cv['BMI_to_age'] < 0.797).astype(int)\ntest_cv['Glucose_to_Cholesterol_normal'] = (test_cv['Glucose_to_Cholesterol'] < 0.64897).astype(int)\ntest_cv['Triglycerides_to_HDL_normal'] = (test_cv['Triglycerides_to_HDL'] < 2.85857).astype(int)\ntest_cv['Systolic_to_age_normal'] = (test_cv['Systolic_to_age'] < 1.986).astype(int)\ntest_cv['Diastolic_to_age_normal'] = (test_cv['Diastolic_to_age'] < 1.1679).astype(int)\ntest_cv['Hemoglobin_to_age_normal'] = (test_cv['Hemoglobin_to_age'] < 0.253).astype(int)\ntest_cv['GTP_to_age_normal'] = (test_cv['GTP_to_age'] < 1.15).astype(int)\ntest_cv['GTP_to_AST_ALT_normal'] = (test_cv['GTP_to_AST_ALT'] < 0.76).astype(int)\ntest_cv['GTP_to_Cholesterol_normal'] = (test_cv['GTP_to_Cholesterol'] < 0.19).astype(int)\ntest_cv['GTP_index_normal'] = (test_cv['GTP_index'] < 0.123).astype(int)\n\ntest_cv.shape","metadata":{"execution":{"iopub.status.busy":"2023-10-31T17:58:00.399005Z","iopub.execute_input":"2023-10-31T17:58:00.399428Z","iopub.status.idle":"2023-10-31T17:58:00.476718Z","shell.execute_reply.started":"2023-10-31T17:58:00.399393Z","shell.execute_reply":"2023-10-31T17:58:00.475572Z"},"trusted":true},"execution_count":262,"outputs":[{"execution_count":262,"output_type":"execute_result","data":{"text/plain":"(5942, 83)"},"metadata":{}}]},{"cell_type":"code","source":"from sklearn.metrics import roc_auc_score\nfrom sklearn.model_selection import train_test_split\n\ndef evaluate_features_auc(data, target, features):\n    \"\"\"\n    Оценивает разделяющую способность каждого признака с помощью ROC-AUC.\n    \n    :param data: DataFrame, содержащий признаки и целевую переменную.\n    :param target: Имя столбца, содержащего целевую переменную.\n    :param features: Список имен признаков для оценки.\n    \n    :return: Словарь, где ключи — названия признаков, а значения — ROC-AUC для каждого признака.\n    \"\"\"\n    auc_scores = {}\n    for feature in tqdm(features):\n        # Разделение данных на обучающую и тестовую выборку\n        X_train, X_test, y_train, y_test = train_test_split(data[[feature]], data[target], test_size=0.2, stratify=data[target], random_state=42)\n        X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42, stratify=y_train)\n        \n        # Обучение модели\n        model = CatBoostClassifier(verbose=0, auto_class_weights='Balanced', random_state=42)\n        model.fit(X_train, y_train, eval_set=[(X_val, y_val)], early_stopping_rounds=50)\n        \n        # Прогнозирование и вычисление ROC-AUC\n        y_pred_proba = model.predict_proba(X_test)[:, 1]\n        auc = roc_auc_score(y_test, y_pred_proba)\n        auc_scores[feature] = auc\n        \n    auc_scores_df = pd.DataFrame(list(auc_scores.items()), columns=['Feature', 'auc_scores'])\n    \n    return auc_scores_df\n","metadata":{"execution":{"iopub.status.busy":"2023-10-31T17:02:00.938228Z","iopub.execute_input":"2023-10-31T17:02:00.938656Z","iopub.status.idle":"2023-10-31T17:02:00.950738Z","shell.execute_reply.started":"2023-10-31T17:02:00.938626Z","shell.execute_reply":"2023-10-31T17:02:00.949555Z"},"trusted":true},"execution_count":243,"outputs":[]},{"cell_type":"code","source":"best_infinity_features = [ 'GTP_index', 'GTP_to_Cholesterol', 'GTP_to_AST_ALT', 'GTP_to_age', 'Triglycerides_to_HDL', 'Gtp', 'triglyceride', 'tartar' ]\ninfinity_features = merged_data.nunique()[merged_data.nunique() >= 3].index.to_list()\ninfinity_features, len(infinity_features), len(merged_data.columns.to_list())","metadata":{"execution":{"iopub.status.busy":"2023-10-31T17:02:01.220970Z","iopub.execute_input":"2023-10-31T17:02:01.221539Z","iopub.status.idle":"2023-10-31T17:02:01.280295Z","shell.execute_reply.started":"2023-10-31T17:02:01.221504Z","shell.execute_reply":"2023-10-31T17:02:01.279399Z"},"trusted":true},"execution_count":244,"outputs":[{"execution_count":244,"output_type":"execute_result","data":{"text/plain":"(['age',\n  'height(cm)',\n  'weight(kg)',\n  'waist(cm)',\n  'eyesight(left)',\n  'eyesight(right)',\n  'systolic',\n  'relaxation',\n  'fasting blood sugar',\n  'Cholesterol',\n  'triglyceride',\n  'HDL',\n  'LDL',\n  'hemoglobin',\n  'Urine protein',\n  'serum creatinine',\n  'AST',\n  'ALT',\n  'Gtp',\n  'BMI',\n  'Chol_HDL_ratio',\n  'ldl_hdl',\n  'map',\n  'Waist_Height_ratio',\n  'height_nin_110',\n  'Average_hearing',\n  'Average_eyesight',\n  'ast_alt',\n  'Systolic_Diastolic_ratio',\n  'Atherogenic_coefficient',\n  'BMI_to_age',\n  'Glucose_to_Cholesterol',\n  'Triglycerides_to_HDL',\n  'Systolic_to_age',\n  'Diastolic_to_age',\n  'Hemoglobin_to_age',\n  'GTP_to_age',\n  'GTP_to_AST_ALT',\n  'GTP_to_Cholesterol',\n  'GTP_index'],\n 40,\n 84)"},"metadata":{}}]},{"cell_type":"code","source":"evaluate_features_auc_df = evaluate_features_auc(merged_data, 'smoking', merged_data.columns.to_list())","metadata":{"execution":{"iopub.status.busy":"2023-10-31T17:02:04.414189Z","iopub.execute_input":"2023-10-31T17:02:04.415446Z","iopub.status.idle":"2023-10-31T17:02:32.061184Z","shell.execute_reply.started":"2023-10-31T17:02:04.415403Z","shell.execute_reply":"2023-10-31T17:02:32.060311Z"},"trusted":true},"execution_count":245,"outputs":[{"name":"stderr","text":"100%|██████████| 84/84 [00:27<00:00,  3.04it/s]\n","output_type":"stream"}]},{"cell_type":"code","source":"evaluate_features_auc_df.sort_values(by='auc_scores', ascending=False) .iloc[:30,:]#['Feature'].to_list()","metadata":{"execution":{"iopub.status.busy":"2023-10-31T17:04:16.218903Z","iopub.execute_input":"2023-10-31T17:04:16.219279Z","iopub.status.idle":"2023-10-31T17:04:16.235727Z","shell.execute_reply.started":"2023-10-31T17:04:16.219250Z","shell.execute_reply":"2023-10-31T17:04:16.234382Z"},"trusted":true},"execution_count":248,"outputs":[{"execution_count":248,"output_type":"execute_result","data":{"text/plain":"                        Feature  auc_scores\n23                      smoking    1.000000\n42               GTP_to_AST_ALT    0.647903\n43           GTP_to_Cholesterol    0.641975\n20                          Gtp    0.638047\n41                   GTP_to_age    0.628335\n44                    GTP_index    0.620890\n12                 triglyceride    0.610875\n82    GTP_to_Cholesterol_normal    0.610485\n37         Triglycerides_to_HDL    0.608918\n0                           age    0.605216\n62                   Gtp_normal    0.604984\n81        GTP_to_AST_ALT_normal    0.604518\n40            Hemoglobin_to_age    0.601915\n83             GTP_index_normal    0.593082\n80            GTP_to_age_normal    0.592633\n76  Triglycerides_to_HDL_normal    0.590703\n54          triglyceride_normal    0.584850\n38              Systolic_to_age    0.575384\n39             Diastolic_to_age    0.565638\n35                   BMI_to_age    0.564959\n15                   hemoglobin    0.558824\n24                          BMI    0.554812\n10          fasting blood sugar    0.553872\n14                          LDL    0.552898\n13                          HDL    0.552207\n1                    height(cm)    0.544958\n22                       tartar    0.543506\n29               height_nin_110    0.542828\n55                   HDL_normal    0.541190\n57            hemoglobin_normal    0.538684","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Feature</th>\n      <th>auc_scores</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>23</th>\n      <td>smoking</td>\n      <td>1.000000</td>\n    </tr>\n    <tr>\n      <th>42</th>\n      <td>GTP_to_AST_ALT</td>\n      <td>0.647903</td>\n    </tr>\n    <tr>\n      <th>43</th>\n      <td>GTP_to_Cholesterol</td>\n      <td>0.641975</td>\n    </tr>\n    <tr>\n      <th>20</th>\n      <td>Gtp</td>\n      <td>0.638047</td>\n    </tr>\n    <tr>\n      <th>41</th>\n      <td>GTP_to_age</td>\n      <td>0.628335</td>\n    </tr>\n    <tr>\n      <th>44</th>\n      <td>GTP_index</td>\n      <td>0.620890</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>triglyceride</td>\n      <td>0.610875</td>\n    </tr>\n    <tr>\n      <th>82</th>\n      <td>GTP_to_Cholesterol_normal</td>\n      <td>0.610485</td>\n    </tr>\n    <tr>\n      <th>37</th>\n      <td>Triglycerides_to_HDL</td>\n      <td>0.608918</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>age</td>\n      <td>0.605216</td>\n    </tr>\n    <tr>\n      <th>62</th>\n      <td>Gtp_normal</td>\n      <td>0.604984</td>\n    </tr>\n    <tr>\n      <th>81</th>\n      <td>GTP_to_AST_ALT_normal</td>\n      <td>0.604518</td>\n    </tr>\n    <tr>\n      <th>40</th>\n      <td>Hemoglobin_to_age</td>\n      <td>0.601915</td>\n    </tr>\n    <tr>\n      <th>83</th>\n      <td>GTP_index_normal</td>\n      <td>0.593082</td>\n    </tr>\n    <tr>\n      <th>80</th>\n      <td>GTP_to_age_normal</td>\n      <td>0.592633</td>\n    </tr>\n    <tr>\n      <th>76</th>\n      <td>Triglycerides_to_HDL_normal</td>\n      <td>0.590703</td>\n    </tr>\n    <tr>\n      <th>54</th>\n      <td>triglyceride_normal</td>\n      <td>0.584850</td>\n    </tr>\n    <tr>\n      <th>38</th>\n      <td>Systolic_to_age</td>\n      <td>0.575384</td>\n    </tr>\n    <tr>\n      <th>39</th>\n      <td>Diastolic_to_age</td>\n      <td>0.565638</td>\n    </tr>\n    <tr>\n      <th>35</th>\n      <td>BMI_to_age</td>\n      <td>0.564959</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>hemoglobin</td>\n      <td>0.558824</td>\n    </tr>\n    <tr>\n      <th>24</th>\n      <td>BMI</td>\n      <td>0.554812</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>fasting blood sugar</td>\n      <td>0.553872</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>LDL</td>\n      <td>0.552898</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>HDL</td>\n      <td>0.552207</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>height(cm)</td>\n      <td>0.544958</td>\n    </tr>\n    <tr>\n      <th>22</th>\n      <td>tartar</td>\n      <td>0.543506</td>\n    </tr>\n    <tr>\n      <th>29</th>\n      <td>height_nin_110</td>\n      <td>0.542828</td>\n    </tr>\n    <tr>\n      <th>55</th>\n      <td>HDL_normal</td>\n      <td>0.541190</td>\n    </tr>\n    <tr>\n      <th>57</th>\n      <td>hemoglobin_normal</td>\n      <td>0.538684</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"from sklearn.preprocessing import PolynomialFeatures\n\n\ncontinuous_data = merged_data[infinity_features]\n# Создание полиномиальных признаков (степень 2)\npoly = PolynomialFeatures(degree=2, include_bias=False)\npoly_data = poly.fit_transform(continuous_data)\npoly_features = poly.get_feature_names_out(infinity_features)\n\n# Создание DataFrame с полиномиальными признаками\npoly_df = pd.DataFrame(poly_data, columns=poly_features)\n\n# Проверка размерности нового DataFrame\npoly_df.shape","metadata":{"execution":{"iopub.status.busy":"2023-10-31T11:10:18.937134Z","iopub.execute_input":"2023-10-31T11:10:18.937525Z","iopub.status.idle":"2023-10-31T11:10:19.075407Z","shell.execute_reply.started":"2023-10-31T11:10:18.937495Z","shell.execute_reply":"2023-10-31T11:10:19.074184Z"},"trusted":true},"execution_count":11,"outputs":[{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"(13863, 860)"},"metadata":{}}]},{"cell_type":"code","source":"poly_df['smoking'] = merged_data['smoking'].copy()","metadata":{"execution":{"iopub.status.busy":"2023-10-31T11:10:28.010007Z","iopub.execute_input":"2023-10-31T11:10:28.010452Z","iopub.status.idle":"2023-10-31T11:10:28.017041Z","shell.execute_reply.started":"2023-10-31T11:10:28.010417Z","shell.execute_reply":"2023-10-31T11:10:28.015857Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"poly_df","metadata":{"execution":{"iopub.status.busy":"2023-10-31T11:10:32.235068Z","iopub.execute_input":"2023-10-31T11:10:32.235561Z","iopub.status.idle":"2023-10-31T11:10:32.284224Z","shell.execute_reply.started":"2023-10-31T11:10:32.235526Z","shell.execute_reply":"2023-10-31T11:10:32.282920Z"},"trusted":true},"execution_count":13,"outputs":[{"execution_count":13,"output_type":"execute_result","data":{"text/plain":"        age  height(cm)  weight(kg)  waist(cm)  eyesight(left)  \\\n0      65.0       170.0        75.0       91.0             0.6   \n1      35.0       170.0        85.0       97.0             1.5   \n2      70.0       165.0        55.0       75.0             0.8   \n3      35.0       180.0        85.0       83.0             1.2   \n4      25.0       170.0        65.0       80.0             1.5   \n...     ...         ...         ...        ...             ...   \n13858  45.0       175.0        85.0       94.0             0.8   \n13859  40.0       170.0        75.0       86.0             1.2   \n13860  65.0       170.0        70.0       85.0             0.6   \n13861  30.0       160.0        80.0       89.0             1.5   \n13862  60.0       170.0        70.0       86.0             1.5   \n\n       eyesight(right)  systolic  relaxation  fasting blood sugar  \\\n0                  0.9     122.0        79.0                107.0   \n1                  1.5     138.0        88.0                117.0   \n2                  1.0     115.0        63.0                128.0   \n3                  1.0     130.0        80.0                100.0   \n4                  1.2     135.0        75.0                 94.0   \n...                ...       ...         ...                  ...   \n13858              0.8     127.0        71.0                 99.0   \n13859              1.0     134.0        88.0                 97.0   \n13860              0.7     131.0        82.0                 99.0   \n13861              1.5     120.0        80.0                 92.0   \n13862              1.5     135.0        85.0                 90.0   \n\n       Cholesterol  ...  GTP_to_age GTP_to_AST_ALT  \\\n0            119.0  ...                   6.360684   \n1            204.0  ...                   1.015873   \n2            165.0  ...                   0.184184   \n3            209.0  ...                   0.206429   \n4            153.0  ...                   0.237576   \n...            ...  ...                        ...   \n13858        249.0  ...                   0.235948   \n13859        247.0  ...                   1.200000   \n13860        180.0  ...                   0.443077   \n13861        172.0  ...                   0.525137   \n13862        159.0  ...                   0.121040   \n\n       GTP_to_age GTP_to_Cholesterol  GTP_to_age GTP_index  GTP_to_AST_ALT^2  \\\n0                           1.924240              1.346968         11.484568   \n1                           0.224090              0.103193          0.790123   \n2                           0.031255              0.022921          0.460459   \n3                           0.039508              0.022684          0.180625   \n4                           0.051242              0.034690          0.179982   \n...                              ...                   ...               ...   \n13858                       0.032218              0.018744          0.312284   \n13859                       0.131174              0.075349          1.777778   \n13860                       0.049231              0.033065          1.440000   \n13861                       0.186240              0.104004          0.258264   \n13862                       0.107338              0.074527          0.051506   \n\n       GTP_to_AST_ALT GTP_to_Cholesterol  GTP_to_AST_ALT GTP_index  \\\n0                               3.474323                  2.432026   \n1                               0.174292                  0.080261   \n2                               0.078139                  0.057302   \n3                               0.034569                  0.019849   \n4                               0.038820                  0.026281   \n...                                  ...                       ...   \n13858                           0.042641                  0.024808   \n13859                           0.194332                  0.111628   \n13860                           0.160000                  0.107463   \n13861                           0.091594                  0.051150   \n13862                           0.045676                  0.031714   \n\n       GTP_to_Cholesterol^2  GTP_to_Cholesterol GTP_index  GTP_index^2  \\\n0                  1.051056                      0.735739     0.515017   \n1                  0.038447                      0.017705     0.008153   \n2                  0.013260                      0.009724     0.007131   \n3                  0.006616                      0.003799     0.002181   \n4                  0.008373                      0.005668     0.003837   \n...                     ...                           ...          ...   \n13858              0.005822                      0.003387     0.001971   \n13859              0.021243                      0.012202     0.007009   \n13860              0.017778                      0.011940     0.008020   \n13861              0.032484                      0.018140     0.010130   \n13862              0.040505                      0.028123     0.019527   \n\n       smoking  \n0            0  \n1            1  \n2            0  \n3            0  \n4            1  \n...        ...  \n13858        0  \n13859        1  \n13860        1  \n13861        0  \n13862        0  \n\n[13863 rows x 861 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>age</th>\n      <th>height(cm)</th>\n      <th>weight(kg)</th>\n      <th>waist(cm)</th>\n      <th>eyesight(left)</th>\n      <th>eyesight(right)</th>\n      <th>systolic</th>\n      <th>relaxation</th>\n      <th>fasting blood sugar</th>\n      <th>Cholesterol</th>\n      <th>...</th>\n      <th>GTP_to_age GTP_to_AST_ALT</th>\n      <th>GTP_to_age GTP_to_Cholesterol</th>\n      <th>GTP_to_age GTP_index</th>\n      <th>GTP_to_AST_ALT^2</th>\n      <th>GTP_to_AST_ALT GTP_to_Cholesterol</th>\n      <th>GTP_to_AST_ALT GTP_index</th>\n      <th>GTP_to_Cholesterol^2</th>\n      <th>GTP_to_Cholesterol GTP_index</th>\n      <th>GTP_index^2</th>\n      <th>smoking</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>65.0</td>\n      <td>170.0</td>\n      <td>75.0</td>\n      <td>91.0</td>\n      <td>0.6</td>\n      <td>0.9</td>\n      <td>122.0</td>\n      <td>79.0</td>\n      <td>107.0</td>\n      <td>119.0</td>\n      <td>...</td>\n      <td>6.360684</td>\n      <td>1.924240</td>\n      <td>1.346968</td>\n      <td>11.484568</td>\n      <td>3.474323</td>\n      <td>2.432026</td>\n      <td>1.051056</td>\n      <td>0.735739</td>\n      <td>0.515017</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>35.0</td>\n      <td>170.0</td>\n      <td>85.0</td>\n      <td>97.0</td>\n      <td>1.5</td>\n      <td>1.5</td>\n      <td>138.0</td>\n      <td>88.0</td>\n      <td>117.0</td>\n      <td>204.0</td>\n      <td>...</td>\n      <td>1.015873</td>\n      <td>0.224090</td>\n      <td>0.103193</td>\n      <td>0.790123</td>\n      <td>0.174292</td>\n      <td>0.080261</td>\n      <td>0.038447</td>\n      <td>0.017705</td>\n      <td>0.008153</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>70.0</td>\n      <td>165.0</td>\n      <td>55.0</td>\n      <td>75.0</td>\n      <td>0.8</td>\n      <td>1.0</td>\n      <td>115.0</td>\n      <td>63.0</td>\n      <td>128.0</td>\n      <td>165.0</td>\n      <td>...</td>\n      <td>0.184184</td>\n      <td>0.031255</td>\n      <td>0.022921</td>\n      <td>0.460459</td>\n      <td>0.078139</td>\n      <td>0.057302</td>\n      <td>0.013260</td>\n      <td>0.009724</td>\n      <td>0.007131</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>35.0</td>\n      <td>180.0</td>\n      <td>85.0</td>\n      <td>83.0</td>\n      <td>1.2</td>\n      <td>1.0</td>\n      <td>130.0</td>\n      <td>80.0</td>\n      <td>100.0</td>\n      <td>209.0</td>\n      <td>...</td>\n      <td>0.206429</td>\n      <td>0.039508</td>\n      <td>0.022684</td>\n      <td>0.180625</td>\n      <td>0.034569</td>\n      <td>0.019849</td>\n      <td>0.006616</td>\n      <td>0.003799</td>\n      <td>0.002181</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>25.0</td>\n      <td>170.0</td>\n      <td>65.0</td>\n      <td>80.0</td>\n      <td>1.5</td>\n      <td>1.2</td>\n      <td>135.0</td>\n      <td>75.0</td>\n      <td>94.0</td>\n      <td>153.0</td>\n      <td>...</td>\n      <td>0.237576</td>\n      <td>0.051242</td>\n      <td>0.034690</td>\n      <td>0.179982</td>\n      <td>0.038820</td>\n      <td>0.026281</td>\n      <td>0.008373</td>\n      <td>0.005668</td>\n      <td>0.003837</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>13858</th>\n      <td>45.0</td>\n      <td>175.0</td>\n      <td>85.0</td>\n      <td>94.0</td>\n      <td>0.8</td>\n      <td>0.8</td>\n      <td>127.0</td>\n      <td>71.0</td>\n      <td>99.0</td>\n      <td>249.0</td>\n      <td>...</td>\n      <td>0.235948</td>\n      <td>0.032218</td>\n      <td>0.018744</td>\n      <td>0.312284</td>\n      <td>0.042641</td>\n      <td>0.024808</td>\n      <td>0.005822</td>\n      <td>0.003387</td>\n      <td>0.001971</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>13859</th>\n      <td>40.0</td>\n      <td>170.0</td>\n      <td>75.0</td>\n      <td>86.0</td>\n      <td>1.2</td>\n      <td>1.0</td>\n      <td>134.0</td>\n      <td>88.0</td>\n      <td>97.0</td>\n      <td>247.0</td>\n      <td>...</td>\n      <td>1.200000</td>\n      <td>0.131174</td>\n      <td>0.075349</td>\n      <td>1.777778</td>\n      <td>0.194332</td>\n      <td>0.111628</td>\n      <td>0.021243</td>\n      <td>0.012202</td>\n      <td>0.007009</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>13860</th>\n      <td>65.0</td>\n      <td>170.0</td>\n      <td>70.0</td>\n      <td>85.0</td>\n      <td>0.6</td>\n      <td>0.7</td>\n      <td>131.0</td>\n      <td>82.0</td>\n      <td>99.0</td>\n      <td>180.0</td>\n      <td>...</td>\n      <td>0.443077</td>\n      <td>0.049231</td>\n      <td>0.033065</td>\n      <td>1.440000</td>\n      <td>0.160000</td>\n      <td>0.107463</td>\n      <td>0.017778</td>\n      <td>0.011940</td>\n      <td>0.008020</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>13861</th>\n      <td>30.0</td>\n      <td>160.0</td>\n      <td>80.0</td>\n      <td>89.0</td>\n      <td>1.5</td>\n      <td>1.5</td>\n      <td>120.0</td>\n      <td>80.0</td>\n      <td>92.0</td>\n      <td>172.0</td>\n      <td>...</td>\n      <td>0.525137</td>\n      <td>0.186240</td>\n      <td>0.104004</td>\n      <td>0.258264</td>\n      <td>0.091594</td>\n      <td>0.051150</td>\n      <td>0.032484</td>\n      <td>0.018140</td>\n      <td>0.010130</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>13862</th>\n      <td>60.0</td>\n      <td>170.0</td>\n      <td>70.0</td>\n      <td>86.0</td>\n      <td>1.5</td>\n      <td>1.5</td>\n      <td>135.0</td>\n      <td>85.0</td>\n      <td>90.0</td>\n      <td>159.0</td>\n      <td>...</td>\n      <td>0.121040</td>\n      <td>0.107338</td>\n      <td>0.074527</td>\n      <td>0.051506</td>\n      <td>0.045676</td>\n      <td>0.031714</td>\n      <td>0.040505</td>\n      <td>0.028123</td>\n      <td>0.019527</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>13863 rows × 861 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"poly_df.columns.to_list()","metadata":{"execution":{"iopub.status.busy":"2023-10-31T11:10:36.537046Z","iopub.execute_input":"2023-10-31T11:10:36.538353Z","iopub.status.idle":"2023-10-31T11:10:36.562827Z","shell.execute_reply.started":"2023-10-31T11:10:36.538287Z","shell.execute_reply":"2023-10-31T11:10:36.561425Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":14,"outputs":[{"execution_count":14,"output_type":"execute_result","data":{"text/plain":"['age',\n 'height(cm)',\n 'weight(kg)',\n 'waist(cm)',\n 'eyesight(left)',\n 'eyesight(right)',\n 'systolic',\n 'relaxation',\n 'fasting blood sugar',\n 'Cholesterol',\n 'triglyceride',\n 'HDL',\n 'LDL',\n 'hemoglobin',\n 'Urine protein',\n 'serum creatinine',\n 'AST',\n 'ALT',\n 'Gtp',\n 'BMI',\n 'Chol_HDL_ratio',\n 'ldl_hdl',\n 'map',\n 'Waist_Height_ratio',\n 'height_nin_110',\n 'Average_hearing',\n 'Average_eyesight',\n 'ast_alt',\n 'Systolic_Diastolic_ratio',\n 'Atherogenic_coefficient',\n 'BMI_to_age',\n 'Glucose_to_Cholesterol',\n 'Triglycerides_to_HDL',\n 'Systolic_to_age',\n 'Diastolic_to_age',\n 'Hemoglobin_to_age',\n 'GTP_to_age',\n 'GTP_to_AST_ALT',\n 'GTP_to_Cholesterol',\n 'GTP_index',\n 'age^2',\n 'age height(cm)',\n 'age weight(kg)',\n 'age waist(cm)',\n 'age eyesight(left)',\n 'age eyesight(right)',\n 'age systolic',\n 'age relaxation',\n 'age fasting blood sugar',\n 'age Cholesterol',\n 'age triglyceride',\n 'age HDL',\n 'age LDL',\n 'age hemoglobin',\n 'age Urine protein',\n 'age serum creatinine',\n 'age AST',\n 'age ALT',\n 'age Gtp',\n 'age BMI',\n 'age Chol_HDL_ratio',\n 'age ldl_hdl',\n 'age map',\n 'age Waist_Height_ratio',\n 'age height_nin_110',\n 'age Average_hearing',\n 'age Average_eyesight',\n 'age ast_alt',\n 'age Systolic_Diastolic_ratio',\n 'age Atherogenic_coefficient',\n 'age BMI_to_age',\n 'age Glucose_to_Cholesterol',\n 'age Triglycerides_to_HDL',\n 'age Systolic_to_age',\n 'age Diastolic_to_age',\n 'age Hemoglobin_to_age',\n 'age GTP_to_age',\n 'age GTP_to_AST_ALT',\n 'age GTP_to_Cholesterol',\n 'age GTP_index',\n 'height(cm)^2',\n 'height(cm) weight(kg)',\n 'height(cm) waist(cm)',\n 'height(cm) eyesight(left)',\n 'height(cm) eyesight(right)',\n 'height(cm) systolic',\n 'height(cm) relaxation',\n 'height(cm) fasting blood sugar',\n 'height(cm) Cholesterol',\n 'height(cm) triglyceride',\n 'height(cm) HDL',\n 'height(cm) LDL',\n 'height(cm) hemoglobin',\n 'height(cm) Urine protein',\n 'height(cm) serum creatinine',\n 'height(cm) AST',\n 'height(cm) ALT',\n 'height(cm) Gtp',\n 'height(cm) BMI',\n 'height(cm) Chol_HDL_ratio',\n 'height(cm) ldl_hdl',\n 'height(cm) map',\n 'height(cm) Waist_Height_ratio',\n 'height(cm) height_nin_110',\n 'height(cm) Average_hearing',\n 'height(cm) Average_eyesight',\n 'height(cm) ast_alt',\n 'height(cm) Systolic_Diastolic_ratio',\n 'height(cm) Atherogenic_coefficient',\n 'height(cm) BMI_to_age',\n 'height(cm) Glucose_to_Cholesterol',\n 'height(cm) Triglycerides_to_HDL',\n 'height(cm) Systolic_to_age',\n 'height(cm) Diastolic_to_age',\n 'height(cm) Hemoglobin_to_age',\n 'height(cm) GTP_to_age',\n 'height(cm) GTP_to_AST_ALT',\n 'height(cm) GTP_to_Cholesterol',\n 'height(cm) GTP_index',\n 'weight(kg)^2',\n 'weight(kg) waist(cm)',\n 'weight(kg) eyesight(left)',\n 'weight(kg) eyesight(right)',\n 'weight(kg) systolic',\n 'weight(kg) relaxation',\n 'weight(kg) fasting blood sugar',\n 'weight(kg) Cholesterol',\n 'weight(kg) triglyceride',\n 'weight(kg) HDL',\n 'weight(kg) LDL',\n 'weight(kg) hemoglobin',\n 'weight(kg) Urine protein',\n 'weight(kg) serum creatinine',\n 'weight(kg) AST',\n 'weight(kg) ALT',\n 'weight(kg) Gtp',\n 'weight(kg) BMI',\n 'weight(kg) Chol_HDL_ratio',\n 'weight(kg) ldl_hdl',\n 'weight(kg) map',\n 'weight(kg) Waist_Height_ratio',\n 'weight(kg) height_nin_110',\n 'weight(kg) Average_hearing',\n 'weight(kg) Average_eyesight',\n 'weight(kg) ast_alt',\n 'weight(kg) Systolic_Diastolic_ratio',\n 'weight(kg) Atherogenic_coefficient',\n 'weight(kg) BMI_to_age',\n 'weight(kg) Glucose_to_Cholesterol',\n 'weight(kg) Triglycerides_to_HDL',\n 'weight(kg) Systolic_to_age',\n 'weight(kg) Diastolic_to_age',\n 'weight(kg) Hemoglobin_to_age',\n 'weight(kg) GTP_to_age',\n 'weight(kg) GTP_to_AST_ALT',\n 'weight(kg) GTP_to_Cholesterol',\n 'weight(kg) GTP_index',\n 'waist(cm)^2',\n 'waist(cm) eyesight(left)',\n 'waist(cm) eyesight(right)',\n 'waist(cm) systolic',\n 'waist(cm) relaxation',\n 'waist(cm) fasting blood sugar',\n 'waist(cm) Cholesterol',\n 'waist(cm) triglyceride',\n 'waist(cm) HDL',\n 'waist(cm) LDL',\n 'waist(cm) hemoglobin',\n 'waist(cm) Urine protein',\n 'waist(cm) serum creatinine',\n 'waist(cm) AST',\n 'waist(cm) ALT',\n 'waist(cm) Gtp',\n 'waist(cm) BMI',\n 'waist(cm) Chol_HDL_ratio',\n 'waist(cm) ldl_hdl',\n 'waist(cm) map',\n 'waist(cm) Waist_Height_ratio',\n 'waist(cm) height_nin_110',\n 'waist(cm) Average_hearing',\n 'waist(cm) Average_eyesight',\n 'waist(cm) ast_alt',\n 'waist(cm) Systolic_Diastolic_ratio',\n 'waist(cm) Atherogenic_coefficient',\n 'waist(cm) BMI_to_age',\n 'waist(cm) Glucose_to_Cholesterol',\n 'waist(cm) Triglycerides_to_HDL',\n 'waist(cm) Systolic_to_age',\n 'waist(cm) Diastolic_to_age',\n 'waist(cm) Hemoglobin_to_age',\n 'waist(cm) GTP_to_age',\n 'waist(cm) GTP_to_AST_ALT',\n 'waist(cm) GTP_to_Cholesterol',\n 'waist(cm) GTP_index',\n 'eyesight(left)^2',\n 'eyesight(left) eyesight(right)',\n 'eyesight(left) systolic',\n 'eyesight(left) relaxation',\n 'eyesight(left) fasting blood sugar',\n 'eyesight(left) Cholesterol',\n 'eyesight(left) triglyceride',\n 'eyesight(left) HDL',\n 'eyesight(left) LDL',\n 'eyesight(left) hemoglobin',\n 'eyesight(left) Urine protein',\n 'eyesight(left) serum creatinine',\n 'eyesight(left) AST',\n 'eyesight(left) ALT',\n 'eyesight(left) Gtp',\n 'eyesight(left) BMI',\n 'eyesight(left) Chol_HDL_ratio',\n 'eyesight(left) ldl_hdl',\n 'eyesight(left) map',\n 'eyesight(left) Waist_Height_ratio',\n 'eyesight(left) height_nin_110',\n 'eyesight(left) Average_hearing',\n 'eyesight(left) Average_eyesight',\n 'eyesight(left) ast_alt',\n 'eyesight(left) Systolic_Diastolic_ratio',\n 'eyesight(left) Atherogenic_coefficient',\n 'eyesight(left) BMI_to_age',\n 'eyesight(left) Glucose_to_Cholesterol',\n 'eyesight(left) Triglycerides_to_HDL',\n 'eyesight(left) Systolic_to_age',\n 'eyesight(left) Diastolic_to_age',\n 'eyesight(left) Hemoglobin_to_age',\n 'eyesight(left) GTP_to_age',\n 'eyesight(left) GTP_to_AST_ALT',\n 'eyesight(left) GTP_to_Cholesterol',\n 'eyesight(left) GTP_index',\n 'eyesight(right)^2',\n 'eyesight(right) systolic',\n 'eyesight(right) relaxation',\n 'eyesight(right) fasting blood sugar',\n 'eyesight(right) Cholesterol',\n 'eyesight(right) triglyceride',\n 'eyesight(right) HDL',\n 'eyesight(right) LDL',\n 'eyesight(right) hemoglobin',\n 'eyesight(right) Urine protein',\n 'eyesight(right) serum creatinine',\n 'eyesight(right) AST',\n 'eyesight(right) ALT',\n 'eyesight(right) Gtp',\n 'eyesight(right) BMI',\n 'eyesight(right) Chol_HDL_ratio',\n 'eyesight(right) ldl_hdl',\n 'eyesight(right) map',\n 'eyesight(right) Waist_Height_ratio',\n 'eyesight(right) height_nin_110',\n 'eyesight(right) Average_hearing',\n 'eyesight(right) Average_eyesight',\n 'eyesight(right) ast_alt',\n 'eyesight(right) Systolic_Diastolic_ratio',\n 'eyesight(right) Atherogenic_coefficient',\n 'eyesight(right) BMI_to_age',\n 'eyesight(right) Glucose_to_Cholesterol',\n 'eyesight(right) Triglycerides_to_HDL',\n 'eyesight(right) Systolic_to_age',\n 'eyesight(right) Diastolic_to_age',\n 'eyesight(right) Hemoglobin_to_age',\n 'eyesight(right) GTP_to_age',\n 'eyesight(right) GTP_to_AST_ALT',\n 'eyesight(right) GTP_to_Cholesterol',\n 'eyesight(right) GTP_index',\n 'systolic^2',\n 'systolic relaxation',\n 'systolic fasting blood sugar',\n 'systolic Cholesterol',\n 'systolic triglyceride',\n 'systolic HDL',\n 'systolic LDL',\n 'systolic hemoglobin',\n 'systolic Urine protein',\n 'systolic serum creatinine',\n 'systolic AST',\n 'systolic ALT',\n 'systolic Gtp',\n 'systolic BMI',\n 'systolic Chol_HDL_ratio',\n 'systolic ldl_hdl',\n 'systolic map',\n 'systolic Waist_Height_ratio',\n 'systolic height_nin_110',\n 'systolic Average_hearing',\n 'systolic Average_eyesight',\n 'systolic ast_alt',\n 'systolic Systolic_Diastolic_ratio',\n 'systolic Atherogenic_coefficient',\n 'systolic BMI_to_age',\n 'systolic Glucose_to_Cholesterol',\n 'systolic Triglycerides_to_HDL',\n 'systolic Systolic_to_age',\n 'systolic Diastolic_to_age',\n 'systolic Hemoglobin_to_age',\n 'systolic GTP_to_age',\n 'systolic GTP_to_AST_ALT',\n 'systolic GTP_to_Cholesterol',\n 'systolic GTP_index',\n 'relaxation^2',\n 'relaxation fasting blood sugar',\n 'relaxation Cholesterol',\n 'relaxation triglyceride',\n 'relaxation HDL',\n 'relaxation LDL',\n 'relaxation hemoglobin',\n 'relaxation Urine protein',\n 'relaxation serum creatinine',\n 'relaxation AST',\n 'relaxation ALT',\n 'relaxation Gtp',\n 'relaxation BMI',\n 'relaxation Chol_HDL_ratio',\n 'relaxation ldl_hdl',\n 'relaxation map',\n 'relaxation Waist_Height_ratio',\n 'relaxation height_nin_110',\n 'relaxation Average_hearing',\n 'relaxation Average_eyesight',\n 'relaxation ast_alt',\n 'relaxation Systolic_Diastolic_ratio',\n 'relaxation Atherogenic_coefficient',\n 'relaxation BMI_to_age',\n 'relaxation Glucose_to_Cholesterol',\n 'relaxation Triglycerides_to_HDL',\n 'relaxation Systolic_to_age',\n 'relaxation Diastolic_to_age',\n 'relaxation Hemoglobin_to_age',\n 'relaxation GTP_to_age',\n 'relaxation GTP_to_AST_ALT',\n 'relaxation GTP_to_Cholesterol',\n 'relaxation GTP_index',\n 'fasting blood sugar^2',\n 'fasting blood sugar Cholesterol',\n 'fasting blood sugar triglyceride',\n 'fasting blood sugar HDL',\n 'fasting blood sugar LDL',\n 'fasting blood sugar hemoglobin',\n 'fasting blood sugar Urine protein',\n 'fasting blood sugar serum creatinine',\n 'fasting blood sugar AST',\n 'fasting blood sugar ALT',\n 'fasting blood sugar Gtp',\n 'fasting blood sugar BMI',\n 'fasting blood sugar Chol_HDL_ratio',\n 'fasting blood sugar ldl_hdl',\n 'fasting blood sugar map',\n 'fasting blood sugar Waist_Height_ratio',\n 'fasting blood sugar height_nin_110',\n 'fasting blood sugar Average_hearing',\n 'fasting blood sugar Average_eyesight',\n 'fasting blood sugar ast_alt',\n 'fasting blood sugar Systolic_Diastolic_ratio',\n 'fasting blood sugar Atherogenic_coefficient',\n 'fasting blood sugar BMI_to_age',\n 'fasting blood sugar Glucose_to_Cholesterol',\n 'fasting blood sugar Triglycerides_to_HDL',\n 'fasting blood sugar Systolic_to_age',\n 'fasting blood sugar Diastolic_to_age',\n 'fasting blood sugar Hemoglobin_to_age',\n 'fasting blood sugar GTP_to_age',\n 'fasting blood sugar GTP_to_AST_ALT',\n 'fasting blood sugar GTP_to_Cholesterol',\n 'fasting blood sugar GTP_index',\n 'Cholesterol^2',\n 'Cholesterol triglyceride',\n 'Cholesterol HDL',\n 'Cholesterol LDL',\n 'Cholesterol hemoglobin',\n 'Cholesterol Urine protein',\n 'Cholesterol serum creatinine',\n 'Cholesterol AST',\n 'Cholesterol ALT',\n 'Cholesterol Gtp',\n 'Cholesterol BMI',\n 'Cholesterol Chol_HDL_ratio',\n 'Cholesterol ldl_hdl',\n 'Cholesterol map',\n 'Cholesterol Waist_Height_ratio',\n 'Cholesterol height_nin_110',\n 'Cholesterol Average_hearing',\n 'Cholesterol Average_eyesight',\n 'Cholesterol ast_alt',\n 'Cholesterol Systolic_Diastolic_ratio',\n 'Cholesterol Atherogenic_coefficient',\n 'Cholesterol BMI_to_age',\n 'Cholesterol Glucose_to_Cholesterol',\n 'Cholesterol Triglycerides_to_HDL',\n 'Cholesterol Systolic_to_age',\n 'Cholesterol Diastolic_to_age',\n 'Cholesterol Hemoglobin_to_age',\n 'Cholesterol GTP_to_age',\n 'Cholesterol GTP_to_AST_ALT',\n 'Cholesterol GTP_to_Cholesterol',\n 'Cholesterol GTP_index',\n 'triglyceride^2',\n 'triglyceride HDL',\n 'triglyceride LDL',\n 'triglyceride hemoglobin',\n 'triglyceride Urine protein',\n 'triglyceride serum creatinine',\n 'triglyceride AST',\n 'triglyceride ALT',\n 'triglyceride Gtp',\n 'triglyceride BMI',\n 'triglyceride Chol_HDL_ratio',\n 'triglyceride ldl_hdl',\n 'triglyceride map',\n 'triglyceride Waist_Height_ratio',\n 'triglyceride height_nin_110',\n 'triglyceride Average_hearing',\n 'triglyceride Average_eyesight',\n 'triglyceride ast_alt',\n 'triglyceride Systolic_Diastolic_ratio',\n 'triglyceride Atherogenic_coefficient',\n 'triglyceride BMI_to_age',\n 'triglyceride Glucose_to_Cholesterol',\n 'triglyceride Triglycerides_to_HDL',\n 'triglyceride Systolic_to_age',\n 'triglyceride Diastolic_to_age',\n 'triglyceride Hemoglobin_to_age',\n 'triglyceride GTP_to_age',\n 'triglyceride GTP_to_AST_ALT',\n 'triglyceride GTP_to_Cholesterol',\n 'triglyceride GTP_index',\n 'HDL^2',\n 'HDL LDL',\n 'HDL hemoglobin',\n 'HDL Urine protein',\n 'HDL serum creatinine',\n 'HDL AST',\n 'HDL ALT',\n 'HDL Gtp',\n 'HDL BMI',\n 'HDL Chol_HDL_ratio',\n 'HDL ldl_hdl',\n 'HDL map',\n 'HDL Waist_Height_ratio',\n 'HDL height_nin_110',\n 'HDL Average_hearing',\n 'HDL Average_eyesight',\n 'HDL ast_alt',\n 'HDL Systolic_Diastolic_ratio',\n 'HDL Atherogenic_coefficient',\n 'HDL BMI_to_age',\n 'HDL Glucose_to_Cholesterol',\n 'HDL Triglycerides_to_HDL',\n 'HDL Systolic_to_age',\n 'HDL Diastolic_to_age',\n 'HDL Hemoglobin_to_age',\n 'HDL GTP_to_age',\n 'HDL GTP_to_AST_ALT',\n 'HDL GTP_to_Cholesterol',\n 'HDL GTP_index',\n 'LDL^2',\n 'LDL hemoglobin',\n 'LDL Urine protein',\n 'LDL serum creatinine',\n 'LDL AST',\n 'LDL ALT',\n 'LDL Gtp',\n 'LDL BMI',\n 'LDL Chol_HDL_ratio',\n 'LDL ldl_hdl',\n 'LDL map',\n 'LDL Waist_Height_ratio',\n 'LDL height_nin_110',\n 'LDL Average_hearing',\n 'LDL Average_eyesight',\n 'LDL ast_alt',\n 'LDL Systolic_Diastolic_ratio',\n 'LDL Atherogenic_coefficient',\n 'LDL BMI_to_age',\n 'LDL Glucose_to_Cholesterol',\n 'LDL Triglycerides_to_HDL',\n 'LDL Systolic_to_age',\n 'LDL Diastolic_to_age',\n 'LDL Hemoglobin_to_age',\n 'LDL GTP_to_age',\n 'LDL GTP_to_AST_ALT',\n 'LDL GTP_to_Cholesterol',\n 'LDL GTP_index',\n 'hemoglobin^2',\n 'hemoglobin Urine protein',\n 'hemoglobin serum creatinine',\n 'hemoglobin AST',\n 'hemoglobin ALT',\n 'hemoglobin Gtp',\n 'hemoglobin BMI',\n 'hemoglobin Chol_HDL_ratio',\n 'hemoglobin ldl_hdl',\n 'hemoglobin map',\n 'hemoglobin Waist_Height_ratio',\n 'hemoglobin height_nin_110',\n 'hemoglobin Average_hearing',\n 'hemoglobin Average_eyesight',\n 'hemoglobin ast_alt',\n 'hemoglobin Systolic_Diastolic_ratio',\n 'hemoglobin Atherogenic_coefficient',\n 'hemoglobin BMI_to_age',\n 'hemoglobin Glucose_to_Cholesterol',\n 'hemoglobin Triglycerides_to_HDL',\n 'hemoglobin Systolic_to_age',\n 'hemoglobin Diastolic_to_age',\n 'hemoglobin Hemoglobin_to_age',\n 'hemoglobin GTP_to_age',\n 'hemoglobin GTP_to_AST_ALT',\n 'hemoglobin GTP_to_Cholesterol',\n 'hemoglobin GTP_index',\n 'Urine protein^2',\n 'Urine protein serum creatinine',\n 'Urine protein AST',\n 'Urine protein ALT',\n 'Urine protein Gtp',\n 'Urine protein BMI',\n 'Urine protein Chol_HDL_ratio',\n 'Urine protein ldl_hdl',\n 'Urine protein map',\n 'Urine protein Waist_Height_ratio',\n 'Urine protein height_nin_110',\n 'Urine protein Average_hearing',\n 'Urine protein Average_eyesight',\n 'Urine protein ast_alt',\n 'Urine protein Systolic_Diastolic_ratio',\n 'Urine protein Atherogenic_coefficient',\n 'Urine protein BMI_to_age',\n 'Urine protein Glucose_to_Cholesterol',\n 'Urine protein Triglycerides_to_HDL',\n 'Urine protein Systolic_to_age',\n 'Urine protein Diastolic_to_age',\n 'Urine protein Hemoglobin_to_age',\n 'Urine protein GTP_to_age',\n 'Urine protein GTP_to_AST_ALT',\n 'Urine protein GTP_to_Cholesterol',\n 'Urine protein GTP_index',\n 'serum creatinine^2',\n 'serum creatinine AST',\n 'serum creatinine ALT',\n 'serum creatinine Gtp',\n 'serum creatinine BMI',\n 'serum creatinine Chol_HDL_ratio',\n 'serum creatinine ldl_hdl',\n 'serum creatinine map',\n 'serum creatinine Waist_Height_ratio',\n 'serum creatinine height_nin_110',\n 'serum creatinine Average_hearing',\n 'serum creatinine Average_eyesight',\n 'serum creatinine ast_alt',\n 'serum creatinine Systolic_Diastolic_ratio',\n 'serum creatinine Atherogenic_coefficient',\n 'serum creatinine BMI_to_age',\n 'serum creatinine Glucose_to_Cholesterol',\n 'serum creatinine Triglycerides_to_HDL',\n 'serum creatinine Systolic_to_age',\n 'serum creatinine Diastolic_to_age',\n 'serum creatinine Hemoglobin_to_age',\n 'serum creatinine GTP_to_age',\n 'serum creatinine GTP_to_AST_ALT',\n 'serum creatinine GTP_to_Cholesterol',\n 'serum creatinine GTP_index',\n 'AST^2',\n 'AST ALT',\n 'AST Gtp',\n 'AST BMI',\n 'AST Chol_HDL_ratio',\n 'AST ldl_hdl',\n 'AST map',\n 'AST Waist_Height_ratio',\n 'AST height_nin_110',\n 'AST Average_hearing',\n 'AST Average_eyesight',\n 'AST ast_alt',\n 'AST Systolic_Diastolic_ratio',\n 'AST Atherogenic_coefficient',\n 'AST BMI_to_age',\n 'AST Glucose_to_Cholesterol',\n 'AST Triglycerides_to_HDL',\n 'AST Systolic_to_age',\n 'AST Diastolic_to_age',\n 'AST Hemoglobin_to_age',\n 'AST GTP_to_age',\n 'AST GTP_to_AST_ALT',\n 'AST GTP_to_Cholesterol',\n 'AST GTP_index',\n 'ALT^2',\n 'ALT Gtp',\n 'ALT BMI',\n 'ALT Chol_HDL_ratio',\n 'ALT ldl_hdl',\n 'ALT map',\n 'ALT Waist_Height_ratio',\n 'ALT height_nin_110',\n 'ALT Average_hearing',\n 'ALT Average_eyesight',\n 'ALT ast_alt',\n 'ALT Systolic_Diastolic_ratio',\n 'ALT Atherogenic_coefficient',\n 'ALT BMI_to_age',\n 'ALT Glucose_to_Cholesterol',\n 'ALT Triglycerides_to_HDL',\n 'ALT Systolic_to_age',\n 'ALT Diastolic_to_age',\n 'ALT Hemoglobin_to_age',\n 'ALT GTP_to_age',\n 'ALT GTP_to_AST_ALT',\n 'ALT GTP_to_Cholesterol',\n 'ALT GTP_index',\n 'Gtp^2',\n 'Gtp BMI',\n 'Gtp Chol_HDL_ratio',\n 'Gtp ldl_hdl',\n 'Gtp map',\n 'Gtp Waist_Height_ratio',\n 'Gtp height_nin_110',\n 'Gtp Average_hearing',\n 'Gtp Average_eyesight',\n 'Gtp ast_alt',\n 'Gtp Systolic_Diastolic_ratio',\n 'Gtp Atherogenic_coefficient',\n 'Gtp BMI_to_age',\n 'Gtp Glucose_to_Cholesterol',\n 'Gtp Triglycerides_to_HDL',\n 'Gtp Systolic_to_age',\n 'Gtp Diastolic_to_age',\n 'Gtp Hemoglobin_to_age',\n 'Gtp GTP_to_age',\n 'Gtp GTP_to_AST_ALT',\n 'Gtp GTP_to_Cholesterol',\n 'Gtp GTP_index',\n 'BMI^2',\n 'BMI Chol_HDL_ratio',\n 'BMI ldl_hdl',\n 'BMI map',\n 'BMI Waist_Height_ratio',\n 'BMI height_nin_110',\n 'BMI Average_hearing',\n 'BMI Average_eyesight',\n 'BMI ast_alt',\n 'BMI Systolic_Diastolic_ratio',\n 'BMI Atherogenic_coefficient',\n 'BMI BMI_to_age',\n 'BMI Glucose_to_Cholesterol',\n 'BMI Triglycerides_to_HDL',\n 'BMI Systolic_to_age',\n 'BMI Diastolic_to_age',\n 'BMI Hemoglobin_to_age',\n 'BMI GTP_to_age',\n 'BMI GTP_to_AST_ALT',\n 'BMI GTP_to_Cholesterol',\n 'BMI GTP_index',\n 'Chol_HDL_ratio^2',\n 'Chol_HDL_ratio ldl_hdl',\n 'Chol_HDL_ratio map',\n 'Chol_HDL_ratio Waist_Height_ratio',\n 'Chol_HDL_ratio height_nin_110',\n 'Chol_HDL_ratio Average_hearing',\n 'Chol_HDL_ratio Average_eyesight',\n 'Chol_HDL_ratio ast_alt',\n 'Chol_HDL_ratio Systolic_Diastolic_ratio',\n 'Chol_HDL_ratio Atherogenic_coefficient',\n 'Chol_HDL_ratio BMI_to_age',\n 'Chol_HDL_ratio Glucose_to_Cholesterol',\n 'Chol_HDL_ratio Triglycerides_to_HDL',\n 'Chol_HDL_ratio Systolic_to_age',\n 'Chol_HDL_ratio Diastolic_to_age',\n 'Chol_HDL_ratio Hemoglobin_to_age',\n 'Chol_HDL_ratio GTP_to_age',\n 'Chol_HDL_ratio GTP_to_AST_ALT',\n 'Chol_HDL_ratio GTP_to_Cholesterol',\n 'Chol_HDL_ratio GTP_index',\n 'ldl_hdl^2',\n 'ldl_hdl map',\n 'ldl_hdl Waist_Height_ratio',\n 'ldl_hdl height_nin_110',\n 'ldl_hdl Average_hearing',\n 'ldl_hdl Average_eyesight',\n 'ldl_hdl ast_alt',\n 'ldl_hdl Systolic_Diastolic_ratio',\n 'ldl_hdl Atherogenic_coefficient',\n 'ldl_hdl BMI_to_age',\n 'ldl_hdl Glucose_to_Cholesterol',\n 'ldl_hdl Triglycerides_to_HDL',\n 'ldl_hdl Systolic_to_age',\n 'ldl_hdl Diastolic_to_age',\n 'ldl_hdl Hemoglobin_to_age',\n 'ldl_hdl GTP_to_age',\n 'ldl_hdl GTP_to_AST_ALT',\n 'ldl_hdl GTP_to_Cholesterol',\n 'ldl_hdl GTP_index',\n 'map^2',\n 'map Waist_Height_ratio',\n 'map height_nin_110',\n 'map Average_hearing',\n 'map Average_eyesight',\n 'map ast_alt',\n 'map Systolic_Diastolic_ratio',\n 'map Atherogenic_coefficient',\n 'map BMI_to_age',\n 'map Glucose_to_Cholesterol',\n 'map Triglycerides_to_HDL',\n 'map Systolic_to_age',\n 'map Diastolic_to_age',\n 'map Hemoglobin_to_age',\n 'map GTP_to_age',\n 'map GTP_to_AST_ALT',\n 'map GTP_to_Cholesterol',\n 'map GTP_index',\n 'Waist_Height_ratio^2',\n 'Waist_Height_ratio height_nin_110',\n 'Waist_Height_ratio Average_hearing',\n 'Waist_Height_ratio Average_eyesight',\n 'Waist_Height_ratio ast_alt',\n 'Waist_Height_ratio Systolic_Diastolic_ratio',\n 'Waist_Height_ratio Atherogenic_coefficient',\n 'Waist_Height_ratio BMI_to_age',\n 'Waist_Height_ratio Glucose_to_Cholesterol',\n 'Waist_Height_ratio Triglycerides_to_HDL',\n 'Waist_Height_ratio Systolic_to_age',\n 'Waist_Height_ratio Diastolic_to_age',\n 'Waist_Height_ratio Hemoglobin_to_age',\n 'Waist_Height_ratio GTP_to_age',\n 'Waist_Height_ratio GTP_to_AST_ALT',\n 'Waist_Height_ratio GTP_to_Cholesterol',\n 'Waist_Height_ratio GTP_index',\n 'height_nin_110^2',\n 'height_nin_110 Average_hearing',\n 'height_nin_110 Average_eyesight',\n 'height_nin_110 ast_alt',\n 'height_nin_110 Systolic_Diastolic_ratio',\n 'height_nin_110 Atherogenic_coefficient',\n 'height_nin_110 BMI_to_age',\n 'height_nin_110 Glucose_to_Cholesterol',\n 'height_nin_110 Triglycerides_to_HDL',\n 'height_nin_110 Systolic_to_age',\n 'height_nin_110 Diastolic_to_age',\n 'height_nin_110 Hemoglobin_to_age',\n 'height_nin_110 GTP_to_age',\n 'height_nin_110 GTP_to_AST_ALT',\n 'height_nin_110 GTP_to_Cholesterol',\n 'height_nin_110 GTP_index',\n 'Average_hearing^2',\n 'Average_hearing Average_eyesight',\n 'Average_hearing ast_alt',\n 'Average_hearing Systolic_Diastolic_ratio',\n 'Average_hearing Atherogenic_coefficient',\n 'Average_hearing BMI_to_age',\n 'Average_hearing Glucose_to_Cholesterol',\n 'Average_hearing Triglycerides_to_HDL',\n 'Average_hearing Systolic_to_age',\n 'Average_hearing Diastolic_to_age',\n 'Average_hearing Hemoglobin_to_age',\n 'Average_hearing GTP_to_age',\n 'Average_hearing GTP_to_AST_ALT',\n 'Average_hearing GTP_to_Cholesterol',\n 'Average_hearing GTP_index',\n 'Average_eyesight^2',\n 'Average_eyesight ast_alt',\n 'Average_eyesight Systolic_Diastolic_ratio',\n 'Average_eyesight Atherogenic_coefficient',\n 'Average_eyesight BMI_to_age',\n 'Average_eyesight Glucose_to_Cholesterol',\n 'Average_eyesight Triglycerides_to_HDL',\n 'Average_eyesight Systolic_to_age',\n 'Average_eyesight Diastolic_to_age',\n 'Average_eyesight Hemoglobin_to_age',\n 'Average_eyesight GTP_to_age',\n 'Average_eyesight GTP_to_AST_ALT',\n 'Average_eyesight GTP_to_Cholesterol',\n 'Average_eyesight GTP_index',\n 'ast_alt^2',\n 'ast_alt Systolic_Diastolic_ratio',\n 'ast_alt Atherogenic_coefficient',\n 'ast_alt BMI_to_age',\n 'ast_alt Glucose_to_Cholesterol',\n 'ast_alt Triglycerides_to_HDL',\n 'ast_alt Systolic_to_age',\n 'ast_alt Diastolic_to_age',\n 'ast_alt Hemoglobin_to_age',\n 'ast_alt GTP_to_age',\n 'ast_alt GTP_to_AST_ALT',\n 'ast_alt GTP_to_Cholesterol',\n 'ast_alt GTP_index',\n 'Systolic_Diastolic_ratio^2',\n 'Systolic_Diastolic_ratio Atherogenic_coefficient',\n 'Systolic_Diastolic_ratio BMI_to_age',\n 'Systolic_Diastolic_ratio Glucose_to_Cholesterol',\n 'Systolic_Diastolic_ratio Triglycerides_to_HDL',\n 'Systolic_Diastolic_ratio Systolic_to_age',\n 'Systolic_Diastolic_ratio Diastolic_to_age',\n 'Systolic_Diastolic_ratio Hemoglobin_to_age',\n 'Systolic_Diastolic_ratio GTP_to_age',\n 'Systolic_Diastolic_ratio GTP_to_AST_ALT',\n 'Systolic_Diastolic_ratio GTP_to_Cholesterol',\n 'Systolic_Diastolic_ratio GTP_index',\n 'Atherogenic_coefficient^2',\n 'Atherogenic_coefficient BMI_to_age',\n 'Atherogenic_coefficient Glucose_to_Cholesterol',\n 'Atherogenic_coefficient Triglycerides_to_HDL',\n 'Atherogenic_coefficient Systolic_to_age',\n 'Atherogenic_coefficient Diastolic_to_age',\n 'Atherogenic_coefficient Hemoglobin_to_age',\n 'Atherogenic_coefficient GTP_to_age',\n 'Atherogenic_coefficient GTP_to_AST_ALT',\n 'Atherogenic_coefficient GTP_to_Cholesterol',\n 'Atherogenic_coefficient GTP_index',\n 'BMI_to_age^2',\n 'BMI_to_age Glucose_to_Cholesterol',\n 'BMI_to_age Triglycerides_to_HDL',\n 'BMI_to_age Systolic_to_age',\n 'BMI_to_age Diastolic_to_age',\n 'BMI_to_age Hemoglobin_to_age',\n 'BMI_to_age GTP_to_age',\n 'BMI_to_age GTP_to_AST_ALT',\n 'BMI_to_age GTP_to_Cholesterol',\n 'BMI_to_age GTP_index',\n 'Glucose_to_Cholesterol^2',\n 'Glucose_to_Cholesterol Triglycerides_to_HDL',\n 'Glucose_to_Cholesterol Systolic_to_age',\n 'Glucose_to_Cholesterol Diastolic_to_age',\n 'Glucose_to_Cholesterol Hemoglobin_to_age',\n 'Glucose_to_Cholesterol GTP_to_age',\n 'Glucose_to_Cholesterol GTP_to_AST_ALT',\n 'Glucose_to_Cholesterol GTP_to_Cholesterol',\n 'Glucose_to_Cholesterol GTP_index',\n 'Triglycerides_to_HDL^2',\n 'Triglycerides_to_HDL Systolic_to_age',\n 'Triglycerides_to_HDL Diastolic_to_age',\n 'Triglycerides_to_HDL Hemoglobin_to_age',\n 'Triglycerides_to_HDL GTP_to_age',\n 'Triglycerides_to_HDL GTP_to_AST_ALT',\n 'Triglycerides_to_HDL GTP_to_Cholesterol',\n 'Triglycerides_to_HDL GTP_index',\n 'Systolic_to_age^2',\n 'Systolic_to_age Diastolic_to_age',\n 'Systolic_to_age Hemoglobin_to_age',\n 'Systolic_to_age GTP_to_age',\n 'Systolic_to_age GTP_to_AST_ALT',\n 'Systolic_to_age GTP_to_Cholesterol',\n 'Systolic_to_age GTP_index',\n 'Diastolic_to_age^2',\n 'Diastolic_to_age Hemoglobin_to_age',\n 'Diastolic_to_age GTP_to_age',\n 'Diastolic_to_age GTP_to_AST_ALT',\n 'Diastolic_to_age GTP_to_Cholesterol',\n 'Diastolic_to_age GTP_index',\n 'Hemoglobin_to_age^2',\n 'Hemoglobin_to_age GTP_to_age',\n 'Hemoglobin_to_age GTP_to_AST_ALT',\n 'Hemoglobin_to_age GTP_to_Cholesterol',\n 'Hemoglobin_to_age GTP_index',\n 'GTP_to_age^2',\n 'GTP_to_age GTP_to_AST_ALT',\n 'GTP_to_age GTP_to_Cholesterol',\n 'GTP_to_age GTP_index',\n 'GTP_to_AST_ALT^2',\n 'GTP_to_AST_ALT GTP_to_Cholesterol',\n 'GTP_to_AST_ALT GTP_index',\n 'GTP_to_Cholesterol^2',\n 'GTP_to_Cholesterol GTP_index',\n 'GTP_index^2',\n 'smoking']"},"metadata":{}}]},{"cell_type":"code","source":"%%time\nevaluate_features_auc_poly_df = evaluate_features_auc(poly_df, 'smoking', poly_df.columns.to_list()) # [:,37:255]","metadata":{"execution":{"iopub.status.busy":"2023-10-31T11:10:56.823098Z","iopub.execute_input":"2023-10-31T11:10:56.823550Z","iopub.status.idle":"2023-10-31T11:17:17.496045Z","shell.execute_reply.started":"2023-10-31T11:10:56.823516Z","shell.execute_reply":"2023-10-31T11:17:17.494593Z"},"trusted":true},"execution_count":15,"outputs":[{"name":"stderr","text":"100%|██████████| 861/861 [06:20<00:00,  2.26it/s]","output_type":"stream"},{"name":"stdout","text":"CPU times: user 11min 51s, sys: 3min 15s, total: 15min 6s\nWall time: 6min 20s\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}]},{"cell_type":"code","source":"evaluate_features_auc_poly_df.sort_values(by='auc_scores', ascending=False).iloc[:50,:]","metadata":{"execution":{"iopub.status.busy":"2023-10-31T11:17:17.498117Z","iopub.execute_input":"2023-10-31T11:17:17.498523Z","iopub.status.idle":"2023-10-31T11:17:17.517428Z","shell.execute_reply.started":"2023-10-31T11:17:17.498492Z","shell.execute_reply":"2023-10-31T11:17:17.516371Z"},"trusted":true},"execution_count":16,"outputs":[{"execution_count":16,"output_type":"execute_result","data":{"text/plain":"                                         Feature  auc_scores\n860                                      smoking    1.000000\n422                  triglyceride GTP_to_AST_ALT    0.665334\n423              triglyceride GTP_to_Cholesterol    0.659486\n361           fasting blood sugar GTP_to_AST_ALT    0.659481\n424                       triglyceride GTP_index    0.657468\n626                           Gtp GTP_to_AST_ALT    0.657310\n821        Glucose_to_Cholesterol GTP_to_AST_ALT    0.655941\n855            GTP_to_AST_ALT GTP_to_Cholesterol    0.655747\n829          Triglycerides_to_HDL GTP_to_AST_ALT    0.654313\n851                    GTP_to_age GTP_to_AST_ALT    0.653787\n830      Triglycerides_to_HDL GTP_to_Cholesterol    0.653071\n421                      triglyceride GTP_to_age    0.652289\n506                    hemoglobin GTP_to_AST_ALT    0.651943\n403                             triglyceride Gtp    0.651681\n831               Triglycerides_to_HDL GTP_index    0.651195\n154                    weight(kg) GTP_to_AST_ALT    0.650894\n828              Triglycerides_to_HDL GTP_to_age    0.650633\n507                hemoglobin GTP_to_Cholesterol    0.648758\n191                     waist(cm) GTP_to_AST_ALT    0.647986\n37                                GTP_to_AST_ALT    0.647903\n854                             GTP_to_AST_ALT^2    0.647903\n856                     GTP_to_AST_ALT GTP_index    0.646407\n738            height_nin_110 GTP_to_Cholesterol    0.644753\n329                    relaxation GTP_to_AST_ALT    0.644599\n532                 Urine protein GTP_to_AST_ALT    0.644078\n791      Systolic_Diastolic_ratio GTP_to_AST_ALT    0.643937\n581                           AST GTP_to_AST_ALT    0.643870\n135                               weight(kg) Gtp    0.643581\n752               Average_hearing GTP_to_AST_ALT    0.642760\n116                    height(cm) GTP_to_AST_ALT    0.642519\n852                GTP_to_age GTP_to_Cholesterol    0.642257\n117                height(cm) GTP_to_Cholesterol    0.642247\n857                         GTP_to_Cholesterol^2    0.641975\n38                            GTP_to_Cholesterol    0.641975\n487                               hemoglobin Gtp    0.641901\n647                           BMI GTP_to_AST_ALT    0.641690\n621                     Gtp Triglycerides_to_HDL    0.641418\n792  Systolic_Diastolic_ratio GTP_to_Cholesterol    0.641360\n362       fasting blood sugar GTP_to_Cholesterol    0.641029\n620                   Gtp Glucose_to_Cholesterol    0.641029\n667                Chol_HDL_ratio GTP_to_AST_ALT    0.640990\n737                height_nin_110 GTP_to_AST_ALT    0.640969\n627                       Gtp GTP_to_Cholesterol    0.640074\n613                           Gtp height_nin_110    0.640029\n342                      fasting blood sugar Gtp    0.639858\n668            Chol_HDL_ratio GTP_to_Cholesterol    0.639776\n704                           map GTP_to_AST_ALT    0.639731\n778                           ast_alt GTP_to_age    0.639651\n705                       map GTP_to_Cholesterol    0.639105\n820            Glucose_to_Cholesterol GTP_to_age    0.638878","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Feature</th>\n      <th>auc_scores</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>860</th>\n      <td>smoking</td>\n      <td>1.000000</td>\n    </tr>\n    <tr>\n      <th>422</th>\n      <td>triglyceride GTP_to_AST_ALT</td>\n      <td>0.665334</td>\n    </tr>\n    <tr>\n      <th>423</th>\n      <td>triglyceride GTP_to_Cholesterol</td>\n      <td>0.659486</td>\n    </tr>\n    <tr>\n      <th>361</th>\n      <td>fasting blood sugar GTP_to_AST_ALT</td>\n      <td>0.659481</td>\n    </tr>\n    <tr>\n      <th>424</th>\n      <td>triglyceride GTP_index</td>\n      <td>0.657468</td>\n    </tr>\n    <tr>\n      <th>626</th>\n      <td>Gtp GTP_to_AST_ALT</td>\n      <td>0.657310</td>\n    </tr>\n    <tr>\n      <th>821</th>\n      <td>Glucose_to_Cholesterol GTP_to_AST_ALT</td>\n      <td>0.655941</td>\n    </tr>\n    <tr>\n      <th>855</th>\n      <td>GTP_to_AST_ALT GTP_to_Cholesterol</td>\n      <td>0.655747</td>\n    </tr>\n    <tr>\n      <th>829</th>\n      <td>Triglycerides_to_HDL GTP_to_AST_ALT</td>\n      <td>0.654313</td>\n    </tr>\n    <tr>\n      <th>851</th>\n      <td>GTP_to_age GTP_to_AST_ALT</td>\n      <td>0.653787</td>\n    </tr>\n    <tr>\n      <th>830</th>\n      <td>Triglycerides_to_HDL GTP_to_Cholesterol</td>\n      <td>0.653071</td>\n    </tr>\n    <tr>\n      <th>421</th>\n      <td>triglyceride GTP_to_age</td>\n      <td>0.652289</td>\n    </tr>\n    <tr>\n      <th>506</th>\n      <td>hemoglobin GTP_to_AST_ALT</td>\n      <td>0.651943</td>\n    </tr>\n    <tr>\n      <th>403</th>\n      <td>triglyceride Gtp</td>\n      <td>0.651681</td>\n    </tr>\n    <tr>\n      <th>831</th>\n      <td>Triglycerides_to_HDL GTP_index</td>\n      <td>0.651195</td>\n    </tr>\n    <tr>\n      <th>154</th>\n      <td>weight(kg) GTP_to_AST_ALT</td>\n      <td>0.650894</td>\n    </tr>\n    <tr>\n      <th>828</th>\n      <td>Triglycerides_to_HDL GTP_to_age</td>\n      <td>0.650633</td>\n    </tr>\n    <tr>\n      <th>507</th>\n      <td>hemoglobin GTP_to_Cholesterol</td>\n      <td>0.648758</td>\n    </tr>\n    <tr>\n      <th>191</th>\n      <td>waist(cm) GTP_to_AST_ALT</td>\n      <td>0.647986</td>\n    </tr>\n    <tr>\n      <th>37</th>\n      <td>GTP_to_AST_ALT</td>\n      <td>0.647903</td>\n    </tr>\n    <tr>\n      <th>854</th>\n      <td>GTP_to_AST_ALT^2</td>\n      <td>0.647903</td>\n    </tr>\n    <tr>\n      <th>856</th>\n      <td>GTP_to_AST_ALT GTP_index</td>\n      <td>0.646407</td>\n    </tr>\n    <tr>\n      <th>738</th>\n      <td>height_nin_110 GTP_to_Cholesterol</td>\n      <td>0.644753</td>\n    </tr>\n    <tr>\n      <th>329</th>\n      <td>relaxation GTP_to_AST_ALT</td>\n      <td>0.644599</td>\n    </tr>\n    <tr>\n      <th>532</th>\n      <td>Urine protein GTP_to_AST_ALT</td>\n      <td>0.644078</td>\n    </tr>\n    <tr>\n      <th>791</th>\n      <td>Systolic_Diastolic_ratio GTP_to_AST_ALT</td>\n      <td>0.643937</td>\n    </tr>\n    <tr>\n      <th>581</th>\n      <td>AST GTP_to_AST_ALT</td>\n      <td>0.643870</td>\n    </tr>\n    <tr>\n      <th>135</th>\n      <td>weight(kg) Gtp</td>\n      <td>0.643581</td>\n    </tr>\n    <tr>\n      <th>752</th>\n      <td>Average_hearing GTP_to_AST_ALT</td>\n      <td>0.642760</td>\n    </tr>\n    <tr>\n      <th>116</th>\n      <td>height(cm) GTP_to_AST_ALT</td>\n      <td>0.642519</td>\n    </tr>\n    <tr>\n      <th>852</th>\n      <td>GTP_to_age GTP_to_Cholesterol</td>\n      <td>0.642257</td>\n    </tr>\n    <tr>\n      <th>117</th>\n      <td>height(cm) GTP_to_Cholesterol</td>\n      <td>0.642247</td>\n    </tr>\n    <tr>\n      <th>857</th>\n      <td>GTP_to_Cholesterol^2</td>\n      <td>0.641975</td>\n    </tr>\n    <tr>\n      <th>38</th>\n      <td>GTP_to_Cholesterol</td>\n      <td>0.641975</td>\n    </tr>\n    <tr>\n      <th>487</th>\n      <td>hemoglobin Gtp</td>\n      <td>0.641901</td>\n    </tr>\n    <tr>\n      <th>647</th>\n      <td>BMI GTP_to_AST_ALT</td>\n      <td>0.641690</td>\n    </tr>\n    <tr>\n      <th>621</th>\n      <td>Gtp Triglycerides_to_HDL</td>\n      <td>0.641418</td>\n    </tr>\n    <tr>\n      <th>792</th>\n      <td>Systolic_Diastolic_ratio GTP_to_Cholesterol</td>\n      <td>0.641360</td>\n    </tr>\n    <tr>\n      <th>362</th>\n      <td>fasting blood sugar GTP_to_Cholesterol</td>\n      <td>0.641029</td>\n    </tr>\n    <tr>\n      <th>620</th>\n      <td>Gtp Glucose_to_Cholesterol</td>\n      <td>0.641029</td>\n    </tr>\n    <tr>\n      <th>667</th>\n      <td>Chol_HDL_ratio GTP_to_AST_ALT</td>\n      <td>0.640990</td>\n    </tr>\n    <tr>\n      <th>737</th>\n      <td>height_nin_110 GTP_to_AST_ALT</td>\n      <td>0.640969</td>\n    </tr>\n    <tr>\n      <th>627</th>\n      <td>Gtp GTP_to_Cholesterol</td>\n      <td>0.640074</td>\n    </tr>\n    <tr>\n      <th>613</th>\n      <td>Gtp height_nin_110</td>\n      <td>0.640029</td>\n    </tr>\n    <tr>\n      <th>342</th>\n      <td>fasting blood sugar Gtp</td>\n      <td>0.639858</td>\n    </tr>\n    <tr>\n      <th>668</th>\n      <td>Chol_HDL_ratio GTP_to_Cholesterol</td>\n      <td>0.639776</td>\n    </tr>\n    <tr>\n      <th>704</th>\n      <td>map GTP_to_AST_ALT</td>\n      <td>0.639731</td>\n    </tr>\n    <tr>\n      <th>778</th>\n      <td>ast_alt GTP_to_age</td>\n      <td>0.639651</td>\n    </tr>\n    <tr>\n      <th>705</th>\n      <td>map GTP_to_Cholesterol</td>\n      <td>0.639105</td>\n    </tr>\n    <tr>\n      <th>820</th>\n      <td>Glucose_to_Cholesterol GTP_to_age</td>\n      <td>0.638878</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"evaluate_features_auc_poly_df.to_csv('evaluate_features_auc_poly_df.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2023-10-30T12:48:08.226714Z","iopub.execute_input":"2023-10-30T12:48:08.227085Z","iopub.status.idle":"2023-10-30T12:48:08.239639Z","shell.execute_reply.started":"2023-10-30T12:48:08.227056Z","shell.execute_reply":"2023-10-30T12:48:08.238339Z"},"trusted":true},"execution_count":38,"outputs":[]},{"cell_type":"code","source":"evaluate_features_Gini_poly_df = pd.read_csv(r'/kaggle/input/evaluate-features-gini-poly-df/evaluate_features_Gini_poly_df.csv')","metadata":{"execution":{"iopub.status.busy":"2023-10-29T16:00:37.423412Z","iopub.execute_input":"2023-10-29T16:00:37.424982Z","iopub.status.idle":"2023-10-29T16:00:37.441020Z","shell.execute_reply.started":"2023-10-29T16:00:37.424916Z","shell.execute_reply":"2023-10-29T16:00:37.439749Z"},"trusted":true},"execution_count":42,"outputs":[]},{"cell_type":"code","source":"# Отсортировать датасеты по соответствующим критериям и присвоить ранг каждому признаку\nauc_df_sorted = evaluate_features_auc_poly_df.sort_values(by='auc_scores', ascending=False).reset_index(drop=True)\nauc_df_sorted['auc_rank'] = auc_df_sorted.index + 1\n\ngini_df_sorted = evaluate_features_Gini_poly_df.sort_values(by='Gini_Index', ascending=True).reset_index(drop=True)\ngini_df_sorted['gini_rank'] = gini_df_sorted.index + 1\n\n# Объединить датасеты по признакам\ncombined_df = pd.merge(auc_df_sorted, gini_df_sorted, on='Feature')\n\n# Рассчитать совокупный рейтинг для каждого признака (усреднение рангов)\ncombined_df['combined_rank'] = (combined_df['auc_rank'] + combined_df['gini_rank']) / 2\n\n# Отсортировать признаки по совокупному рейтингу и выбрать топ-50\ntop_50_features = combined_df.sort_values(by='combined_rank').head(50)\n\ntop_50_features\n","metadata":{"execution":{"iopub.status.busy":"2023-10-29T16:01:19.068403Z","iopub.execute_input":"2023-10-29T16:01:19.068834Z","iopub.status.idle":"2023-10-29T16:01:19.120250Z","shell.execute_reply.started":"2023-10-29T16:01:19.068804Z","shell.execute_reply":"2023-10-29T16:01:19.118966Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":43,"outputs":[{"execution_count":43,"output_type":"execute_result","data":{"text/plain":"                                       Feature  auc_scores  auc_rank  \\\n0                  triglyceride GTP_to_AST_ALT    0.654774         2   \n1          Triglycerides_to_HDL GTP_to_AST_ALT    0.653306         3   \n10                   hemoglobin GTP_to_AST_ALT    0.637554        12   \n4                       triglyceride GTP_index    0.642338         6   \n2              triglyceride GTP_to_Cholesterol    0.644721         4   \n12                          Gtp GTP_to_AST_ALT    0.635941        14   \n15                   height(cm) GTP_to_AST_ALT    0.633692        17   \n13           GTP_to_AST_ALT GTP_to_Cholesterol    0.634940        15   \n19                            GTP_to_AST_ALT^2    0.632416        22   \n26               height_nin_110 GTP_to_AST_ALT    0.627545        29   \n3      Triglycerides_to_HDL GTP_to_Cholesterol    0.642956         5   \n14                    waist(cm) GTP_to_AST_ALT    0.634019        16   \n18                   GTP_to_age GTP_to_AST_ALT    0.632495        20   \n6               Triglycerides_to_HDL GTP_index    0.641767         8   \n8                Chol_HDL_ratio GTP_to_AST_ALT    0.638295        10   \n20          fasting blood sugar GTP_to_AST_ALT    0.632356        23   \n23                Urine protein GTP_to_AST_ALT    0.630378        26   \n16           Waist_Height_ratio GTP_to_AST_ALT    0.632725        18   \n5                             triglyceride Gtp    0.642057         7   \n7                     Gtp Triglycerides_to_HDL    0.641564         9   \n17                   weight(kg) GTP_to_AST_ALT    0.632564        19   \n29     Systolic_Diastolic_ratio GTP_to_AST_ALT    0.626900        32   \n27                  Cholesterol GTP_to_AST_ALT    0.627337        30   \n9              Triglycerides_to_HDL GTP_to_age    0.637748        11   \n28                   relaxation GTP_to_AST_ALT    0.627013        31   \n24              Average_hearing GTP_to_AST_ALT    0.629177        27   \n11                     triglyceride GTP_to_age    0.637098        13   \n31                          map GTP_to_AST_ALT    0.626227        34   \n35                     systolic GTP_to_AST_ALT    0.624187        38   \n22                          BMI GTP_to_AST_ALT    0.631454        25   \n30                          AST GTP_to_AST_ALT    0.626703        33   \n36       Glucose_to_Cholesterol GTP_to_AST_ALT    0.624096        39   \n25           Chol_HDL_ratio GTP_to_Cholesterol    0.627699        28   \n32                          Gtp height_nin_110    0.624801        35   \n21      Atherogenic_coefficient GTP_to_AST_ALT    0.631719        24   \n46                                 Gtp ast_alt    0.621132        50   \n34                              hemoglobin Gtp    0.624494        37   \n44               hemoglobin GTP_to_Cholesterol    0.621504        48   \n48           height_nin_110 GTP_to_Cholesterol    0.620977        52   \n38                              height(cm) Gtp    0.622153        41   \n47                    GTP_to_AST_ALT GTP_index    0.621092        51   \n33  Atherogenic_coefficient GTP_to_Cholesterol    0.624654        36   \n41              Cholesterol GTP_to_Cholesterol    0.621628        44   \n45                      Gtp GTP_to_Cholesterol    0.621351        49   \n42                                       Gtp^2    0.621620        45   \n43                              age GTP_to_age    0.621616        47   \n51               height(cm) GTP_to_Cholesterol    0.619685        55   \n37                          Gtp Chol_HDL_ratio    0.623196        40   \n59                        GTP_to_Cholesterol^2    0.618707        63   \n56                              Gtp GTP_to_age    0.618986        60   \n\n    Gini_Index  gini_rank  combined_rank  \n0     0.311241          2            2.0  \n1     0.312005          7            5.0  \n10    0.311536          3            7.5  \n4     0.312307         12            9.0  \n2     0.312640         15            9.5  \n12    0.312002          6           10.0  \n15    0.311771          4           10.5  \n13    0.312131          8           11.5  \n19    0.311794          5           13.5  \n26    0.311030          1           15.0  \n3     0.313111         26           15.5  \n14    0.312684         16           16.0  \n18    0.312512         13           16.5  \n6     0.313104         25           16.5  \n8     0.312974         24           17.0  \n20    0.312213         11           17.0  \n23    0.312189          9           17.5  \n16    0.312757         17           17.5  \n5     0.313299         29           18.0  \n7     0.313359         30           19.5  \n17    0.312924         21           20.0  \n29    0.312212         10           21.0  \n27    0.312624         14           22.0  \n9     0.313577         35           23.0  \n28    0.312789         18           24.5  \n24    0.312939         23           25.0  \n11    0.313631         37           25.0  \n31    0.312881         20           27.0  \n35    0.312833         19           28.5  \n22    0.313445         33           29.0  \n30    0.313228         27           30.0  \n36    0.312928         22           30.5  \n25    0.313963         42           35.0  \n32    0.313588         36           35.5  \n21    0.314122         49           36.5  \n46    0.313229         28           39.0  \n34    0.313856         41           39.0  \n44    0.313361         31           39.5  \n48    0.313461         34           43.0  \n38    0.314023         46           43.5  \n47    0.313658         38           44.5  \n33    0.314320         53           44.5  \n41    0.314388         54           49.0  \n45    0.314135         50           49.5  \n42    0.314433         56           50.5  \n43    0.314433         55           51.0  \n51    0.314101         47           51.0  \n37    0.314662         67           53.5  \n59    0.314105         48           55.5  \n56    0.314188         51           55.5  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Feature</th>\n      <th>auc_scores</th>\n      <th>auc_rank</th>\n      <th>Gini_Index</th>\n      <th>gini_rank</th>\n      <th>combined_rank</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>triglyceride GTP_to_AST_ALT</td>\n      <td>0.654774</td>\n      <td>2</td>\n      <td>0.311241</td>\n      <td>2</td>\n      <td>2.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Triglycerides_to_HDL GTP_to_AST_ALT</td>\n      <td>0.653306</td>\n      <td>3</td>\n      <td>0.312005</td>\n      <td>7</td>\n      <td>5.0</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>hemoglobin GTP_to_AST_ALT</td>\n      <td>0.637554</td>\n      <td>12</td>\n      <td>0.311536</td>\n      <td>3</td>\n      <td>7.5</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>triglyceride GTP_index</td>\n      <td>0.642338</td>\n      <td>6</td>\n      <td>0.312307</td>\n      <td>12</td>\n      <td>9.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>triglyceride GTP_to_Cholesterol</td>\n      <td>0.644721</td>\n      <td>4</td>\n      <td>0.312640</td>\n      <td>15</td>\n      <td>9.5</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>Gtp GTP_to_AST_ALT</td>\n      <td>0.635941</td>\n      <td>14</td>\n      <td>0.312002</td>\n      <td>6</td>\n      <td>10.0</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>height(cm) GTP_to_AST_ALT</td>\n      <td>0.633692</td>\n      <td>17</td>\n      <td>0.311771</td>\n      <td>4</td>\n      <td>10.5</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>GTP_to_AST_ALT GTP_to_Cholesterol</td>\n      <td>0.634940</td>\n      <td>15</td>\n      <td>0.312131</td>\n      <td>8</td>\n      <td>11.5</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>GTP_to_AST_ALT^2</td>\n      <td>0.632416</td>\n      <td>22</td>\n      <td>0.311794</td>\n      <td>5</td>\n      <td>13.5</td>\n    </tr>\n    <tr>\n      <th>26</th>\n      <td>height_nin_110 GTP_to_AST_ALT</td>\n      <td>0.627545</td>\n      <td>29</td>\n      <td>0.311030</td>\n      <td>1</td>\n      <td>15.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Triglycerides_to_HDL GTP_to_Cholesterol</td>\n      <td>0.642956</td>\n      <td>5</td>\n      <td>0.313111</td>\n      <td>26</td>\n      <td>15.5</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>waist(cm) GTP_to_AST_ALT</td>\n      <td>0.634019</td>\n      <td>16</td>\n      <td>0.312684</td>\n      <td>16</td>\n      <td>16.0</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>GTP_to_age GTP_to_AST_ALT</td>\n      <td>0.632495</td>\n      <td>20</td>\n      <td>0.312512</td>\n      <td>13</td>\n      <td>16.5</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>Triglycerides_to_HDL GTP_index</td>\n      <td>0.641767</td>\n      <td>8</td>\n      <td>0.313104</td>\n      <td>25</td>\n      <td>16.5</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>Chol_HDL_ratio GTP_to_AST_ALT</td>\n      <td>0.638295</td>\n      <td>10</td>\n      <td>0.312974</td>\n      <td>24</td>\n      <td>17.0</td>\n    </tr>\n    <tr>\n      <th>20</th>\n      <td>fasting blood sugar GTP_to_AST_ALT</td>\n      <td>0.632356</td>\n      <td>23</td>\n      <td>0.312213</td>\n      <td>11</td>\n      <td>17.0</td>\n    </tr>\n    <tr>\n      <th>23</th>\n      <td>Urine protein GTP_to_AST_ALT</td>\n      <td>0.630378</td>\n      <td>26</td>\n      <td>0.312189</td>\n      <td>9</td>\n      <td>17.5</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>Waist_Height_ratio GTP_to_AST_ALT</td>\n      <td>0.632725</td>\n      <td>18</td>\n      <td>0.312757</td>\n      <td>17</td>\n      <td>17.5</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>triglyceride Gtp</td>\n      <td>0.642057</td>\n      <td>7</td>\n      <td>0.313299</td>\n      <td>29</td>\n      <td>18.0</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>Gtp Triglycerides_to_HDL</td>\n      <td>0.641564</td>\n      <td>9</td>\n      <td>0.313359</td>\n      <td>30</td>\n      <td>19.5</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>weight(kg) GTP_to_AST_ALT</td>\n      <td>0.632564</td>\n      <td>19</td>\n      <td>0.312924</td>\n      <td>21</td>\n      <td>20.0</td>\n    </tr>\n    <tr>\n      <th>29</th>\n      <td>Systolic_Diastolic_ratio GTP_to_AST_ALT</td>\n      <td>0.626900</td>\n      <td>32</td>\n      <td>0.312212</td>\n      <td>10</td>\n      <td>21.0</td>\n    </tr>\n    <tr>\n      <th>27</th>\n      <td>Cholesterol GTP_to_AST_ALT</td>\n      <td>0.627337</td>\n      <td>30</td>\n      <td>0.312624</td>\n      <td>14</td>\n      <td>22.0</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>Triglycerides_to_HDL GTP_to_age</td>\n      <td>0.637748</td>\n      <td>11</td>\n      <td>0.313577</td>\n      <td>35</td>\n      <td>23.0</td>\n    </tr>\n    <tr>\n      <th>28</th>\n      <td>relaxation GTP_to_AST_ALT</td>\n      <td>0.627013</td>\n      <td>31</td>\n      <td>0.312789</td>\n      <td>18</td>\n      <td>24.5</td>\n    </tr>\n    <tr>\n      <th>24</th>\n      <td>Average_hearing GTP_to_AST_ALT</td>\n      <td>0.629177</td>\n      <td>27</td>\n      <td>0.312939</td>\n      <td>23</td>\n      <td>25.0</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>triglyceride GTP_to_age</td>\n      <td>0.637098</td>\n      <td>13</td>\n      <td>0.313631</td>\n      <td>37</td>\n      <td>25.0</td>\n    </tr>\n    <tr>\n      <th>31</th>\n      <td>map GTP_to_AST_ALT</td>\n      <td>0.626227</td>\n      <td>34</td>\n      <td>0.312881</td>\n      <td>20</td>\n      <td>27.0</td>\n    </tr>\n    <tr>\n      <th>35</th>\n      <td>systolic GTP_to_AST_ALT</td>\n      <td>0.624187</td>\n      <td>38</td>\n      <td>0.312833</td>\n      <td>19</td>\n      <td>28.5</td>\n    </tr>\n    <tr>\n      <th>22</th>\n      <td>BMI GTP_to_AST_ALT</td>\n      <td>0.631454</td>\n      <td>25</td>\n      <td>0.313445</td>\n      <td>33</td>\n      <td>29.0</td>\n    </tr>\n    <tr>\n      <th>30</th>\n      <td>AST GTP_to_AST_ALT</td>\n      <td>0.626703</td>\n      <td>33</td>\n      <td>0.313228</td>\n      <td>27</td>\n      <td>30.0</td>\n    </tr>\n    <tr>\n      <th>36</th>\n      <td>Glucose_to_Cholesterol GTP_to_AST_ALT</td>\n      <td>0.624096</td>\n      <td>39</td>\n      <td>0.312928</td>\n      <td>22</td>\n      <td>30.5</td>\n    </tr>\n    <tr>\n      <th>25</th>\n      <td>Chol_HDL_ratio GTP_to_Cholesterol</td>\n      <td>0.627699</td>\n      <td>28</td>\n      <td>0.313963</td>\n      <td>42</td>\n      <td>35.0</td>\n    </tr>\n    <tr>\n      <th>32</th>\n      <td>Gtp height_nin_110</td>\n      <td>0.624801</td>\n      <td>35</td>\n      <td>0.313588</td>\n      <td>36</td>\n      <td>35.5</td>\n    </tr>\n    <tr>\n      <th>21</th>\n      <td>Atherogenic_coefficient GTP_to_AST_ALT</td>\n      <td>0.631719</td>\n      <td>24</td>\n      <td>0.314122</td>\n      <td>49</td>\n      <td>36.5</td>\n    </tr>\n    <tr>\n      <th>46</th>\n      <td>Gtp ast_alt</td>\n      <td>0.621132</td>\n      <td>50</td>\n      <td>0.313229</td>\n      <td>28</td>\n      <td>39.0</td>\n    </tr>\n    <tr>\n      <th>34</th>\n      <td>hemoglobin Gtp</td>\n      <td>0.624494</td>\n      <td>37</td>\n      <td>0.313856</td>\n      <td>41</td>\n      <td>39.0</td>\n    </tr>\n    <tr>\n      <th>44</th>\n      <td>hemoglobin GTP_to_Cholesterol</td>\n      <td>0.621504</td>\n      <td>48</td>\n      <td>0.313361</td>\n      <td>31</td>\n      <td>39.5</td>\n    </tr>\n    <tr>\n      <th>48</th>\n      <td>height_nin_110 GTP_to_Cholesterol</td>\n      <td>0.620977</td>\n      <td>52</td>\n      <td>0.313461</td>\n      <td>34</td>\n      <td>43.0</td>\n    </tr>\n    <tr>\n      <th>38</th>\n      <td>height(cm) Gtp</td>\n      <td>0.622153</td>\n      <td>41</td>\n      <td>0.314023</td>\n      <td>46</td>\n      <td>43.5</td>\n    </tr>\n    <tr>\n      <th>47</th>\n      <td>GTP_to_AST_ALT GTP_index</td>\n      <td>0.621092</td>\n      <td>51</td>\n      <td>0.313658</td>\n      <td>38</td>\n      <td>44.5</td>\n    </tr>\n    <tr>\n      <th>33</th>\n      <td>Atherogenic_coefficient GTP_to_Cholesterol</td>\n      <td>0.624654</td>\n      <td>36</td>\n      <td>0.314320</td>\n      <td>53</td>\n      <td>44.5</td>\n    </tr>\n    <tr>\n      <th>41</th>\n      <td>Cholesterol GTP_to_Cholesterol</td>\n      <td>0.621628</td>\n      <td>44</td>\n      <td>0.314388</td>\n      <td>54</td>\n      <td>49.0</td>\n    </tr>\n    <tr>\n      <th>45</th>\n      <td>Gtp GTP_to_Cholesterol</td>\n      <td>0.621351</td>\n      <td>49</td>\n      <td>0.314135</td>\n      <td>50</td>\n      <td>49.5</td>\n    </tr>\n    <tr>\n      <th>42</th>\n      <td>Gtp^2</td>\n      <td>0.621620</td>\n      <td>45</td>\n      <td>0.314433</td>\n      <td>56</td>\n      <td>50.5</td>\n    </tr>\n    <tr>\n      <th>43</th>\n      <td>age GTP_to_age</td>\n      <td>0.621616</td>\n      <td>47</td>\n      <td>0.314433</td>\n      <td>55</td>\n      <td>51.0</td>\n    </tr>\n    <tr>\n      <th>51</th>\n      <td>height(cm) GTP_to_Cholesterol</td>\n      <td>0.619685</td>\n      <td>55</td>\n      <td>0.314101</td>\n      <td>47</td>\n      <td>51.0</td>\n    </tr>\n    <tr>\n      <th>37</th>\n      <td>Gtp Chol_HDL_ratio</td>\n      <td>0.623196</td>\n      <td>40</td>\n      <td>0.314662</td>\n      <td>67</td>\n      <td>53.5</td>\n    </tr>\n    <tr>\n      <th>59</th>\n      <td>GTP_to_Cholesterol^2</td>\n      <td>0.618707</td>\n      <td>63</td>\n      <td>0.314105</td>\n      <td>48</td>\n      <td>55.5</td>\n    </tr>\n    <tr>\n      <th>56</th>\n      <td>Gtp GTP_to_age</td>\n      <td>0.618986</td>\n      <td>60</td>\n      <td>0.314188</td>\n      <td>51</td>\n      <td>55.5</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"top_50_features['Feature'].to_list()","metadata":{"execution":{"iopub.status.busy":"2023-10-29T16:06:49.350257Z","iopub.execute_input":"2023-10-29T16:06:49.351558Z","iopub.status.idle":"2023-10-29T16:06:49.362072Z","shell.execute_reply.started":"2023-10-29T16:06:49.351487Z","shell.execute_reply":"2023-10-29T16:06:49.360875Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":44,"outputs":[{"execution_count":44,"output_type":"execute_result","data":{"text/plain":"['triglyceride GTP_to_AST_ALT',\n 'Triglycerides_to_HDL GTP_to_AST_ALT',\n 'hemoglobin GTP_to_AST_ALT',\n 'triglyceride GTP_index',\n 'triglyceride GTP_to_Cholesterol',\n 'Gtp GTP_to_AST_ALT',\n 'height(cm) GTP_to_AST_ALT',\n 'GTP_to_AST_ALT GTP_to_Cholesterol',\n 'GTP_to_AST_ALT^2',\n 'height_nin_110 GTP_to_AST_ALT',\n 'Triglycerides_to_HDL GTP_to_Cholesterol',\n 'waist(cm) GTP_to_AST_ALT',\n 'GTP_to_age GTP_to_AST_ALT',\n 'Triglycerides_to_HDL GTP_index',\n 'Chol_HDL_ratio GTP_to_AST_ALT',\n 'fasting blood sugar GTP_to_AST_ALT',\n 'Urine protein GTP_to_AST_ALT',\n 'Waist_Height_ratio GTP_to_AST_ALT',\n 'triglyceride Gtp',\n 'Gtp Triglycerides_to_HDL',\n 'weight(kg) GTP_to_AST_ALT',\n 'Systolic_Diastolic_ratio GTP_to_AST_ALT',\n 'Cholesterol GTP_to_AST_ALT',\n 'Triglycerides_to_HDL GTP_to_age',\n 'relaxation GTP_to_AST_ALT',\n 'Average_hearing GTP_to_AST_ALT',\n 'triglyceride GTP_to_age',\n 'map GTP_to_AST_ALT',\n 'systolic GTP_to_AST_ALT',\n 'BMI GTP_to_AST_ALT',\n 'AST GTP_to_AST_ALT',\n 'Glucose_to_Cholesterol GTP_to_AST_ALT',\n 'Chol_HDL_ratio GTP_to_Cholesterol',\n 'Gtp height_nin_110',\n 'Atherogenic_coefficient GTP_to_AST_ALT',\n 'Gtp ast_alt',\n 'hemoglobin Gtp',\n 'hemoglobin GTP_to_Cholesterol',\n 'height_nin_110 GTP_to_Cholesterol',\n 'height(cm) Gtp',\n 'GTP_to_AST_ALT GTP_index',\n 'Atherogenic_coefficient GTP_to_Cholesterol',\n 'Cholesterol GTP_to_Cholesterol',\n 'Gtp GTP_to_Cholesterol',\n 'Gtp^2',\n 'age GTP_to_age',\n 'height(cm) GTP_to_Cholesterol',\n 'Gtp Chol_HDL_ratio',\n 'GTP_to_Cholesterol^2',\n 'Gtp GTP_to_age']"},"metadata":{}}]},{"cell_type":"code","source":"evaluate_features_auc_poly_df.sort_values(by='auc_scores', ascending=False).iloc[1:50,:]['Feature'].to_list()","metadata":{"execution":{"iopub.status.busy":"2023-10-29T16:40:06.156147Z","iopub.execute_input":"2023-10-29T16:40:06.156632Z","iopub.status.idle":"2023-10-29T16:40:06.169781Z","shell.execute_reply.started":"2023-10-29T16:40:06.156595Z","shell.execute_reply":"2023-10-29T16:40:06.168260Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":73,"outputs":[{"execution_count":73,"output_type":"execute_result","data":{"text/plain":"['triglyceride GTP_to_AST_ALT',\n 'Triglycerides_to_HDL GTP_to_AST_ALT',\n 'triglyceride GTP_to_Cholesterol',\n 'Triglycerides_to_HDL GTP_to_Cholesterol',\n 'triglyceride GTP_index',\n 'triglyceride Gtp',\n 'Triglycerides_to_HDL GTP_index',\n 'Gtp Triglycerides_to_HDL',\n 'Chol_HDL_ratio GTP_to_AST_ALT',\n 'Triglycerides_to_HDL GTP_to_age',\n 'hemoglobin GTP_to_AST_ALT',\n 'triglyceride GTP_to_age',\n 'Gtp GTP_to_AST_ALT',\n 'GTP_to_AST_ALT GTP_to_Cholesterol',\n 'waist(cm) GTP_to_AST_ALT',\n 'height(cm) GTP_to_AST_ALT',\n 'Waist_Height_ratio GTP_to_AST_ALT',\n 'weight(kg) GTP_to_AST_ALT',\n 'GTP_to_age GTP_to_AST_ALT',\n 'GTP_to_AST_ALT',\n 'GTP_to_AST_ALT^2',\n 'fasting blood sugar GTP_to_AST_ALT',\n 'Atherogenic_coefficient GTP_to_AST_ALT',\n 'BMI GTP_to_AST_ALT',\n 'Urine protein GTP_to_AST_ALT',\n 'Average_hearing GTP_to_AST_ALT',\n 'Chol_HDL_ratio GTP_to_Cholesterol',\n 'height_nin_110 GTP_to_AST_ALT',\n 'Cholesterol GTP_to_AST_ALT',\n 'relaxation GTP_to_AST_ALT',\n 'Systolic_Diastolic_ratio GTP_to_AST_ALT',\n 'AST GTP_to_AST_ALT',\n 'map GTP_to_AST_ALT',\n 'Gtp height_nin_110',\n 'Atherogenic_coefficient GTP_to_Cholesterol',\n 'hemoglobin Gtp',\n 'systolic GTP_to_AST_ALT',\n 'Glucose_to_Cholesterol GTP_to_AST_ALT',\n 'Gtp Chol_HDL_ratio',\n 'height(cm) Gtp',\n 'triglyceride hemoglobin',\n 'triglyceride height_nin_110',\n 'Cholesterol GTP_to_Cholesterol',\n 'Gtp^2',\n 'Gtp',\n 'age GTP_to_age',\n 'hemoglobin GTP_to_Cholesterol',\n 'Gtp GTP_to_Cholesterol',\n 'Gtp ast_alt']"},"metadata":{}}]},{"cell_type":"code","source":"for feat in evaluate_features_auc_poly_df.sort_values(by='auc_scores', ascending=False).iloc[1:55,:]['Feature'].to_list():\n    merged_data[feat] = poly_df[feat]","metadata":{"execution":{"iopub.status.busy":"2023-10-31T11:23:38.962611Z","iopub.execute_input":"2023-10-31T11:23:38.963044Z","iopub.status.idle":"2023-10-31T11:23:39.001828Z","shell.execute_reply.started":"2023-10-31T11:23:38.963010Z","shell.execute_reply":"2023-10-31T11:23:39.000757Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"merged_data#.iloc[:,:45]","metadata":{"execution":{"iopub.status.busy":"2023-10-31T11:23:40.141789Z","iopub.execute_input":"2023-10-31T11:23:40.142197Z","iopub.status.idle":"2023-10-31T11:23:40.189549Z","shell.execute_reply.started":"2023-10-31T11:23:40.142166Z","shell.execute_reply":"2023-10-31T11:23:40.188393Z"},"trusted":true},"execution_count":18,"outputs":[{"execution_count":18,"output_type":"execute_result","data":{"text/plain":"       age  height(cm)  weight(kg)  waist(cm)  eyesight(left)  \\\n0       65         170          75       91.0             0.6   \n1       35         170          85       97.0             1.5   \n2       70         165          55       75.0             0.8   \n3       35         180          85       83.0             1.2   \n4       25         170          65       80.0             1.5   \n...    ...         ...         ...        ...             ...   \n13858   45         175          85       94.0             0.8   \n13859   40         170          75       86.0             1.2   \n13860   65         170          70       85.0             0.6   \n13861   30         160          80       89.0             1.5   \n13862   60         170          70       86.0             1.5   \n\n       eyesight(right)  hearing(left)  hearing(right)  systolic  relaxation  \\\n0                  0.9            1.0             1.0     122.0        79.0   \n1                  1.5            1.0             1.0     138.0        88.0   \n2                  1.0            1.0             1.0     115.0        63.0   \n3                  1.0            1.0             1.0     130.0        80.0   \n4                  1.2            1.0             1.0     135.0        75.0   \n...                ...            ...             ...       ...         ...   \n13858              0.8            1.0             1.0     127.0        71.0   \n13859              1.0            1.0             1.0     134.0        88.0   \n13860              0.7            1.0             1.0     131.0        82.0   \n13861              1.5            1.0             1.0     120.0        80.0   \n13862              1.5            1.0             1.0     135.0        85.0   \n\n       ...  Chol_HDL_ratio GTP_to_Cholesterol  map GTP_to_AST_ALT  \\\n0      ...                           1.718310          316.296296   \n1      ...                           0.869565           93.037037   \n2      ...                           0.279412           54.511905   \n3      ...                           0.320755           41.083333   \n4      ...                           0.241379           40.303030   \n...    ...                                ...                 ...   \n13858  ...                           0.387755           50.107843   \n13859  ...                           0.580645          137.777778   \n13860  ...                           0.510638          118.000000   \n13861  ...                           0.632653           47.431694   \n13862  ...                           0.581818           23.073286   \n\n       ast_alt GTP_to_age  map GTP_to_Cholesterol  \\\n0                2.346154               95.686275   \n1                0.914286               20.522876   \n2                0.313187                9.250505   \n3                0.593651                7.862839   \n4                0.861538                8.692810   \n...                   ...                     ...   \n13858            0.422222                6.842035   \n13859            1.125000               15.060729   \n13860            0.553846               13.111111   \n13861            0.767619               16.821705   \n13862            0.351373               20.461216   \n\n       Glucose_to_Cholesterol GTP_to_age  Diastolic_to_age GTP_to_AST_ALT  \\\n0                               1.687654                         4.118803   \n1                               0.655462                         2.234921   \n2                               0.210563                         0.610714   \n3                               0.232399                         0.971429   \n4                               0.344052                         1.272727   \n...                                  ...                              ...   \n13858                           0.167871                         0.881699   \n13859                           0.353441                         2.933333   \n13860                           0.203077                         1.513846   \n13861                           0.552713                         1.355191   \n13862                           0.301887                         0.321513   \n\n       weight(kg) GTP_to_Cholesterol  fasting blood sugar GTP_to_age  \\\n0                          76.890756                      200.830769   \n1                          16.666667                      133.714286   \n2                           6.333333                       34.742857   \n3                           6.913876                       48.571429   \n4                           5.947712                       52.640000   \n...                              ...                             ...   \n13858                       6.485944                       41.800000   \n13859                      10.931174                       87.300000   \n13860                       9.333333                       36.553846   \n13861                      14.418605                       95.066667   \n13862                      14.088050                       48.000000   \n\n       age GTP_to_age  Cholesterol GTP_to_Cholesterol  \n0               122.0                           122.0  \n1                40.0                            40.0  \n2                19.0                            19.0  \n3                17.0                            17.0  \n4                14.0                            14.0  \n...               ...                             ...  \n13858            19.0                            19.0  \n13859            36.0                            36.0  \n13860            24.0                            24.0  \n13861            31.0                            31.0  \n13862            32.0                            32.0  \n\n[13863 rows x 97 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>age</th>\n      <th>height(cm)</th>\n      <th>weight(kg)</th>\n      <th>waist(cm)</th>\n      <th>eyesight(left)</th>\n      <th>eyesight(right)</th>\n      <th>hearing(left)</th>\n      <th>hearing(right)</th>\n      <th>systolic</th>\n      <th>relaxation</th>\n      <th>...</th>\n      <th>Chol_HDL_ratio GTP_to_Cholesterol</th>\n      <th>map GTP_to_AST_ALT</th>\n      <th>ast_alt GTP_to_age</th>\n      <th>map GTP_to_Cholesterol</th>\n      <th>Glucose_to_Cholesterol GTP_to_age</th>\n      <th>Diastolic_to_age GTP_to_AST_ALT</th>\n      <th>weight(kg) GTP_to_Cholesterol</th>\n      <th>fasting blood sugar GTP_to_age</th>\n      <th>age GTP_to_age</th>\n      <th>Cholesterol GTP_to_Cholesterol</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>65</td>\n      <td>170</td>\n      <td>75</td>\n      <td>91.0</td>\n      <td>0.6</td>\n      <td>0.9</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>122.0</td>\n      <td>79.0</td>\n      <td>...</td>\n      <td>1.718310</td>\n      <td>316.296296</td>\n      <td>2.346154</td>\n      <td>95.686275</td>\n      <td>1.687654</td>\n      <td>4.118803</td>\n      <td>76.890756</td>\n      <td>200.830769</td>\n      <td>122.0</td>\n      <td>122.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>35</td>\n      <td>170</td>\n      <td>85</td>\n      <td>97.0</td>\n      <td>1.5</td>\n      <td>1.5</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>138.0</td>\n      <td>88.0</td>\n      <td>...</td>\n      <td>0.869565</td>\n      <td>93.037037</td>\n      <td>0.914286</td>\n      <td>20.522876</td>\n      <td>0.655462</td>\n      <td>2.234921</td>\n      <td>16.666667</td>\n      <td>133.714286</td>\n      <td>40.0</td>\n      <td>40.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>70</td>\n      <td>165</td>\n      <td>55</td>\n      <td>75.0</td>\n      <td>0.8</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>115.0</td>\n      <td>63.0</td>\n      <td>...</td>\n      <td>0.279412</td>\n      <td>54.511905</td>\n      <td>0.313187</td>\n      <td>9.250505</td>\n      <td>0.210563</td>\n      <td>0.610714</td>\n      <td>6.333333</td>\n      <td>34.742857</td>\n      <td>19.0</td>\n      <td>19.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>35</td>\n      <td>180</td>\n      <td>85</td>\n      <td>83.0</td>\n      <td>1.2</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>130.0</td>\n      <td>80.0</td>\n      <td>...</td>\n      <td>0.320755</td>\n      <td>41.083333</td>\n      <td>0.593651</td>\n      <td>7.862839</td>\n      <td>0.232399</td>\n      <td>0.971429</td>\n      <td>6.913876</td>\n      <td>48.571429</td>\n      <td>17.0</td>\n      <td>17.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>25</td>\n      <td>170</td>\n      <td>65</td>\n      <td>80.0</td>\n      <td>1.5</td>\n      <td>1.2</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>135.0</td>\n      <td>75.0</td>\n      <td>...</td>\n      <td>0.241379</td>\n      <td>40.303030</td>\n      <td>0.861538</td>\n      <td>8.692810</td>\n      <td>0.344052</td>\n      <td>1.272727</td>\n      <td>5.947712</td>\n      <td>52.640000</td>\n      <td>14.0</td>\n      <td>14.0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>13858</th>\n      <td>45</td>\n      <td>175</td>\n      <td>85</td>\n      <td>94.0</td>\n      <td>0.8</td>\n      <td>0.8</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>127.0</td>\n      <td>71.0</td>\n      <td>...</td>\n      <td>0.387755</td>\n      <td>50.107843</td>\n      <td>0.422222</td>\n      <td>6.842035</td>\n      <td>0.167871</td>\n      <td>0.881699</td>\n      <td>6.485944</td>\n      <td>41.800000</td>\n      <td>19.0</td>\n      <td>19.0</td>\n    </tr>\n    <tr>\n      <th>13859</th>\n      <td>40</td>\n      <td>170</td>\n      <td>75</td>\n      <td>86.0</td>\n      <td>1.2</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>134.0</td>\n      <td>88.0</td>\n      <td>...</td>\n      <td>0.580645</td>\n      <td>137.777778</td>\n      <td>1.125000</td>\n      <td>15.060729</td>\n      <td>0.353441</td>\n      <td>2.933333</td>\n      <td>10.931174</td>\n      <td>87.300000</td>\n      <td>36.0</td>\n      <td>36.0</td>\n    </tr>\n    <tr>\n      <th>13860</th>\n      <td>65</td>\n      <td>170</td>\n      <td>70</td>\n      <td>85.0</td>\n      <td>0.6</td>\n      <td>0.7</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>131.0</td>\n      <td>82.0</td>\n      <td>...</td>\n      <td>0.510638</td>\n      <td>118.000000</td>\n      <td>0.553846</td>\n      <td>13.111111</td>\n      <td>0.203077</td>\n      <td>1.513846</td>\n      <td>9.333333</td>\n      <td>36.553846</td>\n      <td>24.0</td>\n      <td>24.0</td>\n    </tr>\n    <tr>\n      <th>13861</th>\n      <td>30</td>\n      <td>160</td>\n      <td>80</td>\n      <td>89.0</td>\n      <td>1.5</td>\n      <td>1.5</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>120.0</td>\n      <td>80.0</td>\n      <td>...</td>\n      <td>0.632653</td>\n      <td>47.431694</td>\n      <td>0.767619</td>\n      <td>16.821705</td>\n      <td>0.552713</td>\n      <td>1.355191</td>\n      <td>14.418605</td>\n      <td>95.066667</td>\n      <td>31.0</td>\n      <td>31.0</td>\n    </tr>\n    <tr>\n      <th>13862</th>\n      <td>60</td>\n      <td>170</td>\n      <td>70</td>\n      <td>86.0</td>\n      <td>1.5</td>\n      <td>1.5</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>135.0</td>\n      <td>85.0</td>\n      <td>...</td>\n      <td>0.581818</td>\n      <td>23.073286</td>\n      <td>0.351373</td>\n      <td>20.461216</td>\n      <td>0.301887</td>\n      <td>0.321513</td>\n      <td>14.088050</td>\n      <td>48.000000</td>\n      <td>32.0</td>\n      <td>32.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>13863 rows × 97 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"poly_df.iloc[:,:100]","metadata":{"execution":{"iopub.status.busy":"2023-10-30T15:12:33.483258Z","iopub.execute_input":"2023-10-30T15:12:33.484394Z","iopub.status.idle":"2023-10-30T15:12:33.569209Z","shell.execute_reply.started":"2023-10-30T15:12:33.484352Z","shell.execute_reply":"2023-10-30T15:12:33.568028Z"},"trusted":true},"execution_count":134,"outputs":[{"execution_count":134,"output_type":"execute_result","data":{"text/plain":"        age  height(cm)  weight(kg)  waist(cm)  eyesight(left)  \\\n0      65.0       170.0        75.0       91.0             0.6   \n1      35.0       170.0        85.0       97.0             1.5   \n2      70.0       165.0        55.0       75.0             0.8   \n3      35.0       180.0        85.0       83.0             1.2   \n4      25.0       170.0        65.0       80.0             1.5   \n...     ...         ...         ...        ...             ...   \n13858  45.0       175.0        85.0       94.0             0.8   \n13859  40.0       170.0        75.0       86.0             1.2   \n13860  65.0       170.0        70.0       85.0             0.6   \n13861  30.0       160.0        80.0       89.0             1.5   \n13862  60.0       170.0        70.0       86.0             1.5   \n\n       eyesight(right)  systolic  relaxation  fasting blood sugar  \\\n0                  0.9     122.0        79.0                107.0   \n1                  1.5     138.0        88.0                117.0   \n2                  1.0     115.0        63.0                128.0   \n3                  1.0     130.0        80.0                100.0   \n4                  1.2     135.0        75.0                 94.0   \n...                ...       ...         ...                  ...   \n13858              0.8     127.0        71.0                 99.0   \n13859              1.0     134.0        88.0                 97.0   \n13860              0.7     131.0        82.0                 99.0   \n13861              1.5     120.0        80.0                 92.0   \n13862              1.5     135.0        85.0                 90.0   \n\n       Cholesterol  ...  height(cm) HDL  height(cm) LDL  \\\n0            119.0  ...         12070.0          8840.0   \n1            204.0  ...          7820.0         20400.0   \n2            165.0  ...         11220.0         14025.0   \n3            209.0  ...          9540.0         22500.0   \n4            153.0  ...          9860.0         13600.0   \n...            ...  ...             ...             ...   \n13858        249.0  ...          8575.0         28700.0   \n13859        247.0  ...         10540.0         25160.0   \n13860        180.0  ...          7990.0         19550.0   \n13861        172.0  ...          7840.0         15360.0   \n13862        159.0  ...          9350.0         15300.0   \n\n       height(cm) hemoglobin  height(cm) Urine protein  \\\n0                     2380.0                     510.0   \n1                     2482.0                     170.0   \n2                     2425.5                     165.0   \n3                     3096.0                     180.0   \n4                     2805.0                     170.0   \n...                      ...                       ...   \n13858                 2870.0                     175.0   \n13859                 2839.0                     170.0   \n13860                 2669.0                     170.0   \n13861                 2368.0                     160.0   \n13862                 2533.0                     170.0   \n\n       height(cm) serum creatinine  height(cm) AST  height(cm) ALT  \\\n0                            204.0          3400.0          2720.0   \n1                            119.0          3400.0          4250.0   \n2                            115.5          2475.0          2145.0   \n3                            144.0          3960.0          3240.0   \n4                            170.0          3400.0          2210.0   \n...                            ...             ...             ...   \n13858                        157.5          2975.0          2975.0   \n13859                        153.0          2550.0          2040.0   \n13860                        136.0          2040.0          1360.0   \n13861                        128.0          4160.0          5600.0   \n13862                        170.0          9520.0         14450.0   \n\n       height(cm) Gtp  height(cm) BMI  height(cm) Chol_HDL_ratio  \n0             20740.0     4411.764706                 284.929577  \n1              6800.0     5000.000000                 753.913043  \n2              3135.0     3333.333333                 400.367647  \n3              3060.0     4722.222222                 709.811321  \n4              2380.0     3823.529412                 448.448276  \n...               ...             ...                        ...  \n13858          3325.0     4857.142857                 889.285714  \n13859          6120.0     4411.764706                 677.258065  \n13860          4080.0     4117.647059                 651.063830  \n13861          4960.0     5000.000000                 561.632653  \n13862          5440.0     4117.647059                 491.454545  \n\n[13863 rows x 100 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>age</th>\n      <th>height(cm)</th>\n      <th>weight(kg)</th>\n      <th>waist(cm)</th>\n      <th>eyesight(left)</th>\n      <th>eyesight(right)</th>\n      <th>systolic</th>\n      <th>relaxation</th>\n      <th>fasting blood sugar</th>\n      <th>Cholesterol</th>\n      <th>...</th>\n      <th>height(cm) HDL</th>\n      <th>height(cm) LDL</th>\n      <th>height(cm) hemoglobin</th>\n      <th>height(cm) Urine protein</th>\n      <th>height(cm) serum creatinine</th>\n      <th>height(cm) AST</th>\n      <th>height(cm) ALT</th>\n      <th>height(cm) Gtp</th>\n      <th>height(cm) BMI</th>\n      <th>height(cm) Chol_HDL_ratio</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>65.0</td>\n      <td>170.0</td>\n      <td>75.0</td>\n      <td>91.0</td>\n      <td>0.6</td>\n      <td>0.9</td>\n      <td>122.0</td>\n      <td>79.0</td>\n      <td>107.0</td>\n      <td>119.0</td>\n      <td>...</td>\n      <td>12070.0</td>\n      <td>8840.0</td>\n      <td>2380.0</td>\n      <td>510.0</td>\n      <td>204.0</td>\n      <td>3400.0</td>\n      <td>2720.0</td>\n      <td>20740.0</td>\n      <td>4411.764706</td>\n      <td>284.929577</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>35.0</td>\n      <td>170.0</td>\n      <td>85.0</td>\n      <td>97.0</td>\n      <td>1.5</td>\n      <td>1.5</td>\n      <td>138.0</td>\n      <td>88.0</td>\n      <td>117.0</td>\n      <td>204.0</td>\n      <td>...</td>\n      <td>7820.0</td>\n      <td>20400.0</td>\n      <td>2482.0</td>\n      <td>170.0</td>\n      <td>119.0</td>\n      <td>3400.0</td>\n      <td>4250.0</td>\n      <td>6800.0</td>\n      <td>5000.000000</td>\n      <td>753.913043</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>70.0</td>\n      <td>165.0</td>\n      <td>55.0</td>\n      <td>75.0</td>\n      <td>0.8</td>\n      <td>1.0</td>\n      <td>115.0</td>\n      <td>63.0</td>\n      <td>128.0</td>\n      <td>165.0</td>\n      <td>...</td>\n      <td>11220.0</td>\n      <td>14025.0</td>\n      <td>2425.5</td>\n      <td>165.0</td>\n      <td>115.5</td>\n      <td>2475.0</td>\n      <td>2145.0</td>\n      <td>3135.0</td>\n      <td>3333.333333</td>\n      <td>400.367647</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>35.0</td>\n      <td>180.0</td>\n      <td>85.0</td>\n      <td>83.0</td>\n      <td>1.2</td>\n      <td>1.0</td>\n      <td>130.0</td>\n      <td>80.0</td>\n      <td>100.0</td>\n      <td>209.0</td>\n      <td>...</td>\n      <td>9540.0</td>\n      <td>22500.0</td>\n      <td>3096.0</td>\n      <td>180.0</td>\n      <td>144.0</td>\n      <td>3960.0</td>\n      <td>3240.0</td>\n      <td>3060.0</td>\n      <td>4722.222222</td>\n      <td>709.811321</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>25.0</td>\n      <td>170.0</td>\n      <td>65.0</td>\n      <td>80.0</td>\n      <td>1.5</td>\n      <td>1.2</td>\n      <td>135.0</td>\n      <td>75.0</td>\n      <td>94.0</td>\n      <td>153.0</td>\n      <td>...</td>\n      <td>9860.0</td>\n      <td>13600.0</td>\n      <td>2805.0</td>\n      <td>170.0</td>\n      <td>170.0</td>\n      <td>3400.0</td>\n      <td>2210.0</td>\n      <td>2380.0</td>\n      <td>3823.529412</td>\n      <td>448.448276</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>13858</th>\n      <td>45.0</td>\n      <td>175.0</td>\n      <td>85.0</td>\n      <td>94.0</td>\n      <td>0.8</td>\n      <td>0.8</td>\n      <td>127.0</td>\n      <td>71.0</td>\n      <td>99.0</td>\n      <td>249.0</td>\n      <td>...</td>\n      <td>8575.0</td>\n      <td>28700.0</td>\n      <td>2870.0</td>\n      <td>175.0</td>\n      <td>157.5</td>\n      <td>2975.0</td>\n      <td>2975.0</td>\n      <td>3325.0</td>\n      <td>4857.142857</td>\n      <td>889.285714</td>\n    </tr>\n    <tr>\n      <th>13859</th>\n      <td>40.0</td>\n      <td>170.0</td>\n      <td>75.0</td>\n      <td>86.0</td>\n      <td>1.2</td>\n      <td>1.0</td>\n      <td>134.0</td>\n      <td>88.0</td>\n      <td>97.0</td>\n      <td>247.0</td>\n      <td>...</td>\n      <td>10540.0</td>\n      <td>25160.0</td>\n      <td>2839.0</td>\n      <td>170.0</td>\n      <td>153.0</td>\n      <td>2550.0</td>\n      <td>2040.0</td>\n      <td>6120.0</td>\n      <td>4411.764706</td>\n      <td>677.258065</td>\n    </tr>\n    <tr>\n      <th>13860</th>\n      <td>65.0</td>\n      <td>170.0</td>\n      <td>70.0</td>\n      <td>85.0</td>\n      <td>0.6</td>\n      <td>0.7</td>\n      <td>131.0</td>\n      <td>82.0</td>\n      <td>99.0</td>\n      <td>180.0</td>\n      <td>...</td>\n      <td>7990.0</td>\n      <td>19550.0</td>\n      <td>2669.0</td>\n      <td>170.0</td>\n      <td>136.0</td>\n      <td>2040.0</td>\n      <td>1360.0</td>\n      <td>4080.0</td>\n      <td>4117.647059</td>\n      <td>651.063830</td>\n    </tr>\n    <tr>\n      <th>13861</th>\n      <td>30.0</td>\n      <td>160.0</td>\n      <td>80.0</td>\n      <td>89.0</td>\n      <td>1.5</td>\n      <td>1.5</td>\n      <td>120.0</td>\n      <td>80.0</td>\n      <td>92.0</td>\n      <td>172.0</td>\n      <td>...</td>\n      <td>7840.0</td>\n      <td>15360.0</td>\n      <td>2368.0</td>\n      <td>160.0</td>\n      <td>128.0</td>\n      <td>4160.0</td>\n      <td>5600.0</td>\n      <td>4960.0</td>\n      <td>5000.000000</td>\n      <td>561.632653</td>\n    </tr>\n    <tr>\n      <th>13862</th>\n      <td>60.0</td>\n      <td>170.0</td>\n      <td>70.0</td>\n      <td>86.0</td>\n      <td>1.5</td>\n      <td>1.5</td>\n      <td>135.0</td>\n      <td>85.0</td>\n      <td>90.0</td>\n      <td>159.0</td>\n      <td>...</td>\n      <td>9350.0</td>\n      <td>15300.0</td>\n      <td>2533.0</td>\n      <td>170.0</td>\n      <td>170.0</td>\n      <td>9520.0</td>\n      <td>14450.0</td>\n      <td>5440.0</td>\n      <td>4117.647059</td>\n      <td>491.454545</td>\n    </tr>\n  </tbody>\n</table>\n<p>13863 rows × 100 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"phik_overview = merged_data.phik_matrix()\n# phik_overview['smoking'].sort_values(ascending=False) \nsorted_smoking_values = phik_overview['smoking'].sort_values(ascending=False)","metadata":{"execution":{"iopub.status.busy":"2023-10-31T17:05:24.099878Z","iopub.execute_input":"2023-10-31T17:05:24.100337Z","iopub.status.idle":"2023-10-31T17:06:12.024047Z","shell.execute_reply.started":"2023-10-31T17:05:24.100286Z","shell.execute_reply":"2023-10-31T17:06:12.023030Z"},"trusted":true},"execution_count":249,"outputs":[{"name":"stdout","text":"interval columns not set, guessing: ['age', 'height(cm)', 'weight(kg)', 'waist(cm)', 'eyesight(left)', 'eyesight(right)', 'hearing(left)', 'hearing(right)', 'systolic', 'relaxation', 'fasting blood sugar', 'Cholesterol', 'triglyceride', 'HDL', 'LDL', 'hemoglobin', 'Urine protein', 'serum creatinine', 'AST', 'ALT', 'Gtp', 'dental caries', 'tartar', 'smoking', 'BMI', 'Chol_HDL_ratio', 'ldl_hdl', 'map', 'Waist_Height_ratio', 'height_nin_110', 'Average_hearing', 'Average_eyesight', 'ast_alt', 'Systolic_Diastolic_ratio', 'Atherogenic_coefficient', 'BMI_to_age', 'Glucose_to_Cholesterol', 'Triglycerides_to_HDL', 'Systolic_to_age', 'Diastolic_to_age', 'Hemoglobin_to_age', 'GTP_to_age', 'GTP_to_AST_ALT', 'GTP_to_Cholesterol', 'GTP_index', 'age_normal', 'weight(kg)_normal', 'waist(cm)_normal', 'eyesight(left)_normal', 'eyesight(right)_normal', 'systolic_normal', 'relaxation_normal', 'fasting_blood_sugar_normal', 'Cholesterol_normal', 'triglyceride_normal', 'HDL_normal', 'LDL_normal', 'hemoglobin_normal', 'Urine_protein_normal', 'serum_creatinine_normal', 'AST_normal', 'ALT_normal', 'Gtp_normal', 'BMI_normal', 'Chol_HDL_ratio_normal', 'ldl_hdl_normal', 'map_normal', 'Waist_Height_ratio_normal', 'height_nin_110_normal', 'Average_hearing_normal', 'Average_eyesight_normal', 'ast_alt_normal', 'Systolic_Diastolic_ratio_normal', 'Atherogenic_coefficient_normal', 'BMI_to_age_normal', 'Glucose_to_Cholesterol_normal', 'Triglycerides_to_HDL_normal', 'Systolic_to_age_normal', 'Diastolic_to_age_normal', 'Hemoglobin_to_age_normal', 'GTP_to_age_normal', 'GTP_to_AST_ALT_normal', 'GTP_to_Cholesterol_normal', 'GTP_index_normal']\n","output_type":"stream"}]},{"cell_type":"code","source":"# sorted_smoking_values_bu = sorted_smoking_values.copy()","metadata":{"execution":{"iopub.status.busy":"2023-10-31T12:05:22.817933Z","iopub.execute_input":"2023-10-31T12:05:22.818371Z","iopub.status.idle":"2023-10-31T12:05:22.823522Z","shell.execute_reply.started":"2023-10-31T12:05:22.818309Z","shell.execute_reply":"2023-10-31T12:05:22.822686Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"# sorted_smoking_values = phik_overview['smoking'].sort_values(ascending=False)\nsorted_smoking_values[:30]\n# phik_overview","metadata":{"execution":{"iopub.status.busy":"2023-10-31T17:06:26.225495Z","iopub.execute_input":"2023-10-31T17:06:26.225887Z","iopub.status.idle":"2023-10-31T17:06:26.235551Z","shell.execute_reply.started":"2023-10-31T17:06:26.225854Z","shell.execute_reply":"2023-10-31T17:06:26.234190Z"},"trusted":true},"execution_count":250,"outputs":[{"execution_count":250,"output_type":"execute_result","data":{"text/plain":"smoking                           1.000000\nGTP_to_AST_ALT_normal             0.278280\nGTP_to_Cholesterol_normal         0.244651\nGtp_normal                        0.243253\nGTP_to_age_normal                 0.231220\nGTP_index_normal                  0.204338\ntriglyceride_normal               0.203980\nTriglycerides_to_HDL_normal       0.203776\ntriglyceride                      0.190617\nGTP_to_AST_ALT                    0.187505\nage                               0.183296\nHemoglobin_to_age                 0.160277\nGtp                               0.142844\nGTP_to_Cholesterol                0.127258\nage_normal                        0.120534\nGTP_to_age                        0.120122\nHemoglobin_to_age_normal          0.118743\nhemoglobin_normal                 0.117904\nhemoglobin                        0.112074\ntartar                            0.104470\nDiastolic_to_age                  0.101645\nSystolic_to_age                   0.099949\nSystolic_to_age_normal            0.096548\nBMI_to_age                        0.093247\nDiastolic_to_age_normal           0.092873\nHDL_normal                        0.091878\ndental caries                     0.089124\nAtherogenic_coefficient_normal    0.088843\nChol_HDL_ratio_normal             0.087919\nGTP_index                         0.078257\nName: smoking, dtype: float64"},"metadata":{}}]},{"cell_type":"code","source":"sorted_smoking_values_df = sorted_smoking_values.reset_index()\nsorted_smoking_values_df.columns = ['index', 'value']","metadata":{"execution":{"iopub.status.busy":"2023-10-31T12:05:22.843091Z","iopub.execute_input":"2023-10-31T12:05:22.843474Z","iopub.status.idle":"2023-10-31T12:05:22.853232Z","shell.execute_reply.started":"2023-10-31T12:05:22.843432Z","shell.execute_reply":"2023-10-31T12:05:22.851981Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"sorted_smoking_values_df.to_csv('sorted_smoking_values_зршл_860_куыгде_df.csv')","metadata":{"execution":{"iopub.status.busy":"2023-10-31T12:05:22.854982Z","iopub.execute_input":"2023-10-31T12:05:22.855523Z","iopub.status.idle":"2023-10-31T12:05:22.879270Z","shell.execute_reply.started":"2023-10-31T12:05:22.855491Z","shell.execute_reply":"2023-10-31T12:05:22.878245Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"sorted_smoking_values_df.iloc[:35,:]","metadata":{"execution":{"iopub.status.busy":"2023-10-31T12:05:22.881048Z","iopub.execute_input":"2023-10-31T12:05:22.881479Z","iopub.status.idle":"2023-10-31T12:05:22.895667Z","shell.execute_reply.started":"2023-10-31T12:05:22.881437Z","shell.execute_reply":"2023-10-31T12:05:22.894432Z"},"trusted":true},"execution_count":24,"outputs":[{"execution_count":24,"output_type":"execute_result","data":{"text/plain":"                                    index     value\n0                                 smoking  1.000000\n1             triglyceride height_nin_110  0.207605\n2                 triglyceride hemoglobin  0.204950\n3                 height(cm) triglyceride  0.197030\n4               BMI_to_age GTP_to_AST_ALT  0.193019\n5                 systolic GTP_to_AST_ALT  0.191646\n6                            triglyceride  0.190617\n7                HDL Triglycerides_to_HDL  0.190531\n8             triglyceride GTP_to_AST_ALT  0.189900\n9                          GTP_to_AST_ALT  0.187505\n10  Glucose_to_Cholesterol GTP_to_AST_ALT  0.186609\n11  triglyceride Systolic_Diastolic_ratio  0.185686\n12        Diastolic_to_age GTP_to_AST_ALT  0.185198\n13                relaxation triglyceride  0.184088\n14        triglyceride Waist_Height_ratio  0.184026\n15                 waist(cm) triglyceride  0.183321\n16                                    age  0.183296\n17        Average_eyesight GTP_to_AST_ALT  0.180600\n18                       triglyceride map  0.180091\n19                  systolic triglyceride  0.178960\n20                         age height(cm)  0.178067\n21                weight(kg) triglyceride  0.177356\n22         Average_hearing GTP_to_AST_ALT  0.177057\n23     fasting blood sugar GTP_to_AST_ALT  0.176157\n24              height_nin_110 BMI_to_age  0.176138\n25                       triglyceride BMI  0.173477\n26               Cholesterol triglyceride  0.171330\n27       fasting blood sugar triglyceride  0.167730\n28                         triglyceride^2  0.167099\n29                                age map  0.163343\n30         triglyceride Hemoglobin_to_age  0.162880\n31                      Hemoglobin_to_age  0.160277\n32          triglyceride Diastolic_to_age  0.159254\n33          height_nin_110 GTP_to_AST_ALT  0.158429\n34                                  age^2  0.157865","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>index</th>\n      <th>value</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>smoking</td>\n      <td>1.000000</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>triglyceride height_nin_110</td>\n      <td>0.207605</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>triglyceride hemoglobin</td>\n      <td>0.204950</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>height(cm) triglyceride</td>\n      <td>0.197030</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>BMI_to_age GTP_to_AST_ALT</td>\n      <td>0.193019</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>systolic GTP_to_AST_ALT</td>\n      <td>0.191646</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>triglyceride</td>\n      <td>0.190617</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>HDL Triglycerides_to_HDL</td>\n      <td>0.190531</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>triglyceride GTP_to_AST_ALT</td>\n      <td>0.189900</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>GTP_to_AST_ALT</td>\n      <td>0.187505</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>Glucose_to_Cholesterol GTP_to_AST_ALT</td>\n      <td>0.186609</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>triglyceride Systolic_Diastolic_ratio</td>\n      <td>0.185686</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>Diastolic_to_age GTP_to_AST_ALT</td>\n      <td>0.185198</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>relaxation triglyceride</td>\n      <td>0.184088</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>triglyceride Waist_Height_ratio</td>\n      <td>0.184026</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>waist(cm) triglyceride</td>\n      <td>0.183321</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>age</td>\n      <td>0.183296</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>Average_eyesight GTP_to_AST_ALT</td>\n      <td>0.180600</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>triglyceride map</td>\n      <td>0.180091</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>systolic triglyceride</td>\n      <td>0.178960</td>\n    </tr>\n    <tr>\n      <th>20</th>\n      <td>age height(cm)</td>\n      <td>0.178067</td>\n    </tr>\n    <tr>\n      <th>21</th>\n      <td>weight(kg) triglyceride</td>\n      <td>0.177356</td>\n    </tr>\n    <tr>\n      <th>22</th>\n      <td>Average_hearing GTP_to_AST_ALT</td>\n      <td>0.177057</td>\n    </tr>\n    <tr>\n      <th>23</th>\n      <td>fasting blood sugar GTP_to_AST_ALT</td>\n      <td>0.176157</td>\n    </tr>\n    <tr>\n      <th>24</th>\n      <td>height_nin_110 BMI_to_age</td>\n      <td>0.176138</td>\n    </tr>\n    <tr>\n      <th>25</th>\n      <td>triglyceride BMI</td>\n      <td>0.173477</td>\n    </tr>\n    <tr>\n      <th>26</th>\n      <td>Cholesterol triglyceride</td>\n      <td>0.171330</td>\n    </tr>\n    <tr>\n      <th>27</th>\n      <td>fasting blood sugar triglyceride</td>\n      <td>0.167730</td>\n    </tr>\n    <tr>\n      <th>28</th>\n      <td>triglyceride^2</td>\n      <td>0.167099</td>\n    </tr>\n    <tr>\n      <th>29</th>\n      <td>age map</td>\n      <td>0.163343</td>\n    </tr>\n    <tr>\n      <th>30</th>\n      <td>triglyceride Hemoglobin_to_age</td>\n      <td>0.162880</td>\n    </tr>\n    <tr>\n      <th>31</th>\n      <td>Hemoglobin_to_age</td>\n      <td>0.160277</td>\n    </tr>\n    <tr>\n      <th>32</th>\n      <td>triglyceride Diastolic_to_age</td>\n      <td>0.159254</td>\n    </tr>\n    <tr>\n      <th>33</th>\n      <td>height_nin_110 GTP_to_AST_ALT</td>\n      <td>0.158429</td>\n    </tr>\n    <tr>\n      <th>34</th>\n      <td>age^2</td>\n      <td>0.157865</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"for feat in poly_df.columns.to_list():\n    merged_data[feat] = poly_df[feat]","metadata":{"execution":{"iopub.status.busy":"2023-10-31T16:28:48.809320Z","iopub.execute_input":"2023-10-31T16:28:48.809734Z","iopub.status.idle":"2023-10-31T16:28:49.374454Z","shell.execute_reply.started":"2023-10-31T16:28:48.809704Z","shell.execute_reply":"2023-10-31T16:28:49.371177Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":227,"outputs":[{"name":"stderr","text":"/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n/tmp/ipykernel_31/454015848.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  merged_data[feat] = poly_df[feat]\n","output_type":"stream"}]},{"cell_type":"code","source":"features_4_learing = list(set(evaluate_features_auc_df.sort_values(by='auc_scores', ascending=False).iloc[:35,:]['Feature'].to_list()) \\\n                    | set(sorted_smoking_values[:45].index.to_list()))","metadata":{"execution":{"iopub.status.busy":"2023-10-31T16:28:55.004823Z","iopub.execute_input":"2023-10-31T16:28:55.005202Z","iopub.status.idle":"2023-10-31T16:28:55.012396Z","shell.execute_reply.started":"2023-10-31T16:28:55.005173Z","shell.execute_reply":"2023-10-31T16:28:55.011165Z"},"trusted":true},"execution_count":228,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\n# X = merged_data[evaluate_features_auc_poly_df.sort_values(by='auc_scores', ascending=False).iloc[1:50,:]['Feature'].to_list()]#.drop(['smoking'], axis=1).copy() # [] #   [selected_features.index.to_list()]\n# X = merged_data[evaluate_features_auc_df.sort_values(by='auc_scores', ascending=False).iloc[:10,:]['Feature'].to_list()].drop(['smoking'], axis=1).copy()\n# X = merged_data[list(set(evaluate_features_auc_df.sort_values(by='auc_scores', ascending=False).iloc[:25,:]['Feature'].to_list()) \\\n#                      | set(evaluate_features_auc_poly_df.sort_values(by='auc_scores', ascending=False).iloc[1:55,:]['Feature'].to_list()))]\n#                            .drop(['smoking'], axis=1).copy()\n# X = merged_data[features_4_learing].drop(['smoking'], axis=1).copy() # [] #   [selected_features.index.to_list()]\nX = merged_data.drop(['smoking'], axis=1).copy() # [] #   [selected_features.index.to_list()]\n\n\n# y = merged_data['smoking'].copy()\ny = merged_data['smoking'].copy()\n\n\n# Разделение данных на обучающую и тестовую выборки\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\nX_train.shape, X_test.shape","metadata":{"execution":{"iopub.status.busy":"2023-10-31T17:07:30.283738Z","iopub.execute_input":"2023-10-31T17:07:30.284683Z","iopub.status.idle":"2023-10-31T17:07:30.352623Z","shell.execute_reply.started":"2023-10-31T17:07:30.284646Z","shell.execute_reply":"2023-10-31T17:07:30.351381Z"},"trusted":true},"execution_count":251,"outputs":[{"execution_count":251,"output_type":"execute_result","data":{"text/plain":"((11090, 83), (2773, 83))"},"metadata":{}}]},{"cell_type":"code","source":"X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.25, random_state=42, stratify=y_train)\n\nX_train = pd.DataFrame(X_train)\nX_val = pd.DataFrame(X_val)\nX_train.shape, X_val.shape, y_train.shape, y_val.shape","metadata":{"execution":{"iopub.status.busy":"2023-10-31T17:07:32.054863Z","iopub.execute_input":"2023-10-31T17:07:32.055255Z","iopub.status.idle":"2023-10-31T17:07:32.094064Z","shell.execute_reply.started":"2023-10-31T17:07:32.055225Z","shell.execute_reply":"2023-10-31T17:07:32.093054Z"},"trusted":true},"execution_count":252,"outputs":[{"execution_count":252,"output_type":"execute_result","data":{"text/plain":"((8317, 83), (2773, 83), (8317,), (2773,))"},"metadata":{}}]},{"cell_type":"code","source":"import optuna\nfrom sklearn.metrics import roc_auc_score, average_precision_score\n\n\nX_train_temp = X_train.copy() # .drop(columns=['hearing(left)'])\nX_test_temp = X_test.copy()\nX_val_temp = X_val.copy()\n\ndef objective(trial):\n    params = {\n        'iterations': trial.suggest_int('iterations', 1000, 4000),\n        'boosting_type': trial.suggest_categorical('boosting_type', [ 'Plain' ]), # 'Ordered',\n        'depth': trial.suggest_int('depth', 6, 11),\n        'learning_rate': trial.suggest_float('learning_rate', 0.005, 0.08 ), #  0.05, 0.1\n        'l2_leaf_reg': trial.suggest_float('l2_leaf_reg', 20, 35),\n        'border_count': trial.suggest_int('border_count', 20, 300),\n        'bagging_temperature': trial.suggest_float('bagging_temperature', 0, 9),\n        'od_type': 'Iter', \n        'od_wait': 100, \n        'eval_metric': 'AUC',\n        'logging_level': 'Silent',\n        'random_seed': 42,\n        'auto_class_weights': 'Balanced',\n#         'task_type': 'GPU'\n    }\n\n    model = CatBoostClassifier(**params)\n    model.fit(X_train_temp, y_train, eval_set=[(X_val_temp, y_val)], early_stopping_rounds=params['od_wait'], cat_features=[])\n\n    y_pred_proba = model.predict_proba(X_test_temp)[:, 1]\n        \n    roc_auc = roc_auc_score(y_test, y_pred_proba)\n    avg_prec = average_precision_score(y_test, y_pred_proba)\n    \n    return roc_auc, avg_prec","metadata":{"execution":{"iopub.status.busy":"2023-10-31T17:11:10.231165Z","iopub.execute_input":"2023-10-31T17:11:10.231902Z","iopub.status.idle":"2023-10-31T17:11:10.246260Z","shell.execute_reply.started":"2023-10-31T17:11:10.231867Z","shell.execute_reply":"2023-10-31T17:11:10.245276Z"},"trusted":true},"execution_count":257,"outputs":[]},{"cell_type":"code","source":"%%time \nstudy = optuna.create_study(pruner=MedianPruner(), directions=['maximize', 'maximize'] ) #pruner=MedianPruner(), sampler=optuna.samplers.TPESampler(seed=42)\nstudy.optimize(objective,\n               n_jobs=-1,\n               n_trials=10, # 25 показывает результат лучше\n               show_progress_bar=True\n              )\n\nbest_trial = study.best_trials[0]\nroc_auc_best = best_trial.values[0]\navg_prec_best = best_trial.values[1]\n\nprint(f\"Лучшее значение ROC AUC: {roc_auc_best:.4f}\")\nprint(f\"Лучшее значение Average Precision: {avg_prec_best:.4f}\")","metadata":{"execution":{"iopub.status.busy":"2023-10-31T17:11:10.733400Z","iopub.execute_input":"2023-10-31T17:11:10.733864Z","iopub.status.idle":"2023-10-31T17:16:46.212455Z","shell.execute_reply.started":"2023-10-31T17:11:10.733832Z","shell.execute_reply":"2023-10-31T17:16:46.211257Z"},"trusted":true},"execution_count":258,"outputs":[{"name":"stderr","text":"[I 2023-10-31 17:11:10,737] A new study created in memory with name: no-name-55474b09-c61c-4612-aae2-315781a87ab7\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/10 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"474a98431aeb4722b52bae8dafe94d7e"}},"metadata":{}},{"name":"stdout","text":"[I 2023-10-31 17:11:50,037] Trial 1 finished with values: [0.7257165450906978, 0.4228203500412938] and parameters: {'iterations': 3314, 'boosting_type': 'Plain', 'depth': 8, 'learning_rate': 0.07727299983983583, 'l2_leaf_reg': 22.85633040212972, 'border_count': 39, 'bagging_temperature': 7.821303153298909}. \n[I 2023-10-31 17:12:25,314] Trial 2 finished with values: [0.7294356400490607, 0.4288716249434281] and parameters: {'iterations': 3738, 'boosting_type': 'Plain', 'depth': 10, 'learning_rate': 0.045880388018615284, 'l2_leaf_reg': 34.695174066374186, 'border_count': 88, 'bagging_temperature': 6.946739598972309}. \n[I 2023-10-31 17:13:38,997] Trial 5 finished with values: [0.727470789490672, 0.4277758296075022] and parameters: {'iterations': 1502, 'boosting_type': 'Plain', 'depth': 6, 'learning_rate': 0.013045000352372684, 'l2_leaf_reg': 27.504269063327865, 'border_count': 164, 'bagging_temperature': 4.234007505189664}. \n[I 2023-10-31 17:14:19,392] Trial 6 finished with values: [0.7258424246336583, 0.424805973864281] and parameters: {'iterations': 2067, 'boosting_type': 'Plain', 'depth': 6, 'learning_rate': 0.04316623266753643, 'l2_leaf_reg': 28.626570004790388, 'border_count': 184, 'bagging_temperature': 2.70368386830952}. \n[I 2023-10-31 17:15:34,093] Trial 0 finished with values: [0.7395213349686914, 0.4485584118116386] and parameters: {'iterations': 2992, 'boosting_type': 'Plain', 'depth': 11, 'learning_rate': 0.019537221489194654, 'l2_leaf_reg': 24.861158232026952, 'border_count': 227, 'bagging_temperature': 3.8485745358813874}. \n[I 2023-10-31 17:15:35,228] Trial 4 finished with values: [0.7334379639790846, 0.4357396731150875] and parameters: {'iterations': 1573, 'boosting_type': 'Plain', 'depth': 9, 'learning_rate': 0.009218233873379791, 'l2_leaf_reg': 33.932884983031876, 'border_count': 179, 'bagging_temperature': 4.166589336519836}. \n[I 2023-10-31 17:15:50,865] Trial 7 finished with values: [0.7248119876057064, 0.42430743607573135] and parameters: {'iterations': 2056, 'boosting_type': 'Plain', 'depth': 10, 'learning_rate': 0.0685657311707169, 'l2_leaf_reg': 26.232361904119692, 'border_count': 232, 'bagging_temperature': 8.995947022146892}. \n[I 2023-10-31 17:15:55,497] Trial 9 finished with values: [0.7184938028532697, 0.4165566032198322] and parameters: {'iterations': 2211, 'boosting_type': 'Plain', 'depth': 6, 'learning_rate': 0.052972276537060506, 'l2_leaf_reg': 23.726551594685724, 'border_count': 108, 'bagging_temperature': 7.504345742909377}. \n[I 2023-10-31 17:16:01,695] Trial 8 finished with values: [0.7246740042605384, 0.4180717419731472] and parameters: {'iterations': 1637, 'boosting_type': 'Plain', 'depth': 6, 'learning_rate': 0.020709179034682033, 'l2_leaf_reg': 20.85001653302423, 'border_count': 32, 'bagging_temperature': 0.6636063670798752}. \n[I 2023-10-31 17:16:46,201] Trial 3 finished with values: [0.7423245755600026, 0.44765379901894464] and parameters: {'iterations': 1811, 'boosting_type': 'Plain', 'depth': 11, 'learning_rate': 0.010196771769294406, 'l2_leaf_reg': 29.522487014028105, 'border_count': 166, 'bagging_temperature': 6.782200068451898}. \nЛучшее значение ROC AUC: 0.7395\nЛучшее значение Average Precision: 0.4486\nCPU times: user 20min 22s, sys: 18.2 s, total: 20min 40s\nWall time: 5min 35s\n","output_type":"stream"}]},{"cell_type":"code","source":"%%time\n# Возьмите параметры из лучшего trial на основе первой метрики (ROC AUC в данном случае)\nbest_params = study.best_trials[0].params\n\nCatBoost_model = CatBoostClassifier(**best_params, auto_class_weights='Balanced', logging_level='Silent') #  task_type='GPU' auto_class_weights='Balanced' , \n\nCatBoost_model.fit(X_train_temp, y_train, eval_set=[(X_val_temp, y_val)], early_stopping_rounds=100, verbose=100, cat_features=[]) # cat_features\n\ny_pred_proba = CatBoost_model.predict_proba(X_test_temp)[:, 1]\n\nthresholds = np.linspace(0.01, 1, 300)\nf1_scores = [f1_score(y_test, y_pred_proba > thresh) for thresh in thresholds]\noptimal_threshold = thresholds[np.argmax(f1_scores)]\n\nprint(f\"Наивысший F1: {max(f1_scores):.5f}\")","metadata":{"execution":{"iopub.status.busy":"2023-10-31T17:16:46.214606Z","iopub.execute_input":"2023-10-31T17:16:46.214928Z","iopub.status.idle":"2023-10-31T17:17:37.701485Z","shell.execute_reply.started":"2023-10-31T17:16:46.214900Z","shell.execute_reply":"2023-10-31T17:17:37.700313Z"},"trusted":true},"execution_count":259,"outputs":[{"name":"stdout","text":"Наивысший F1: 0.45278\nCPU times: user 3min 1s, sys: 3.17 s, total: 3min 4s\nWall time: 51.5 s\n","output_type":"stream"}]},{"cell_type":"code","source":"# Получение значимости признаков\nfeature_importances = CatBoost_model.get_feature_importance()\n\n# Создание датафрейма для лучшей визуализации\nfeatures_df = pd.DataFrame({\n    'Feature': X_train.columns,\n    'Importance': feature_importances\n})\n\n# Сортировка признаков по их значимости  \nfeatures_df = features_df.sort_values(by='Importance', ascending=False)\n\nprint(features_df)","metadata":{"execution":{"iopub.status.busy":"2023-10-31T17:10:28.635351Z","iopub.execute_input":"2023-10-31T17:10:28.635694Z","iopub.status.idle":"2023-10-31T17:10:28.677831Z","shell.execute_reply.started":"2023-10-31T17:10:28.635665Z","shell.execute_reply":"2023-10-31T17:10:28.676514Z"},"trusted":true},"execution_count":256,"outputs":[{"name":"stdout","text":"                   Feature  Importance\n41          GTP_to_AST_ALT    4.684443\n15              hemoglobin    4.336206\n22                  tartar    3.865928\n39       Hemoglobin_to_age    3.651757\n12            triglyceride    3.562104\n..                     ...         ...\n52      Cholesterol_normal    0.002561\n65              map_normal    0.000569\n59              AST_normal    0.000000\n70          ast_alt_normal    0.000000\n48  eyesight(right)_normal    0.000000\n\n[83 rows x 2 columns]\n","output_type":"stream"}]},{"cell_type":"code","source":"# df_catboost_test_result.to_csv('df_catboost_test_result.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2023-10-31T15:36:50.366414Z","iopub.execute_input":"2023-10-31T15:36:50.366861Z","iopub.status.idle":"2023-10-31T15:36:50.374263Z","shell.execute_reply.started":"2023-10-31T15:36:50.366828Z","shell.execute_reply":"2023-10-31T15:36:50.373245Z"},"trusted":true},"execution_count":138,"outputs":[]},{"cell_type":"code","source":"import optuna\nfrom optuna.pruners import MedianPruner\nfrom xgboost import XGBClassifier\n\ndef XGB_objective(trial):\n   \n    \n    params = {\n        'learning_rate': trial.suggest_float('learning_rate', 0.005, 0.08),\n        'n_estimators': trial.suggest_int('n_estimators', 800, 3500),\n        'max_depth': trial.suggest_int('max_depth', 6, 20),\n        'subsample': trial.suggest_float('subsample', 0.5, 1),\n        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.5, 1),\n        'gamma': trial.suggest_float('gamma', 0, 0.5),\n        'scale_pos_weight': 1/y_train.mean(),\n        'early_stopping_rounds': 50,\n        'reg_lambda': trial.suggest_int('reg_lambda', 3, 10),\n        'eval_metric': \"auc\"\n    }\n\n\n    model = XGBClassifier(**params)\n    eval_set = [(X_val, y_val)]\n    model.fit(X_train, y_train, eval_set=eval_set, verbose=500) # , early_stopping_rounds=50\n\n    y_prob_fold = model.predict_proba(X_test)[:, 1]\n        \n    roc_auc = roc_auc_score(y_test, y_prob_fold)\n#     avg_prec = average_precision_score(y_test, y_prob_fold)\n    \n    return roc_auc\n\n# Запуск оптимизации Optuna\nXGB_study = optuna.create_study(pruner=MedianPruner(), direction='maximize')\nXGB_study.optimize(XGB_objective, n_trials=20, n_jobs=-1)   # , show_progress_bar=True\n\n# Лучшие параметры\nXGB_best_params = XGB_study.best_params\nXGB_roc_auc_best = XGB_study.best_value\n\n\nprint(f\"Лучшее значение ROC AUC: {XGB_roc_auc_best:.5f}\")\n# print(f\"Лучшее значение Average Precision: {XGB_avg_prec_best:.4f}\")","metadata":{"execution":{"iopub.status.busy":"2023-10-31T15:36:50.378374Z","iopub.execute_input":"2023-10-31T15:36:50.378754Z","iopub.status.idle":"2023-10-31T15:41:34.151992Z","shell.execute_reply.started":"2023-10-31T15:36:50.378722Z","shell.execute_reply":"2023-10-31T15:41:34.150758Z"},"trusted":true},"execution_count":139,"outputs":[{"name":"stderr","text":"[I 2023-10-31 15:36:50,387] A new study created in memory with name: no-name-4ee20817-7133-4f7b-963c-e71c1489c99b\n","output_type":"stream"},{"name":"stdout","text":"[0]\tvalidation_0-auc:0.62146\n[0]\tvalidation_0-auc:0.62654\n[0]\tvalidation_0-auc:0.63310\n[0]\tvalidation_0-auc:0.62237\n[186]\tvalidation_0-auc:0.73553\n","output_type":"stream"},{"name":"stderr","text":"[I 2023-10-31 15:37:25,773] Trial 0 finished with value: 0.7136990833387128 and parameters: {'learning_rate': 0.07965796912601965, 'n_estimators': 1288, 'max_depth': 14, 'subsample': 0.6542533148636265, 'colsample_bytree': 0.7461319807365632, 'gamma': 0.02678420413918503, 'reg_lambda': 10}. Best is trial 0 with value: 0.7136990833387128.\n","output_type":"stream"},{"name":"stdout","text":"[0]\tvalidation_0-auc:0.64674\n[251]\tvalidation_0-auc:0.74561\n","output_type":"stream"},{"name":"stderr","text":"[I 2023-10-31 15:37:39,645] Trial 3 finished with value: 0.7252892808727648 and parameters: {'learning_rate': 0.06718967320180498, 'n_estimators': 2414, 'max_depth': 19, 'subsample': 0.7760936375039661, 'colsample_bytree': 0.6362842907002032, 'gamma': 0.3441793844422684, 'reg_lambda': 9}. Best is trial 3 with value: 0.7252892808727648.\n","output_type":"stream"},{"name":"stdout","text":"[0]\tvalidation_0-auc:0.61038\n[442]\tvalidation_0-auc:0.73353\n","output_type":"stream"},{"name":"stderr","text":"[I 2023-10-31 15:37:42,982] Trial 2 finished with value: 0.7101680007746434 and parameters: {'learning_rate': 0.07959023211942642, 'n_estimators': 872, 'max_depth': 11, 'subsample': 0.6404055504784054, 'colsample_bytree': 0.5763377942446235, 'gamma': 0.10563676706482178, 'reg_lambda': 6}. Best is trial 3 with value: 0.7252892808727648.\n","output_type":"stream"},{"name":"stdout","text":"[0]\tvalidation_0-auc:0.64263\n[257]\tvalidation_0-auc:0.74202\n","output_type":"stream"},{"name":"stderr","text":"[I 2023-10-31 15:38:07,999] Trial 4 finished with value: 0.7193184752436899 and parameters: {'learning_rate': 0.07440613709346654, 'n_estimators': 3422, 'max_depth': 14, 'subsample': 0.9504072570333735, 'colsample_bytree': 0.6774973869405374, 'gamma': 0.08572186252417868, 'reg_lambda': 4}. Best is trial 3 with value: 0.7252892808727648.\n","output_type":"stream"},{"name":"stdout","text":"[0]\tvalidation_0-auc:0.65954\n[431]\tvalidation_0-auc:0.75008\n","output_type":"stream"},{"name":"stderr","text":"[I 2023-10-31 15:38:26,272] Trial 1 finished with value: 0.7209121425343749 and parameters: {'learning_rate': 0.030099415112926735, 'n_estimators': 1332, 'max_depth': 18, 'subsample': 0.641686753451538, 'colsample_bytree': 0.7924212160033968, 'gamma': 0.038338339072938876, 'reg_lambda': 3}. Best is trial 3 with value: 0.7252892808727648.\n","output_type":"stream"},{"name":"stdout","text":"[0]\tvalidation_0-auc:0.64064\n[345]\tvalidation_0-auc:0.72961\n","output_type":"stream"},{"name":"stderr","text":"[I 2023-10-31 15:38:28,266] Trial 7 finished with value: 0.7082414789232456 and parameters: {'learning_rate': 0.05111261293620938, 'n_estimators': 2155, 'max_depth': 6, 'subsample': 0.8547999277328149, 'colsample_bytree': 0.6278312923031155, 'gamma': 0.22638344697717705, 'reg_lambda': 8}. Best is trial 3 with value: 0.7252892808727648.\n","output_type":"stream"},{"name":"stdout","text":"[0]\tvalidation_0-auc:0.62386\n[486]\tvalidation_0-auc:0.73387\n","output_type":"stream"},{"name":"stderr","text":"[I 2023-10-31 15:38:39,403] Trial 6 finished with value: 0.717676392744174 and parameters: {'learning_rate': 0.016616307802475916, 'n_estimators': 3187, 'max_depth': 8, 'subsample': 0.692964198339147, 'colsample_bytree': 0.9422820506949727, 'gamma': 0.3640874097056582, 'reg_lambda': 7}. Best is trial 3 with value: 0.7252892808727648.\n","output_type":"stream"},{"name":"stdout","text":"[0]\tvalidation_0-auc:0.63201\n[161]\tvalidation_0-auc:0.71946\n","output_type":"stream"},{"name":"stderr","text":"[I 2023-10-31 15:38:41,291] Trial 9 finished with value: 0.7093715705893745 and parameters: {'learning_rate': 0.06325027263998181, 'n_estimators': 3094, 'max_depth': 7, 'subsample': 0.9101409727793444, 'colsample_bytree': 0.824729236183062, 'gamma': 0.2675156952312281, 'reg_lambda': 4}. Best is trial 3 with value: 0.7252892808727648.\n","output_type":"stream"},{"name":"stdout","text":"[0]\tvalidation_0-auc:0.63750\n[343]\tvalidation_0-auc:0.74195\n","output_type":"stream"},{"name":"stderr","text":"[I 2023-10-31 15:38:55,522] Trial 5 finished with value: 0.7240123297398491 and parameters: {'learning_rate': 0.03818348621391965, 'n_estimators': 3092, 'max_depth': 17, 'subsample': 0.6617505735762192, 'colsample_bytree': 0.823889138737923, 'gamma': 0.23157825958098938, 'reg_lambda': 5}. Best is trial 3 with value: 0.7252892808727648.\n","output_type":"stream"},{"name":"stdout","text":"[0]\tvalidation_0-auc:0.65190\n[193]\tvalidation_0-auc:0.73607\n","output_type":"stream"},{"name":"stderr","text":"[I 2023-10-31 15:39:26,207] Trial 10 finished with value: 0.7234862178038862 and parameters: {'learning_rate': 0.07342936773238143, 'n_estimators': 1455, 'max_depth': 19, 'subsample': 0.9612028557188768, 'colsample_bytree': 0.792112482565507, 'gamma': 0.3508691611758166, 'reg_lambda': 8}. Best is trial 3 with value: 0.7252892808727648.\n","output_type":"stream"},{"name":"stdout","text":"[0]\tvalidation_0-auc:0.65227\n[329]\tvalidation_0-auc:0.73231\n","output_type":"stream"},{"name":"stderr","text":"[I 2023-10-31 15:39:27,381] Trial 12 finished with value: 0.7120856465044219 and parameters: {'learning_rate': 0.05169300558512178, 'n_estimators': 1564, 'max_depth': 9, 'subsample': 0.8204996411664061, 'colsample_bytree': 0.6332518284107618, 'gamma': 0.3548461433955553, 'reg_lambda': 7}. Best is trial 3 with value: 0.7252892808727648.\n","output_type":"stream"},{"name":"stdout","text":"[0]\tvalidation_0-auc:0.61639\n[445]\tvalidation_0-auc:0.73800\n","output_type":"stream"},{"name":"stderr","text":"[I 2023-10-31 15:39:50,864] Trial 11 finished with value: 0.7225364727906527 and parameters: {'learning_rate': 0.02537885155744196, 'n_estimators': 1482, 'max_depth': 13, 'subsample': 0.5397107091738385, 'colsample_bytree': 0.666805100545615, 'gamma': 0.3434625593816933, 'reg_lambda': 4}. Best is trial 3 with value: 0.7252892808727648.\n","output_type":"stream"},{"name":"stdout","text":"[0]\tvalidation_0-auc:0.63066\n[319]\tvalidation_0-auc:0.74060\n","output_type":"stream"},{"name":"stderr","text":"[I 2023-10-31 15:40:15,530] Trial 13 finished with value: 0.721767477890388 and parameters: {'learning_rate': 0.05443112129512843, 'n_estimators': 2263, 'max_depth': 16, 'subsample': 0.7851429427639375, 'colsample_bytree': 0.5057349751965254, 'gamma': 0.48534882793984496, 'reg_lambda': 10}. Best is trial 3 with value: 0.7252892808727648.\n","output_type":"stream"},{"name":"stdout","text":"[0]\tvalidation_0-auc:0.64132\n[376]\tvalidation_0-auc:0.73960\n","output_type":"stream"},{"name":"stderr","text":"[I 2023-10-31 15:40:24,142] Trial 14 finished with value: 0.7232086372732555 and parameters: {'learning_rate': 0.037431840892289917, 'n_estimators': 2619, 'max_depth': 17, 'subsample': 0.5435922316373516, 'colsample_bytree': 0.5055229739066887, 'gamma': 0.4881294998126802, 'reg_lambda': 10}. Best is trial 3 with value: 0.7252892808727648.\n","output_type":"stream"},{"name":"stdout","text":"[0]\tvalidation_0-auc:0.62915\n[500]\tvalidation_0-auc:0.74115\n[261]\tvalidation_0-auc:0.73849\n","output_type":"stream"},{"name":"stderr","text":"[I 2023-10-31 15:40:36,394] Trial 15 finished with value: 0.7251742947517914 and parameters: {'learning_rate': 0.040132768257086275, 'n_estimators': 2560, 'max_depth': 17, 'subsample': 0.7474108318559, 'colsample_bytree': 0.5290996147842864, 'gamma': 0.4526998419519538, 'reg_lambda': 10}. Best is trial 3 with value: 0.7252892808727648.\n","output_type":"stream"},{"name":"stdout","text":"[0]\tvalidation_0-auc:0.62826\n[102]\tvalidation_0-auc:0.73051\n","output_type":"stream"},{"name":"stderr","text":"[I 2023-10-31 15:40:52,722] Trial 17 finished with value: 0.7167177716093216 and parameters: {'learning_rate': 0.04096043899371877, 'n_estimators': 2677, 'max_depth': 20, 'subsample': 0.7412679046808979, 'colsample_bytree': 0.8818634674864625, 'gamma': 0.19724287484127037, 'reg_lambda': 6}. Best is trial 3 with value: 0.7252892808727648.\n","output_type":"stream"},{"name":"stdout","text":"[0]\tvalidation_0-auc:0.62301\n[186]\tvalidation_0-auc:0.73835\n","output_type":"stream"},{"name":"stderr","text":"[I 2023-10-31 15:41:12,924] Trial 18 finished with value: 0.722458201536376 and parameters: {'learning_rate': 0.06218272936249701, 'n_estimators': 2596, 'max_depth': 20, 'subsample': 0.7471130292854244, 'colsample_bytree': 0.5724596335300937, 'gamma': 0.4073109153360035, 'reg_lambda': 9}. Best is trial 3 with value: 0.7252892808727648.\n","output_type":"stream"},{"name":"stdout","text":"[287]\tvalidation_0-auc:0.74506\n","output_type":"stream"},{"name":"stderr","text":"[I 2023-10-31 15:41:28,174] Trial 16 finished with value: 0.7224408527532116 and parameters: {'learning_rate': 0.038432139675971165, 'n_estimators': 2675, 'max_depth': 20, 'subsample': 0.7394298269841204, 'colsample_bytree': 0.9238063874295501, 'gamma': 0.19207110189704393, 'reg_lambda': 6}. Best is trial 3 with value: 0.7252892808727648.\n","output_type":"stream"},{"name":"stdout","text":"[272]\tvalidation_0-auc:0.74516\n","output_type":"stream"},{"name":"stderr","text":"[I 2023-10-31 15:41:33,400] Trial 19 finished with value: 0.7182452714479375 and parameters: {'learning_rate': 0.061091025677423846, 'n_estimators': 2625, 'max_depth': 20, 'subsample': 0.7373055297544274, 'colsample_bytree': 0.5719821228274851, 'gamma': 0.4388495552755469, 'reg_lambda': 9}. Best is trial 3 with value: 0.7252892808727648.\n","output_type":"stream"},{"name":"stdout","text":"[837]\tvalidation_0-auc:0.74446\n","output_type":"stream"},{"name":"stderr","text":"[I 2023-10-31 15:41:34,139] Trial 8 finished with value: 0.730579045897618 and parameters: {'learning_rate': 0.008983383691096733, 'n_estimators': 1360, 'max_depth': 15, 'subsample': 0.8269021597266271, 'colsample_bytree': 0.9255855574853349, 'gamma': 0.07887945401031737, 'reg_lambda': 4}. Best is trial 8 with value: 0.730579045897618.\n","output_type":"stream"},{"name":"stdout","text":"Лучшее значение ROC AUC: 0.73058\n","output_type":"stream"}]},{"cell_type":"code","source":"XGB_roc_auc_best = XGB_study.best_value\nprint(f\"Лучшее значение ROC AUC: {XGB_roc_auc_best:.5f}\")","metadata":{"execution":{"iopub.status.busy":"2023-10-31T15:41:34.153299Z","iopub.execute_input":"2023-10-31T15:41:34.153704Z","iopub.status.idle":"2023-10-31T15:41:34.161485Z","shell.execute_reply.started":"2023-10-31T15:41:34.153671Z","shell.execute_reply":"2023-10-31T15:41:34.160170Z"},"trusted":true},"execution_count":140,"outputs":[{"name":"stdout","text":"Лучшее значение ROC AUC: 0.73058\n","output_type":"stream"}]},{"cell_type":"code","source":"# Обучение с лучшими гиперпараметрами на всем тренировочном наборе данных\nbest_model = XGBClassifier(**XGB_best_params, eval_metric='auc')\nbest_model.fit(X_train, y_train)\n\n# Предсказания на тестовой выборке\ny_prob_test = best_model.predict_proba(X_test)[:, 1]\n\n# Определение оптимального порога\nthresholds = np.linspace(0, 1, 300)\nf1_scores_test = [f1_score(y_test, y_prob_test > thresh) for thresh in thresholds]\noptimal_threshold_test = thresholds[np.argmax(f1_scores_test)]\n\n# Применение оптимального порога для классификации\ny_pred_test = [1 if prob >= optimal_threshold_test else 0 for prob in y_prob_test]\n\n# Оценка качества модели с новым порогом на тестовой выборке\nprint(\"ROC AUC:\", roc_auc_score(y_test, y_prob_test))\nprint(\"Average Precision:\", average_precision_score(y_test, y_prob_test))\nprint(\"\\nOptimal Threshold:\", optimal_threshold_test)\nprint(\"\\nClassification Report with Optimal Threshold:\\n\", classification_report(y_test, y_pred_test))\nprint(f\"Наивысший F1: {max(f1_scores_test):.5f}\")\n0.47829","metadata":{"execution":{"iopub.status.busy":"2023-10-31T15:41:34.162886Z","iopub.execute_input":"2023-10-31T15:41:34.163293Z","iopub.status.idle":"2023-10-31T15:42:44.097772Z","shell.execute_reply.started":"2023-10-31T15:41:34.163258Z","shell.execute_reply":"2023-10-31T15:42:44.096669Z"},"trusted":true},"execution_count":141,"outputs":[{"name":"stdout","text":"ROC AUC: 0.7237363630495126\nAverage Precision: 0.42828280138692154\n\nOptimal Threshold: 0.14046822742474915\n\nClassification Report with Optimal Threshold:\n               precision    recall  f1-score   support\n\n           0       0.88      0.74      0.80      2213\n           1       0.36      0.59      0.45       560\n\n    accuracy                           0.71      2773\n   macro avg       0.62      0.66      0.62      2773\nweighted avg       0.77      0.71      0.73      2773\n\nНаивысший F1: 0.44792\n","output_type":"stream"},{"execution_count":141,"output_type":"execute_result","data":{"text/plain":"0.47829"},"metadata":{}}]},{"cell_type":"code","source":"y_prob_test","metadata":{"execution":{"iopub.status.busy":"2023-10-31T15:42:44.099275Z","iopub.execute_input":"2023-10-31T15:42:44.099734Z","iopub.status.idle":"2023-10-31T15:42:44.107785Z","shell.execute_reply.started":"2023-10-31T15:42:44.099694Z","shell.execute_reply":"2023-10-31T15:42:44.106581Z"},"trusted":true},"execution_count":142,"outputs":[{"execution_count":142,"output_type":"execute_result","data":{"text/plain":"array([0.09185857, 0.21478112, 0.09101312, ..., 0.05281026, 0.10517685,\n       0.0347778 ], dtype=float32)"},"metadata":{}}]},{"cell_type":"code","source":"from lightgbm import LGBMClassifier\nfrom sklearn.metrics import accuracy_score, roc_auc_score, f1_score, precision_recall_curve\nfrom lightgbm.callback import early_stopping, log_evaluation","metadata":{"execution":{"iopub.status.busy":"2023-10-31T15:42:44.109750Z","iopub.execute_input":"2023-10-31T15:42:44.110175Z","iopub.status.idle":"2023-10-31T15:42:44.118742Z","shell.execute_reply.started":"2023-10-31T15:42:44.110144Z","shell.execute_reply":"2023-10-31T15:42:44.117614Z"},"trusted":true},"execution_count":143,"outputs":[]},{"cell_type":"code","source":"def lgbm_objective(trial):\n    # Гиперпараметры для оптимизации\n    params = {\n        'n_estimators': trial.suggest_int('n_estimators', 1000, 3500),\n        'learning_rate': trial.suggest_float('learning_rate', 0.005, 0.07),\n        'max_depth': trial.suggest_int('max_depth', 6, 25),\n        'num_leaves': trial.suggest_int('num_leaves', 50, 150),\n        'min_child_samples': trial.suggest_int('min_child_samples', 15, 55),\n        'feature_fraction': trial.suggest_float('feature_fraction', 0.1, 1),\n        'bagging_fraction': trial.suggest_float('bagging_fraction', 0.5, 1),\n        'bagging_freq': trial.suggest_int('bagging_freq', 1, 7),\n        'lambda_l1': trial.suggest_float('lambda_l1', 3.0, 12.0),\n        'lambda_l2': trial.suggest_float('lambda_l2', 3.0, 12.0),\n        'class_weight': 'balanced'\n    }\n\n    lgbm_model = LGBMClassifier(**params)\n    lgbm_model.fit(\n        X_train, y_train,\n        eval_set=[(X_val, y_val)],\n        callbacks=[early_stopping(50), log_evaluation(0)]\n        )\n\n    # Сохранение предсказаний\n    lgbm_model_preds = lgbm_model.predict_proba(X_test)[:, 1]\n\n    # Вычисление ROC AUC на out-of-fold предсказаниях\n    oof_roc_auc = roc_auc_score(y_test, lgbm_model_preds)\n\n    return oof_roc_auc","metadata":{"execution":{"iopub.status.busy":"2023-10-31T15:42:44.122946Z","iopub.execute_input":"2023-10-31T15:42:44.123422Z","iopub.status.idle":"2023-10-31T15:42:44.134504Z","shell.execute_reply.started":"2023-10-31T15:42:44.123382Z","shell.execute_reply":"2023-10-31T15:42:44.133393Z"},"trusted":true},"execution_count":144,"outputs":[]},{"cell_type":"code","source":"%%time\n# Запуск оптимизации\nlgbm_study = optuna.create_study(pruner=MedianPruner(), direction='maximize')\nlgbm_study.optimize(lgbm_objective,\n               n_jobs=-1,\n               show_progress_bar=True,\n               n_trials=20)\n\nlgbm_roc_auc_best = lgbm_study.best_value\nprint(f\"Best roc_auc: {lgbm_roc_auc_best}\")","metadata":{"execution":{"iopub.status.busy":"2023-10-31T15:42:44.136280Z","iopub.execute_input":"2023-10-31T15:42:44.136708Z","iopub.status.idle":"2023-10-31T15:44:59.064686Z","shell.execute_reply.started":"2023-10-31T15:42:44.136662Z","shell.execute_reply":"2023-10-31T15:44:59.063485Z"},"trusted":true},"execution_count":145,"outputs":[{"name":"stderr","text":"[I 2023-10-31 15:42:44,148] A new study created in memory with name: no-name-243e9f11-aade-45c3-9a68-63ea7ab4f6cd\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/20 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8d1d74d65e4440e4834a2f879d9bb804"}},"metadata":{}},{"name":"stdout","text":"[LightGBM] [Warning] lambda_l1 is set=6.409777695344145, reg_alpha=0.0 will be ignored. Current value: lambda_l1=6.409777695344145\n[LightGBM] [Warning] feature_fraction is set=0.15498922261728795, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.15498922261728795\n[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n[LightGBM] [Warning] lambda_l2 is set=7.372284506552304, reg_lambda=0.0 will be ignored. Current value: lambda_l2=7.372284506552304\n[LightGBM] [Warning] bagging_fraction is set=0.6954609859080949, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6954609859080949\n[LightGBM] [Warning] lambda_l1 is set=9.26177491674685, reg_alpha=0.0 will be ignored. Current value: lambda_l1=9.26177491674685\n[LightGBM] [Warning] feature_fraction is set=0.3408535269563131, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3408535269563131\n[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n[LightGBM] [Warning] lambda_l2 is set=9.319102124782564, reg_lambda=0.0 will be ignored. Current value: lambda_l2=9.319102124782564\n[LightGBM] [Warning] bagging_fraction is set=0.5239098964036879, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5239098964036879\n[LightGBM] [Warning] lambda_l1 is set=8.592927144684042, reg_alpha=0.0 will be ignored. Current value: lambda_l1=8.592927144684042\n[LightGBM] [Warning] feature_fraction is set=0.6758202498293022, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6758202498293022\n[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n[LightGBM] [Warning] lambda_l2 is set=10.341200704864093, reg_lambda=0.0 will be ignored. Current value: lambda_l2=10.341200704864093\n[LightGBM] [Warning] bagging_fraction is set=0.5532948120709098, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5532948120709098\n[LightGBM] [Warning] lambda_l1 is set=10.002735553428241, reg_alpha=0.0 will be ignored. Current value: lambda_l1=10.002735553428241\n[LightGBM] [Warning] feature_fraction is set=0.40688332380361025, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.40688332380361025\n[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n[LightGBM] [Warning] lambda_l2 is set=8.540015292677378, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8.540015292677378\n[LightGBM] [Warning] bagging_fraction is set=0.7411735190908953, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7411735190908953\nTraining until validation scores don't improve for 50 rounds\nTraining until validation scores don't improve for 50 rounds\nTraining until validation scores don't improve for 50 rounds\nTraining until validation scores don't improve for 50 rounds\nEarly stopping, best iteration is:\n[474]\tvalid_0's binary_logloss: 0.523774\n[I 2023-10-31 15:43:00,474] Trial 2 finished with value: 0.7113243173455555 and parameters: {'n_estimators': 1221, 'learning_rate': 0.06850433848704582, 'max_depth': 17, 'num_leaves': 118, 'min_child_samples': 25, 'feature_fraction': 0.6758202498293022, 'bagging_fraction': 0.5532948120709098, 'bagging_freq': 2, 'lambda_l1': 8.592927144684042, 'lambda_l2': 10.341200704864093}. Best is trial 2 with value: 0.7113243173455555.\n[LightGBM] [Warning] lambda_l1 is set=5.190811246813759, reg_alpha=0.0 will be ignored. Current value: lambda_l1=5.190811246813759\n[LightGBM] [Warning] feature_fraction is set=0.8850526324565248, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8850526324565248\n[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n[LightGBM] [Warning] lambda_l2 is set=8.837570280056461, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8.837570280056461\n[LightGBM] [Warning] bagging_fraction is set=0.5352557949249703, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5352557949249703\nTraining until validation scores don't improve for 50 rounds\nEarly stopping, best iteration is:\n[812]\tvalid_0's binary_logloss: 0.572087\n[I 2023-10-31 15:43:03,254] Trial 1 finished with value: 0.721342230972823 and parameters: {'n_estimators': 2343, 'learning_rate': 0.01815138992441224, 'max_depth': 25, 'num_leaves': 128, 'min_child_samples': 21, 'feature_fraction': 0.3408535269563131, 'bagging_fraction': 0.5239098964036879, 'bagging_freq': 7, 'lambda_l1': 9.26177491674685, 'lambda_l2': 9.319102124782564}. Best is trial 1 with value: 0.721342230972823.\n[LightGBM] [Warning] lambda_l1 is set=5.436193372188855, reg_alpha=0.0 will be ignored. Current value: lambda_l1=5.436193372188855\n[LightGBM] [Warning] feature_fraction is set=0.30995854106431187, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.30995854106431187\n[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n[LightGBM] [Warning] lambda_l2 is set=11.153545377072469, reg_lambda=0.0 will be ignored. Current value: lambda_l2=11.153545377072469\n[LightGBM] [Warning] bagging_fraction is set=0.7810459846489599, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7810459846489599\nTraining until validation scores don't improve for 50 rounds\nDid not meet early stopping. Best iteration is:\n[1208]\tvalid_0's binary_logloss: 0.524357\n[I 2023-10-31 15:43:06,934] Trial 3 finished with value: 0.7129672067652185 and parameters: {'n_estimators': 1237, 'learning_rate': 0.049105778398715196, 'max_depth': 11, 'num_leaves': 82, 'min_child_samples': 36, 'feature_fraction': 0.40688332380361025, 'bagging_fraction': 0.7411735190908953, 'bagging_freq': 2, 'lambda_l1': 10.002735553428241, 'lambda_l2': 8.540015292677378}. Best is trial 1 with value: 0.721342230972823.\n[LightGBM] [Warning] lambda_l1 is set=10.20089741663793, reg_alpha=0.0 will be ignored. Current value: lambda_l1=10.20089741663793\n[LightGBM] [Warning] feature_fraction is set=0.1749248165745746, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1749248165745746\n[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n[LightGBM] [Warning] lambda_l2 is set=4.779675898905472, reg_lambda=0.0 will be ignored. Current value: lambda_l2=4.779675898905472\n[LightGBM] [Warning] bagging_fraction is set=0.5787643071920667, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5787643071920667\nTraining until validation scores don't improve for 50 rounds\nDid not meet early stopping. Best iteration is:\n[1148]\tvalid_0's binary_logloss: 0.603663\n[I 2023-10-31 15:43:08,614] Trial 0 finished with value: 0.7144995481247176 and parameters: {'n_estimators': 1148, 'learning_rate': 0.008004724569370816, 'max_depth': 12, 'num_leaves': 130, 'min_child_samples': 50, 'feature_fraction': 0.15498922261728795, 'bagging_fraction': 0.6954609859080949, 'bagging_freq': 6, 'lambda_l1': 6.409777695344145, 'lambda_l2': 7.372284506552304}. Best is trial 1 with value: 0.721342230972823.\n[LightGBM] [Warning] lambda_l1 is set=8.738138201992655, reg_alpha=0.0 will be ignored. Current value: lambda_l1=8.738138201992655\n[LightGBM] [Warning] feature_fraction is set=0.4196189742251998, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4196189742251998\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n[LightGBM] [Warning] lambda_l2 is set=10.603514048506586, reg_lambda=0.0 will be ignored. Current value: lambda_l2=10.603514048506586\n[LightGBM] [Warning] bagging_fraction is set=0.9673467389872519, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9673467389872519\nTraining until validation scores don't improve for 50 rounds\nEarly stopping, best iteration is:\n[427]\tvalid_0's binary_logloss: 0.590621\n[I 2023-10-31 15:43:11,516] Trial 6 finished with value: 0.7111024143050804 and parameters: {'n_estimators': 2668, 'learning_rate': 0.04805281191052999, 'max_depth': 14, 'num_leaves': 72, 'min_child_samples': 34, 'feature_fraction': 0.1749248165745746, 'bagging_fraction': 0.5787643071920667, 'bagging_freq': 3, 'lambda_l1': 10.20089741663793, 'lambda_l2': 4.779675898905472}. Best is trial 1 with value: 0.721342230972823.\n[LightGBM] [Warning] lambda_l1 is set=8.278070522999062, reg_alpha=0.0 will be ignored. Current value: lambda_l1=8.278070522999062\n[LightGBM] [Warning] feature_fraction is set=0.7959698158052898, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7959698158052898\n[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n[LightGBM] [Warning] lambda_l2 is set=4.62630099966897, reg_lambda=0.0 will be ignored. Current value: lambda_l2=4.62630099966897\n[LightGBM] [Warning] bagging_fraction is set=0.6134203683484251, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6134203683484251\nTraining until validation scores don't improve for 50 rounds\nEarly stopping, best iteration is:\n[510]\tvalid_0's binary_logloss: 0.524654\n[I 2023-10-31 15:43:19,056] Trial 4 finished with value: 0.7099686914982893 and parameters: {'n_estimators': 2079, 'learning_rate': 0.046227998875859856, 'max_depth': 21, 'num_leaves': 108, 'min_child_samples': 47, 'feature_fraction': 0.8850526324565248, 'bagging_fraction': 0.5352557949249703, 'bagging_freq': 6, 'lambda_l1': 5.190811246813759, 'lambda_l2': 8.837570280056461}. Best is trial 1 with value: 0.721342230972823.\n[LightGBM] [Warning] lambda_l1 is set=8.499439080789763, reg_alpha=0.0 will be ignored. Current value: lambda_l1=8.499439080789763\n[LightGBM] [Warning] feature_fraction is set=0.3827769073073992, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3827769073073992\n[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n[LightGBM] [Warning] lambda_l2 is set=8.71289940803808, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8.71289940803808\n[LightGBM] [Warning] bagging_fraction is set=0.869677990077728, subsample=1.0 will be ignored. Current value: bagging_fraction=0.869677990077728\nTraining until validation scores don't improve for 50 rounds\nEarly stopping, best iteration is:\n[476]\tvalid_0's binary_logloss: 0.537216\n[I 2023-10-31 15:43:22,463] Trial 8 finished with value: 0.714554418694726 and parameters: {'n_estimators': 3150, 'learning_rate': 0.029979377430244772, 'max_depth': 17, 'num_leaves': 112, 'min_child_samples': 27, 'feature_fraction': 0.7959698158052898, 'bagging_fraction': 0.6134203683484251, 'bagging_freq': 2, 'lambda_l1': 8.278070522999062, 'lambda_l2': 4.62630099966897}. Best is trial 1 with value: 0.721342230972823.\n[LightGBM] [Warning] lambda_l1 is set=11.179286153730525, reg_alpha=0.0 will be ignored. Current value: lambda_l1=11.179286153730525\n[LightGBM] [Warning] feature_fraction is set=0.5234813942187486, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5234813942187486\n[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n[LightGBM] [Warning] lambda_l2 is set=9.751631826212563, reg_lambda=0.0 will be ignored. Current value: lambda_l2=9.751631826212563\n[LightGBM] [Warning] bagging_fraction is set=0.8728400755623045, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8728400755623045\nTraining until validation scores don't improve for 50 rounds\nEarly stopping, best iteration is:\n[801]\tvalid_0's binary_logloss: 0.514496\n[I 2023-10-31 15:43:31,694] Trial 7 finished with value: 0.7127453037247434 and parameters: {'n_estimators': 1510, 'learning_rate': 0.06478754455840645, 'max_depth': 10, 'num_leaves': 111, 'min_child_samples': 47, 'feature_fraction': 0.4196189742251998, 'bagging_fraction': 0.9673467389872519, 'bagging_freq': 5, 'lambda_l1': 8.738138201992655, 'lambda_l2': 10.603514048506586}. Best is trial 1 with value: 0.721342230972823.\n[LightGBM] [Warning] lambda_l1 is set=8.802829626699449, reg_alpha=0.0 will be ignored. Current value: lambda_l1=8.802829626699449\n[LightGBM] [Warning] feature_fraction is set=0.1852985795919479, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1852985795919479\n[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n[LightGBM] [Warning] lambda_l2 is set=4.9957054673076655, reg_lambda=0.0 will be ignored. Current value: lambda_l2=4.9957054673076655\n[LightGBM] [Warning] bagging_fraction is set=0.8874660597828523, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8874660597828523\nEarly stopping, best iteration is:\n[533]\tvalid_0's binary_logloss: 0.537771\nTraining until validation scores don't improve for 50 rounds\n[I 2023-10-31 15:43:32,280] Trial 10 finished with value: 0.7176529920599057 and parameters: {'n_estimators': 2402, 'learning_rate': 0.062156211937893495, 'max_depth': 20, 'num_leaves': 115, 'min_child_samples': 52, 'feature_fraction': 0.5234813942187486, 'bagging_fraction': 0.8728400755623045, 'bagging_freq': 7, 'lambda_l1': 11.179286153730525, 'lambda_l2': 9.751631826212563}. Best is trial 1 with value: 0.721342230972823.\n[LightGBM] [Warning] lambda_l1 is set=8.217519937038276, reg_alpha=0.0 will be ignored. Current value: lambda_l1=8.217519937038276\n[LightGBM] [Warning] feature_fraction is set=0.9855120772931161, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9855120772931161\n[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n[LightGBM] [Warning] lambda_l2 is set=7.561630973350094, reg_lambda=0.0 will be ignored. Current value: lambda_l2=7.561630973350094\n[LightGBM] [Warning] bagging_fraction is set=0.9896539091421973, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9896539091421973\nTraining until validation scores don't improve for 50 rounds\nEarly stopping, best iteration is:\n[971]\tvalid_0's binary_logloss: 0.49889\n[I 2023-10-31 15:43:47,885] Trial 5 finished with value: 0.7098992963656316 and parameters: {'n_estimators': 1956, 'learning_rate': 0.04195456122201692, 'max_depth': 23, 'num_leaves': 144, 'min_child_samples': 24, 'feature_fraction': 0.30995854106431187, 'bagging_fraction': 0.7810459846489599, 'bagging_freq': 7, 'lambda_l1': 5.436193372188855, 'lambda_l2': 11.153545377072469}. Best is trial 1 with value: 0.721342230972823.\n[LightGBM] [Warning] lambda_l1 is set=3.131600294262724, reg_alpha=0.0 will be ignored. Current value: lambda_l1=3.131600294262724\n[LightGBM] [Warning] feature_fraction is set=0.9913583299504607, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9913583299504607\n[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n[LightGBM] [Warning] lambda_l2 is set=11.939220362394057, reg_lambda=0.0 will be ignored. Current value: lambda_l2=11.939220362394057\n[LightGBM] [Warning] bagging_fraction is set=0.5006490790327357, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5006490790327357\nTraining until validation scores don't improve for 50 rounds\nEarly stopping, best iteration is:\n[1070]\tvalid_0's binary_logloss: 0.508919\n[I 2023-10-31 15:43:57,240] Trial 9 finished with value: 0.7129179846362403 and parameters: {'n_estimators': 2630, 'learning_rate': 0.06282099948918603, 'max_depth': 10, 'num_leaves': 143, 'min_child_samples': 38, 'feature_fraction': 0.3827769073073992, 'bagging_fraction': 0.869677990077728, 'bagging_freq': 2, 'lambda_l1': 8.499439080789763, 'lambda_l2': 8.71289940803808}. Best is trial 1 with value: 0.721342230972823.\n[LightGBM] [Warning] lambda_l1 is set=11.825466775246749, reg_alpha=0.0 will be ignored. Current value: lambda_l1=11.825466775246749\n[LightGBM] [Warning] feature_fraction is set=0.5722308537224348, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5722308537224348\n[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n[LightGBM] [Warning] lambda_l2 is set=11.89249173429608, reg_lambda=0.0 will be ignored. Current value: lambda_l2=11.89249173429608\n[LightGBM] [Warning] bagging_fraction is set=0.8557356038877586, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8557356038877586\nTraining until validation scores don't improve for 50 rounds\nDid not meet early stopping. Best iteration is:\n[1612]\tvalid_0's binary_logloss: 0.59755\nEarly stopping, best iteration is:\n[952]\tvalid_0's binary_logloss: 0.543576\n[I 2023-10-31 15:44:11,342] Trial 11 finished with value: 0.7125693951326577 and parameters: {'n_estimators': 1612, 'learning_rate': 0.006610222696734515, 'max_depth': 23, 'num_leaves': 93, 'min_child_samples': 29, 'feature_fraction': 0.1852985795919479, 'bagging_fraction': 0.8874660597828523, 'bagging_freq': 6, 'lambda_l1': 8.802829626699449, 'lambda_l2': 4.9957054673076655}. Best is trial 1 with value: 0.721342230972823.\n[I 2023-10-31 15:44:11,848] Trial 13 finished with value: 0.7135417339100123 and parameters: {'n_estimators': 3483, 'learning_rate': 0.016550377032815877, 'max_depth': 6, 'num_leaves': 56, 'min_child_samples': 16, 'feature_fraction': 0.9913583299504607, 'bagging_fraction': 0.5006490790327357, 'bagging_freq': 4, 'lambda_l1': 3.131600294262724, 'lambda_l2': 11.939220362394057}. Best is trial 1 with value: 0.721342230972823.\n[LightGBM] [Warning] lambda_l1 is set=11.934716845032083, reg_alpha=0.0 will be ignored. Current value: lambda_l1=11.934716845032083\n[LightGBM] [Warning] feature_fraction is set=0.5705125571902175, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5705125571902175\n[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n[LightGBM] [Warning] lambda_l2 is set=11.8007963770752, reg_lambda=0.0 will be ignored. Current value: lambda_l2=11.8007963770752\n[LightGBM] [Warning] bagging_fraction is set=0.6579959561344709, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6579959561344709\nTraining until validation scores don't improve for 50 rounds\n[LightGBM] [Warning] lambda_l1 is set=11.906446094648366, reg_alpha=0.0 will be ignored. Current value: lambda_l1=11.906446094648366\n[LightGBM] [Warning] feature_fraction is set=0.5635345090916233, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5635345090916233\n[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n[LightGBM] [Warning] lambda_l2 is set=9.741963915218417, reg_lambda=0.0 will be ignored. Current value: lambda_l2=9.741963915218417\n[LightGBM] [Warning] bagging_fraction is set=0.6505111015699974, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6505111015699974\nTraining until validation scores don't improve for 50 rounds\nEarly stopping, best iteration is:\n[631]\tvalid_0's binary_logloss: 0.563002\n[I 2023-10-31 15:44:25,608] Trial 16 finished with value: 0.7210912788070492 and parameters: {'n_estimators': 2491, 'learning_rate': 0.02949905629942362, 'max_depth': 25, 'num_leaves': 130, 'min_child_samples': 54, 'feature_fraction': 0.5635345090916233, 'bagging_fraction': 0.6505111015699974, 'bagging_freq': 7, 'lambda_l1': 11.906446094648366, 'lambda_l2': 9.741963915218417}. Best is trial 1 with value: 0.721342230972823.\n[LightGBM] [Warning] lambda_l1 is set=11.692481326667451, reg_alpha=0.0 will be ignored. Current value: lambda_l1=11.692481326667451\n[LightGBM] [Warning] feature_fraction is set=0.5378620426289538, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5378620426289538\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n[LightGBM] [Warning] lambda_l2 is set=7.142101395638226, reg_lambda=0.0 will be ignored. Current value: lambda_l2=7.142101395638226\n[LightGBM] [Warning] bagging_fraction is set=0.6420553000099949, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6420553000099949\nTraining until validation scores don't improve for 50 rounds\nEarly stopping, best iteration is:\n[969]\tvalid_0's binary_logloss: 0.538921\n[I 2023-10-31 15:44:34,839] Trial 14 finished with value: 0.7199067200309858 and parameters: {'n_estimators': 2411, 'learning_rate': 0.024430075367151093, 'max_depth': 25, 'num_leaves': 93, 'min_child_samples': 16, 'feature_fraction': 0.5722308537224348, 'bagging_fraction': 0.8557356038877586, 'bagging_freq': 7, 'lambda_l1': 11.825466775246749, 'lambda_l2': 11.89249173429608}. Best is trial 1 with value: 0.721342230972823.\n[LightGBM] [Warning] lambda_l1 is set=11.95590154540109, reg_alpha=0.0 will be ignored. Current value: lambda_l1=11.95590154540109\n[LightGBM] [Warning] feature_fraction is set=0.6061011199740687, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6061011199740687\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n[LightGBM] [Warning] lambda_l2 is set=7.133920367425215, reg_lambda=0.0 will be ignored. Current value: lambda_l2=7.133920367425215\n[LightGBM] [Warning] bagging_fraction is set=0.6519544391430381, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6519544391430381\nTraining until validation scores don't improve for 50 rounds\nEarly stopping, best iteration is:\n[633]\tvalid_0's binary_logloss: 0.556308\n[I 2023-10-31 15:44:37,971] Trial 15 finished with value: 0.7234765347621199 and parameters: {'n_estimators': 2563, 'learning_rate': 0.026744495802093586, 'max_depth': 20, 'num_leaves': 51, 'min_child_samples': 18, 'feature_fraction': 0.5705125571902175, 'bagging_fraction': 0.6579959561344709, 'bagging_freq': 7, 'lambda_l1': 11.934716845032083, 'lambda_l2': 11.8007963770752}. Best is trial 15 with value: 0.7234765347621199.\n[LightGBM] [Warning] lambda_l1 is set=10.40178646988874, reg_alpha=0.0 will be ignored. Current value: lambda_l1=10.40178646988874\n[LightGBM] [Warning] feature_fraction is set=0.6757867631804788, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6757867631804788\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n[LightGBM] [Warning] lambda_l2 is set=7.339461945673081, reg_lambda=0.0 will be ignored. Current value: lambda_l2=7.339461945673081\n[LightGBM] [Warning] bagging_fraction is set=0.6253561585628825, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6253561585628825\nTraining until validation scores don't improve for 50 rounds\nEarly stopping, best iteration is:\n[435]\tvalid_0's binary_logloss: 0.561356\n[I 2023-10-31 15:44:44,263] Trial 17 finished with value: 0.7212260344716287 and parameters: {'n_estimators': 2890, 'learning_rate': 0.02908296188389653, 'max_depth': 25, 'num_leaves': 131, 'min_child_samples': 15, 'feature_fraction': 0.5378620426289538, 'bagging_fraction': 0.6420553000099949, 'bagging_freq': 5, 'lambda_l1': 11.692481326667451, 'lambda_l2': 7.142101395638226}. Best is trial 15 with value: 0.7234765347621199.\nDid not meet early stopping. Best iteration is:\n[3058]\tvalid_0's binary_logloss: 0.512853\n[I 2023-10-31 15:44:51,893] Trial 12 finished with value: 0.7112944613001098 and parameters: {'n_estimators': 3058, 'learning_rate': 0.006894024657393918, 'max_depth': 19, 'num_leaves': 84, 'min_child_samples': 47, 'feature_fraction': 0.9855120772931161, 'bagging_fraction': 0.9896539091421973, 'bagging_freq': 3, 'lambda_l1': 8.217519937038276, 'lambda_l2': 7.561630973350094}. Best is trial 15 with value: 0.7234765347621199.\nEarly stopping, best iteration is:\n[710]\tvalid_0's binary_logloss: 0.555747\n[I 2023-10-31 15:44:53,338] Trial 18 finished with value: 0.7183388741850106 and parameters: {'n_estimators': 2875, 'learning_rate': 0.031341465988333206, 'max_depth': 25, 'num_leaves': 135, 'min_child_samples': 42, 'feature_fraction': 0.6061011199740687, 'bagging_fraction': 0.6519544391430381, 'bagging_freq': 5, 'lambda_l1': 11.95590154540109, 'lambda_l2': 7.133920367425215}. Best is trial 15 with value: 0.7234765347621199.\nEarly stopping, best iteration is:\n[970]\tvalid_0's binary_logloss: 0.5436\n[I 2023-10-31 15:44:59,054] Trial 19 finished with value: 0.7193781873345814 and parameters: {'n_estimators': 2968, 'learning_rate': 0.017788456107978683, 'max_depth': 19, 'num_leaves': 52, 'min_child_samples': 21, 'feature_fraction': 0.6757867631804788, 'bagging_fraction': 0.6253561585628825, 'bagging_freq': 5, 'lambda_l1': 10.40178646988874, 'lambda_l2': 7.339461945673081}. Best is trial 15 with value: 0.7234765347621199.\nBest roc_auc: 0.7234765347621199\nCPU times: user 3min 59s, sys: 3min 6s, total: 7min 6s\nWall time: 2min 14s\n","output_type":"stream"}]},{"cell_type":"code","source":"# Обучение с лучшими гиперпараметрами\nbest_params = lgbm_study.best_params\nlgbm_model = LGBMClassifier(**best_params)\nlgbm_model.fit(X_train, y_train)\n\n# Предсказания на тестовой выборке\nlgbm_test_preds = lgbm_model.predict_proba(X_test)[:, 1]","metadata":{"execution":{"iopub.status.busy":"2023-10-31T15:44:59.066367Z","iopub.execute_input":"2023-10-31T15:44:59.066826Z","iopub.status.idle":"2023-10-31T15:45:18.464651Z","shell.execute_reply.started":"2023-10-31T15:44:59.066782Z","shell.execute_reply":"2023-10-31T15:45:18.463706Z"},"trusted":true},"execution_count":146,"outputs":[{"name":"stdout","text":"[LightGBM] [Warning] lambda_l1 is set=11.934716845032083, reg_alpha=0.0 will be ignored. Current value: lambda_l1=11.934716845032083\n[LightGBM] [Warning] feature_fraction is set=0.5705125571902175, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5705125571902175\n[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n[LightGBM] [Warning] lambda_l2 is set=11.8007963770752, reg_lambda=0.0 will be ignored. Current value: lambda_l2=11.8007963770752\n[LightGBM] [Warning] bagging_fraction is set=0.6579959561344709, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6579959561344709\n","output_type":"stream"}]},{"cell_type":"code","source":"# Определение оптимального порога\nprecision, recall, thresholds = precision_recall_curve(y_test, lgbm_test_preds)\nf1_scores = 2 * (precision * recall) / (precision + recall)\noptimal_threshold = thresholds[f1_scores[:-1].argmax()]\n# Применение оптимального порога для классификации\ny_pred_optimal = (lgbm_test_preds > optimal_threshold).astype(int)\n\n# Оценка качества модели с новым порогом на тестовой выборке\naccuracy = accuracy_score(y_test, y_pred_optimal)\nroc_auc = roc_auc_score(y_test, lgbm_test_preds)\nf1 = f1_score(y_test, y_pred_optimal)\n\nprint(f\"Accuracy: {accuracy}\")\nprint(f\"ROC AUC: {roc_auc}\")\nprint(f\"F1 Score: {f1}\")","metadata":{"execution":{"iopub.status.busy":"2023-10-31T15:45:18.465782Z","iopub.execute_input":"2023-10-31T15:45:18.466700Z","iopub.status.idle":"2023-10-31T15:45:18.485169Z","shell.execute_reply.started":"2023-10-31T15:45:18.466667Z","shell.execute_reply":"2023-10-31T15:45:18.483917Z"},"trusted":true},"execution_count":147,"outputs":[{"name":"stdout","text":"Accuracy: 0.711864406779661\nROC AUC: 0.717932993350978\nF1 Score: 0.4455239417071478\n","output_type":"stream"}]},{"cell_type":"code","source":"lgbm_test_preds","metadata":{"execution":{"iopub.status.busy":"2023-10-31T15:45:18.486552Z","iopub.execute_input":"2023-10-31T15:45:18.487398Z","iopub.status.idle":"2023-10-31T15:45:18.495237Z","shell.execute_reply.started":"2023-10-31T15:45:18.487354Z","shell.execute_reply":"2023-10-31T15:45:18.494007Z"},"trusted":true},"execution_count":148,"outputs":[{"execution_count":148,"output_type":"execute_result","data":{"text/plain":"array([0.09973263, 0.30152035, 0.15214354, ..., 0.12434203, 0.29900278,\n       0.05742968])"},"metadata":{}}]},{"cell_type":"code","source":"df_preds = pd.DataFrame()","metadata":{"execution":{"iopub.status.busy":"2023-10-31T15:45:18.496702Z","iopub.execute_input":"2023-10-31T15:45:18.497050Z","iopub.status.idle":"2023-10-31T15:45:18.504942Z","shell.execute_reply.started":"2023-10-31T15:45:18.497019Z","shell.execute_reply":"2023-10-31T15:45:18.503962Z"},"trusted":true},"execution_count":149,"outputs":[]},{"cell_type":"code","source":"df_preds['catboost_preds'] = y_pred_proba\ndf_preds['XGBoost_preds'] = y_prob_test\ndf_preds['LGBM_preds'] = lgbm_test_preds\ndf_preds['Real_class'] = y_test.reset_index(drop=True)","metadata":{"execution":{"iopub.status.busy":"2023-10-31T15:45:18.505963Z","iopub.execute_input":"2023-10-31T15:45:18.506668Z","iopub.status.idle":"2023-10-31T15:45:18.520452Z","shell.execute_reply.started":"2023-10-31T15:45:18.506618Z","shell.execute_reply":"2023-10-31T15:45:18.519381Z"},"trusted":true},"execution_count":150,"outputs":[]},{"cell_type":"code","source":"df_preds","metadata":{"execution":{"iopub.status.busy":"2023-10-31T15:45:18.521854Z","iopub.execute_input":"2023-10-31T15:45:18.522192Z","iopub.status.idle":"2023-10-31T15:45:18.542518Z","shell.execute_reply.started":"2023-10-31T15:45:18.522154Z","shell.execute_reply":"2023-10-31T15:45:18.541279Z"},"trusted":true},"execution_count":151,"outputs":[{"execution_count":151,"output_type":"execute_result","data":{"text/plain":"      catboost_preds  XGBoost_preds  LGBM_preds  Real_class\n0           0.450911       0.091859    0.099733           0\n1           0.399373       0.214781    0.301520           0\n2           0.361224       0.091013    0.152144           0\n3           0.187130       0.029062    0.040717           0\n4           0.298977       0.022129    0.095674           0\n...              ...            ...         ...         ...\n2768        0.742135       0.272055    0.390383           1\n2769        0.537838       0.318988    0.403494           0\n2770        0.513000       0.052810    0.124342           0\n2771        0.581785       0.105177    0.299003           0\n2772        0.513486       0.034778    0.057430           0\n\n[2773 rows x 4 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>catboost_preds</th>\n      <th>XGBoost_preds</th>\n      <th>LGBM_preds</th>\n      <th>Real_class</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.450911</td>\n      <td>0.091859</td>\n      <td>0.099733</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.399373</td>\n      <td>0.214781</td>\n      <td>0.301520</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.361224</td>\n      <td>0.091013</td>\n      <td>0.152144</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.187130</td>\n      <td>0.029062</td>\n      <td>0.040717</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.298977</td>\n      <td>0.022129</td>\n      <td>0.095674</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>2768</th>\n      <td>0.742135</td>\n      <td>0.272055</td>\n      <td>0.390383</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2769</th>\n      <td>0.537838</td>\n      <td>0.318988</td>\n      <td>0.403494</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2770</th>\n      <td>0.513000</td>\n      <td>0.052810</td>\n      <td>0.124342</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2771</th>\n      <td>0.581785</td>\n      <td>0.105177</td>\n      <td>0.299003</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2772</th>\n      <td>0.513486</td>\n      <td>0.034778</td>\n      <td>0.057430</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>2773 rows × 4 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"# df_preds.to_csv('df_preds_V4.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2023-10-31T15:45:18.544242Z","iopub.execute_input":"2023-10-31T15:45:18.544636Z","iopub.status.idle":"2023-10-31T15:45:18.553179Z","shell.execute_reply.started":"2023-10-31T15:45:18.544606Z","shell.execute_reply":"2023-10-31T15:45:18.552307Z"},"trusted":true},"execution_count":152,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import accuracy_score, roc_auc_score, precision_score, recall_score, f1_score","metadata":{"execution":{"iopub.status.busy":"2023-10-31T15:45:18.554591Z","iopub.execute_input":"2023-10-31T15:45:18.555097Z","iopub.status.idle":"2023-10-31T15:45:18.563762Z","shell.execute_reply.started":"2023-10-31T15:45:18.555062Z","shell.execute_reply":"2023-10-31T15:45:18.562731Z"},"trusted":true},"execution_count":153,"outputs":[]},{"cell_type":"code","source":"# Инициализация словаря для хранения метрик новых данных\nmetrics_new = {}\n\nmodel_names = ['catboost_preds', 'XGBoost_preds', 'LGBM_preds']\nthresholds = np.linspace(0.01, 1, 300)\nmetrics_optimal_threshold = {}\n\n# Расчет метрик для каждой модели в новом наборе данных\nfor model in model_names:\n    f1_scores = [f1_score(df_preds['Real_class'], df_preds[model] > thresh) for thresh in thresholds]\n    \n    # Определение оптимального порога\n    optimal_threshold = thresholds[np.argmax(f1_scores)]\n    print(model, optimal_threshold)\n    # Бинаризация предсказаний на основе оптимального порога\n    predictions_optimal = (df_preds[model] >= optimal_threshold).astype(int)\n    \n    # Расчет метрик\n    accuracy_new = accuracy_score(df_preds['Real_class'], predictions_optimal)\n    auc_roc_new = roc_auc_score(df_preds['Real_class'], df_preds[model])\n    precision_new = precision_score(df_preds['Real_class'], predictions_optimal)\n    recall_new = recall_score(df_preds['Real_class'], predictions_optimal)\n    f1_new = f1_score(df_preds['Real_class'], predictions_optimal)\n    \n    # Сохранение метрик в словаре\n    metrics_new[model] = {\n        'Accuracy': accuracy_new,\n        'AUC ROC': auc_roc_new,\n        'Precision': precision_new,\n        'Recall': recall_new,\n        'F1 Score': f1_new\n    }\n\nmetrics_new_df = pd.DataFrame(metrics_new).T\nmetrics_new_df","metadata":{"execution":{"iopub.status.busy":"2023-10-31T16:24:25.934207Z","iopub.execute_input":"2023-10-31T16:24:25.934671Z","iopub.status.idle":"2023-10-31T16:24:29.184236Z","shell.execute_reply.started":"2023-10-31T16:24:25.934639Z","shell.execute_reply":"2023-10-31T16:24:29.183305Z"},"trusted":true},"execution_count":210,"outputs":[{"name":"stdout","text":"catboost_preds 0.4603010033444816\nXGBoost_preds 0.14244147157190637\nLGBM_preds 0.2583277591973244\n","output_type":"stream"},{"execution_count":210,"output_type":"execute_result","data":{"text/plain":"                Accuracy   AUC ROC  Precision    Recall  F1 Score\ncatboost_preds  0.702128  0.732683   0.364008  0.635714  0.462939\nXGBoost_preds   0.710783  0.723736   0.364955  0.583929  0.449176\nLGBM_preds      0.741435  0.717933   0.392613  0.512500  0.444617","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Accuracy</th>\n      <th>AUC ROC</th>\n      <th>Precision</th>\n      <th>Recall</th>\n      <th>F1 Score</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>catboost_preds</th>\n      <td>0.702128</td>\n      <td>0.732683</td>\n      <td>0.364008</td>\n      <td>0.635714</td>\n      <td>0.462939</td>\n    </tr>\n    <tr>\n      <th>XGBoost_preds</th>\n      <td>0.710783</td>\n      <td>0.723736</td>\n      <td>0.364955</td>\n      <td>0.583929</td>\n      <td>0.449176</td>\n    </tr>\n    <tr>\n      <th>LGBM_preds</th>\n      <td>0.741435</td>\n      <td>0.717933</td>\n      <td>0.392613</td>\n      <td>0.512500</td>\n      <td>0.444617</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"cat_pred_test = CatBoost_model.predict_proba(test_cv)[:, 1]","metadata":{"execution":{"iopub.status.busy":"2023-10-31T17:59:35.445468Z","iopub.execute_input":"2023-10-31T17:59:35.445906Z","iopub.status.idle":"2023-10-31T17:59:35.496718Z","shell.execute_reply.started":"2023-10-31T17:59:35.445868Z","shell.execute_reply":"2023-10-31T17:59:35.495693Z"},"trusted":true},"execution_count":264,"outputs":[]},{"cell_type":"code","source":"XGB_pred_test = best_model.predict_proba(test_cv)[:, 1]\nLGBM_pred_test = lgbm_model.predict_proba(test_cv)[:, 1]","metadata":{"execution":{"iopub.status.busy":"2023-10-31T15:49:23.622938Z","iopub.execute_input":"2023-10-31T15:49:23.623349Z","iopub.status.idle":"2023-10-31T15:49:26.048922Z","shell.execute_reply.started":"2023-10-31T15:49:23.623301Z","shell.execute_reply":"2023-10-31T15:49:26.047934Z"},"trusted":true},"execution_count":159,"outputs":[]},{"cell_type":"code","source":"cat_optimal_threshold = 0.4603010033444816\nXGB_optimal_threshold = 0.14244147157190637\nLGBM_optimal_threshold = 0.2583277591973244","metadata":{"execution":{"iopub.status.busy":"2023-10-31T15:49:38.341993Z","iopub.execute_input":"2023-10-31T15:49:38.342400Z","iopub.status.idle":"2023-10-31T15:49:38.348833Z","shell.execute_reply.started":"2023-10-31T15:49:38.342368Z","shell.execute_reply":"2023-10-31T15:49:38.347387Z"},"trusted":true},"execution_count":160,"outputs":[]},{"cell_type":"code","source":"cat_final_predictions = (cat_pred_test > optimal_threshold).astype(int)\nXGB_final_predictions = (XGB_pred_test > optimal_threshold).astype(int)\nLGBM_final_predictions = (LGBM_pred_test > optimal_threshold).astype(int)","metadata":{"execution":{"iopub.status.busy":"2023-10-31T18:00:24.876610Z","iopub.execute_input":"2023-10-31T18:00:24.877048Z","iopub.status.idle":"2023-10-31T18:00:24.883062Z","shell.execute_reply.started":"2023-10-31T18:00:24.877011Z","shell.execute_reply":"2023-10-31T18:00:24.882037Z"},"trusted":true},"execution_count":265,"outputs":[]},{"cell_type":"code","source":"test_preds_df = pd.DataFrame()\ntest_preds_df['cat_final_predictions'] = cat_final_predictions\n# test_preds_df['XGB_final_predictions'] = XGB_final_predictions\n# test_preds_df['LGBM_final_predictions'] = LGBM_final_predictions","metadata":{"execution":{"iopub.status.busy":"2023-10-31T18:00:27.451413Z","iopub.execute_input":"2023-10-31T18:00:27.451866Z","iopub.status.idle":"2023-10-31T18:00:27.459124Z","shell.execute_reply.started":"2023-10-31T18:00:27.451829Z","shell.execute_reply":"2023-10-31T18:00:27.458085Z"},"trusted":true},"execution_count":266,"outputs":[]},{"cell_type":"code","source":"test_preds_df","metadata":{"execution":{"iopub.status.busy":"2023-10-31T18:00:28.142950Z","iopub.execute_input":"2023-10-31T18:00:28.143680Z","iopub.status.idle":"2023-10-31T18:00:28.155919Z","shell.execute_reply.started":"2023-10-31T18:00:28.143642Z","shell.execute_reply":"2023-10-31T18:00:28.154681Z"},"trusted":true},"execution_count":267,"outputs":[{"execution_count":267,"output_type":"execute_result","data":{"text/plain":"      cat_final_predictions\n0                         1\n1                         0\n2                         0\n3                         0\n4                         1\n...                     ...\n5937                      0\n5938                      0\n5939                      0\n5940                      0\n5941                      0\n\n[5942 rows x 1 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>cat_final_predictions</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>5937</th>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>5938</th>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>5939</th>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>5940</th>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>5941</th>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>5942 rows × 1 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"test_preds_df.to_csv('test_preds_df.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2023-10-31T15:59:15.244607Z","iopub.execute_input":"2023-10-31T15:59:15.245051Z","iopub.status.idle":"2023-10-31T15:59:15.267516Z","shell.execute_reply.started":"2023-10-31T15:59:15.245013Z","shell.execute_reply":"2023-10-31T15:59:15.266123Z"},"trusted":true},"execution_count":170,"outputs":[]},{"cell_type":"code","source":"test_preds_df['Consensus'] = test_preds_df.apply(lambda x: x.value_counts().max()/3, axis=1)","metadata":{"execution":{"iopub.status.busy":"2023-10-31T16:26:19.230522Z","iopub.execute_input":"2023-10-31T16:26:19.230922Z","iopub.status.idle":"2023-10-31T16:26:21.240289Z","shell.execute_reply.started":"2023-10-31T16:26:19.230892Z","shell.execute_reply":"2023-10-31T16:26:21.239146Z"},"trusted":true},"execution_count":213,"outputs":[]},{"cell_type":"code","source":"# Окончательное предсказание на основе голосования\ntest_preds_df['Final_Prediction'] = test_preds_df.mode(axis=1)[0].astype(int)","metadata":{"execution":{"iopub.status.busy":"2023-10-31T18:00:36.952033Z","iopub.execute_input":"2023-10-31T18:00:36.952453Z","iopub.status.idle":"2023-10-31T18:00:38.206707Z","shell.execute_reply.started":"2023-10-31T18:00:36.952419Z","shell.execute_reply":"2023-10-31T18:00:38.205631Z"},"trusted":true},"execution_count":268,"outputs":[]},{"cell_type":"code","source":"test_preds_df.iloc[:30,:]","metadata":{"execution":{"iopub.status.busy":"2023-10-31T18:00:38.208792Z","iopub.execute_input":"2023-10-31T18:00:38.209137Z","iopub.status.idle":"2023-10-31T18:00:38.220915Z","shell.execute_reply.started":"2023-10-31T18:00:38.209107Z","shell.execute_reply":"2023-10-31T18:00:38.219843Z"},"trusted":true},"execution_count":269,"outputs":[{"execution_count":269,"output_type":"execute_result","data":{"text/plain":"    cat_final_predictions  Final_Prediction\n0                       1                 1\n1                       0                 0\n2                       0                 0\n3                       0                 0\n4                       1                 1\n5                       0                 0\n6                       1                 1\n7                       0                 0\n8                       1                 1\n9                       0                 0\n10                      1                 1\n11                      0                 0\n12                      1                 1\n13                      0                 0\n14                      0                 0\n15                      0                 0\n16                      0                 0\n17                      1                 1\n18                      0                 0\n19                      0                 0\n20                      0                 0\n21                      0                 0\n22                      1                 1\n23                      0                 0\n24                      1                 1\n25                      1                 1\n26                      0                 0\n27                      1                 1\n28                      0                 0\n29                      1                 1","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>cat_final_predictions</th>\n      <th>Final_Prediction</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>20</th>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>21</th>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>22</th>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>23</th>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>24</th>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>25</th>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>26</th>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>27</th>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>28</th>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>29</th>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"test_preds_df['Final_Prediction'].sum()","metadata":{"execution":{"iopub.status.busy":"2023-10-31T18:00:47.481496Z","iopub.execute_input":"2023-10-31T18:00:47.481897Z","iopub.status.idle":"2023-10-31T18:00:47.492591Z","shell.execute_reply.started":"2023-10-31T18:00:47.481865Z","shell.execute_reply":"2023-10-31T18:00:47.491461Z"},"trusted":true},"execution_count":270,"outputs":[{"execution_count":270,"output_type":"execute_result","data":{"text/plain":"2129"},"metadata":{}}]},{"cell_type":"code","source":"submission = pd.read_csv(r'/kaggle/input/leopard-challenge-classification/sample_submission.csv')","metadata":{"execution":{"iopub.status.busy":"2023-10-31T18:00:55.542952Z","iopub.execute_input":"2023-10-31T18:00:55.543413Z","iopub.status.idle":"2023-10-31T18:00:55.558303Z","shell.execute_reply.started":"2023-10-31T18:00:55.543374Z","shell.execute_reply":"2023-10-31T18:00:55.557148Z"},"trusted":true},"execution_count":271,"outputs":[]},{"cell_type":"code","source":"submission['smoking'] = test_preds_df['Final_Prediction']\nsubmission.to_csv('Catboost_only_submission_20_4.csv', index = False)","metadata":{"execution":{"iopub.status.busy":"2023-10-31T18:01:00.267474Z","iopub.execute_input":"2023-10-31T18:01:00.267865Z","iopub.status.idle":"2023-10-31T18:01:00.291025Z","shell.execute_reply.started":"2023-10-31T18:01:00.267835Z","shell.execute_reply":"2023-10-31T18:01:00.290083Z"},"trusted":true},"execution_count":272,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}