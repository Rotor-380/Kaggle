{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install imbalanced-learn","metadata":{"execution":{"iopub.status.busy":"2023-10-11T21:51:17.329398Z","iopub.execute_input":"2023-10-11T21:51:17.329917Z","iopub.status.idle":"2023-10-11T21:51:31.155017Z","shell.execute_reply.started":"2023-10-11T21:51:17.329878Z","shell.execute_reply":"2023-10-11T21:51:31.153010Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Requirement already satisfied: imbalanced-learn in /opt/conda/lib/python3.10/site-packages (0.11.0)\nRequirement already satisfied: numpy>=1.17.3 in /opt/conda/lib/python3.10/site-packages (from imbalanced-learn) (1.23.5)\nRequirement already satisfied: scipy>=1.5.0 in /opt/conda/lib/python3.10/site-packages (from imbalanced-learn) (1.11.2)\nRequirement already satisfied: scikit-learn>=1.0.2 in /opt/conda/lib/python3.10/site-packages (from imbalanced-learn) (1.2.2)\nRequirement already satisfied: joblib>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from imbalanced-learn) (1.3.2)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from imbalanced-learn) (3.1.0)\n","output_type":"stream"}]},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom phik.report import plot_correlation_matrix\nfrom catboost import CatBoostClassifier, Pool\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, \\\n    classification_report, roc_auc_score\nfrom sklearn.preprocessing import PolynomialFeatures\nimport matplotlib.pyplot as plt\nplt.style.use('dark_background')","metadata":{"execution":{"iopub.status.busy":"2023-10-12T18:57:40.670102Z","iopub.execute_input":"2023-10-12T18:57:40.670453Z","iopub.status.idle":"2023-10-12T18:57:43.763202Z","shell.execute_reply.started":"2023-10-12T18:57:40.670410Z","shell.execute_reply":"2023-10-12T18:57:43.762259Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"df_raw = pd.read_csv('/kaggle/input/leopard-challenge-classification/train.csv')\ntest = pd.read_csv(r'/kaggle/input/leopard-challenge-classification/test.csv')\ndf_raw.shape, test.shape","metadata":{"execution":{"iopub.status.busy":"2023-10-12T18:57:43.765834Z","iopub.execute_input":"2023-10-12T18:57:43.766575Z","iopub.status.idle":"2023-10-12T18:57:43.896175Z","shell.execute_reply.started":"2023-10-12T18:57:43.766531Z","shell.execute_reply":"2023-10-12T18:57:43.894847Z"},"trusted":true},"execution_count":2,"outputs":[{"execution_count":2,"output_type":"execute_result","data":{"text/plain":"((13863, 26), (5942, 25))"},"metadata":{}}]},{"cell_type":"code","source":"test_cv = test.drop(['oral', 'ID'], axis = 1).copy()\ntest_cv['tartar'] = test_cv['tartar'].apply(lambda x: 1 if x == 'Y' else 0)","metadata":{"execution":{"iopub.status.busy":"2023-10-12T18:57:43.897779Z","iopub.execute_input":"2023-10-12T18:57:43.898198Z","iopub.status.idle":"2023-10-12T18:57:43.928933Z","shell.execute_reply.started":"2023-10-12T18:57:43.898154Z","shell.execute_reply":"2023-10-12T18:57:43.926893Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"merged_data = df_raw.drop(['oral', 'ID'], axis=1).copy()\nmerged_data['tartar'] = merged_data['tartar'].apply(lambda x: 1 if x == 'Y' else 0)","metadata":{"execution":{"iopub.status.busy":"2023-10-12T18:57:43.931980Z","iopub.execute_input":"2023-10-12T18:57:43.932765Z","iopub.status.idle":"2023-10-12T18:57:43.951061Z","shell.execute_reply.started":"2023-10-12T18:57:43.932701Z","shell.execute_reply":"2023-10-12T18:57:43.949856Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"# Создание бинарного признака на основе BMI\nmerged_data['BMI'] = merged_data['weight(kg)'] / ((merged_data['height(cm)'] / 100) ** 2)\nmerged_data['BMI_status'] = (merged_data['BMI'] < 18.5) | (merged_data['BMI'] >= 24.9)\nmerged_data['BMI_status'] = merged_data['BMI_status'].astype(int)\nmerged_data['log_tr'] = merged_data['triglyceride'].apply(np.log)\nmerged_data['log_gtp'] = merged_data['Gtp'].apply(np.log)\nmerged_data['log_log_alt'] = np.log(np.log(merged_data['ALT']))\nmerged_data['BMI_log_gtp'] = merged_data['BMI'].apply(np.log)\nmerged_data = merged_data.drop(['triglyceride', 'Gtp', 'ALT', 'BMI'], axis=1)\n\ntest_cv['BMI'] = test_cv['weight(kg)'] / ((test_cv['height(cm)'] / 100) ** 2)\ntest_cv['BMI_status'] = (test_cv['BMI'] < 18.5) | (test_cv['BMI'] >= 24.9)\ntest_cv['BMI_status'] = test_cv['BMI_status'].astype(int)\ntest_cv['log_tr'] = test_cv['triglyceride'].apply(np.log)\ntest_cv['log_gtp'] = test_cv['Gtp'].apply(np.log)\ntest_cv['log_log_alt'] = np.log(np.log(test_cv['ALT']))\ntest_cv['BMI_log_gtp'] = test_cv['BMI'].apply(np.log)\ntest_cv = test_cv.drop(['triglyceride', 'Gtp', 'ALT', 'BMI'], axis=1)","metadata":{"execution":{"iopub.status.busy":"2023-10-12T18:57:43.953049Z","iopub.execute_input":"2023-10-12T18:57:43.954023Z","iopub.status.idle":"2023-10-12T18:57:43.982889Z","shell.execute_reply.started":"2023-10-12T18:57:43.953978Z","shell.execute_reply":"2023-10-12T18:57:43.981505Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n# polynom = PolynomialFeatures(interaction_only=True, include_bias=False)\n# from imblearn.over_sampling import SMOTE\n\nX = merged_data.drop(['smoking'], axis=1) \nY = merged_data['smoking']\n\n# X_poly = pd.DataFrame(polynom.fit_transform(X))\n# test_cv_poly = pd.DataFrame(polynom.transform(test_cv))\n\n# Применение SMOTE\n# X_new_train, X_test_sim, Y_new_train, Y_test_sim = train_test_split(X, Y, test_size=0.3, random_state=42, stratify=Y)\n# X_new_train.shape, X_test_sim.shape, Y_new_train.shape, Y_test_sim.shape","metadata":{"execution":{"iopub.status.busy":"2023-10-12T18:57:43.984507Z","iopub.execute_input":"2023-10-12T18:57:43.985405Z","iopub.status.idle":"2023-10-12T18:57:43.995766Z","shell.execute_reply.started":"2023-10-12T18:57:43.985365Z","shell.execute_reply":"2023-10-12T18:57:43.994335Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"from sklearn.preprocessing import MinMaxScaler\n\n# Масштабирование признаков\nscaler = MinMaxScaler()\n\nX_scale = scaler.fit_transform(X)\ntest_cv = scaler.transform(test_cv)\n\nX = pd.DataFrame(X_scale)\nX.shape, test_cv.shape","metadata":{"execution":{"iopub.status.busy":"2023-10-12T18:57:43.997684Z","iopub.execute_input":"2023-10-12T18:57:43.998766Z","iopub.status.idle":"2023-10-12T18:57:44.035398Z","shell.execute_reply.started":"2023-10-12T18:57:43.998604Z","shell.execute_reply":"2023-10-12T18:57:44.033950Z"},"trusted":true},"execution_count":7,"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"((13863, 25), (5942, 25))"},"metadata":{}}]},{"cell_type":"code","source":"from sklearn.tree import DecisionTreeClassifier, plot_tree\nfrom sklearn.preprocessing import MinMaxScaler, StandardScaler, LabelEncoder, FunctionTransformer\nfrom sklearn.pipeline import make_pipeline, Pipeline\nfrom sklearn.decomposition import PCA\nfrom sklearn.cluster import KMeans\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.impute import KNNImputer\nfrom sklearn.multiclass import OneVsRestClassifier\nfrom sklearn.model_selection import KFold, StratifiedKFold, train_test_split, GridSearchCV, RepeatedStratifiedKFold\nfrom sklearn.metrics import roc_auc_score, roc_curve, RocCurveDisplay, cohen_kappa_score, log_loss, f1_score\nfrom sklearn.discriminant_analysis import LinearDiscriminantAnalysis, QuadraticDiscriminantAnalysis\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.feature_selection import RFE, RFECV\nfrom sklearn.isotonic import IsotonicRegression\nfrom sklearn.calibration import CalibrationDisplay\nfrom sklearn.inspection import PartialDependenceDisplay, permutation_importance\nfrom sklearn.linear_model import LogisticRegression\nfrom collections import Counter\nfrom sklearn.ensemble import RandomForestClassifier, HistGradientBoostingClassifier, GradientBoostingClassifier, ExtraTreesClassifier\nfrom sklearn.svm import SVC\nfrom lightgbm import LGBMClassifier\nfrom xgboost import XGBClassifier\nfrom catboost import CatBoostClassifier\n\nfrom sklearn.manifold import TSNE\nimport optuna","metadata":{"execution":{"iopub.status.busy":"2023-10-12T18:57:44.037283Z","iopub.execute_input":"2023-10-12T18:57:44.038043Z","iopub.status.idle":"2023-10-12T18:57:47.672421Z","shell.execute_reply.started":"2023-10-12T18:57:44.038002Z","shell.execute_reply":"2023-10-12T18:57:47.671411Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"import json\nimport pickle\n\n# Загрузка сохраненных параметров\nwith open('/kaggle/input/lgbm-optuna-v-1-best-params-no-exta-features/LGBM_Optuna_V_1_best_params_no_exta_features.json', 'r') as f:\n    LGBM_best_params = json.load(f)\n\n# Обучение модели с загруженными параметрами\n# model_with_best_params = LGBMClassifier(**loaded_params)\n\n# Загрузка гиперпараметров из файла\nwith open(\"/kaggle/input/best-xgb-params/best_xgb_params.pkl\", \"rb\") as f:\n    loaded_best_xgb_params = pickle.load(f)\n    \nwith open(\"/kaggle/input/cb-best-parameters/best_parameters.json\", \"r\") as f:\n    CatBoost_loaded_best_params = json.load(f)\n","metadata":{"execution":{"iopub.status.busy":"2023-10-12T18:57:58.033599Z","iopub.execute_input":"2023-10-12T18:57:58.033959Z","iopub.status.idle":"2023-10-12T18:57:58.045867Z","shell.execute_reply.started":"2023-10-12T18:57:58.033934Z","shell.execute_reply":"2023-10-12T18:57:58.044812Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"%%time\nens_cv_scores, ens_preds = list(), list()\nhill_ens_cv_scores, hill_ens_preds =  list(), list()\n\nresults_df = pd.DataFrame(columns=['Fold', 'Model', 'ROC AUC', 'Optimal Threshold', 'F1 Score'])\n\nens_cv_scores = []\nens_preds = []\n\nsk = RepeatedStratifiedKFold(n_splits = 7, n_repeats = 1, random_state = 42)\nratio = float(np.sum(Y == 0)) / np.sum(Y == 1)\n\nfor i, (train_idx, test_idx) in enumerate(sk.split(X, Y)):\n\n    X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n    Y_train, Y_test = Y.iloc[train_idx], Y.iloc[test_idx]\n    \n    X_train_sub, X_val_sub, Y_train_sub, Y_val_sub = train_test_split(X_train, Y_train, test_size=0.2, random_state=42, stratify=Y_train)\n    \n    print('----------------------------------------------------------')\n\n    ##########\n    ## LGBM ##\n    ##########\n\n    LGBM_md = LGBMClassifier(**LGBM_best_params\n#                              class_weight='balanced',\n#                              n_estimators = 3500,\n#                              max_depth = 9,\n#                              learning_rate = 0.03,\n#                              num_leaves = 20,\n#                              reg_alpha = 2,\n#                              reg_lambda = 5,\n#                              subsample = 0.7,\n#                              colsample_bytree = 0.7\n                                                    ).fit(X_train_sub, Y_train_sub, \n                                                            eval_set=[(X_val_sub, Y_val_sub)], \n                                                            early_stopping_rounds=100, \n                                                            verbose=100)\n\n    lgb_pred = LGBM_md.predict_proba(X_test)[:, 1]\n    lgb_score = roc_auc_score(Y_test, lgb_pred)\n\n    print('Fold', i, '==> LGBM oof ROC-AUC score is ==>', lgb_score) \n\n    lgb_pred_test = LGBM_md.predict_proba(test_cv)[:, 1]\n\n    #########\n    ## XGB ##\n    #########\n\n    XGB_md = XGBClassifier(**loaded_best_xgb_params\n#                             objective = 'binary:logistic',\n#                            tree_method = 'hist',\n#                            colsample_bytree = 0.7, \n#                            gamma = 2, \n#                            learning_rate = 0.03, \n#                            max_depth = 10, \n#                            min_child_weight = 10, \n#                            n_estimators = 2500, \n#                            reg_lambda=5,\n#                            scale_pos_weight=ratio,\n#                            subsample = 0.7\n                                  ).fit(X_train_sub, Y_train_sub, \n                                                   eval_metric=\"auc\", \n                                                   eval_set=[(X_val_sub, Y_val_sub)], \n                                                   early_stopping_rounds=100, \n                                                   verbose=100)\n\n    xgb_pred = XGB_md.predict_proba(X_test)[:, 1]\n    xgb_score = roc_auc_score(Y_test, xgb_pred)\n\n    print('Fold', i, '==> XGB oof ROC-AUC score is ==>', xgb_score)\n\n    xgb_pred_test = XGB_md.predict_proba(test_cv)[:, 1]\n\n    ##############\n    ## CatBoost ##\n    ##############\n\n    Cat_md = CatBoostClassifier(**CatBoost_loaded_best_params\n#                                 auto_class_weights='Balanced',\n#                                 eval_metric='AUC',\n#                                 iterations = 3_000,\n#                                 learning_rate = 0.05,\n#                                 depth = 8,\n#                                 random_strength = 0.5,\n#                                 bagging_temperature = 0.7,\n#                                 border_count = 30,\n#                                 l2_leaf_reg = 7,\n#                                 verbose = False, \n#                                 task_type = 'CPU'\n                                                ).fit(X_train_sub, Y_train_sub, \n                                                           eval_set=(X_val_sub, Y_val_sub), \n                                                           early_stopping_rounds=100, \n                                                           verbose=100, \n                                                           use_best_model=True)\n\n    cat_pred = Cat_md.predict_proba(X_test)[:, 1]\n    cat_score = roc_auc_score(Y_test, cat_pred)\n\n    print('Fold', i, '==> CatBoost oof ROC-AUC score is ==>', cat_score)\n\n    cat_pred_test = Cat_md.predict_proba(test_cv)[:, 1]    \n    \n    ##############\n    ## Ensemble ##\n    ##############\n    \n    \n    \n    \n    # Ансамбль моделей\n    ens_pred_1 = ( lgb_pred + xgb_pred + cat_pred ) / 3\n    ens_pred_2 = ( lgb_pred_test + xgb_pred_test + cat_pred_test ) / 3\n    ens_score_fold = roc_auc_score(Y_test, ens_pred_1)\n    ens_cv_scores.append(ens_score_fold)\n    ens_preds.append(ens_pred_2)\n\n    print('Fold', i, '==> Average Ensemble oof ROC-AUC score is ==>', ens_score_fold)\n    \n    # Поиск оптимального порога для F1\n    thresholds = np.linspace(0, 1, 300)\n    f1_scores = [f1_score(Y_test, ens_pred_1 > thresh) for thresh in thresholds]\n    optimal_threshold = thresholds[np.argmax(f1_scores)]\n    ens_f1_score = max(f1_scores)\n    \n    results_df.loc[len(results_df)] = [i, 'LGBM', lgb_score, optimal_threshold, ens_f1_score]\n    results_df.loc[len(results_df)] = [i, 'XGB', xgb_score, optimal_threshold, ens_f1_score]\n    results_df.loc[len(results_df)] = [i, 'CatBoost', cat_score, optimal_threshold, ens_f1_score]\n    \n\nens_mean_score = np.mean(ens_cv_scores)\noptimal_threshold, ens_mean_score","metadata":{"execution":{"iopub.status.busy":"2023-10-12T18:58:42.425816Z","iopub.execute_input":"2023-10-12T18:58:42.426149Z","iopub.status.idle":"2023-10-12T19:11:29.098195Z","shell.execute_reply.started":"2023-10-12T18:58:42.426124Z","shell.execute_reply":"2023-10-12T19:11:29.096971Z"},"trusted":true},"execution_count":11,"outputs":[{"name":"stdout","text":"----------------------------------------------------------\n[LightGBM] [Warning] lambda_l1 is set=3.8476260070128565, reg_alpha=0.0 will be ignored. Current value: lambda_l1=3.8476260070128565\n[LightGBM] [Warning] bagging_fraction is set=0.4265533399132706, subsample=1.0 will be ignored. Current value: bagging_fraction=0.4265533399132706\n[LightGBM] [Warning] lambda_l2 is set=2.465060612958123, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.465060612958123\n[LightGBM] [Warning] feature_fraction is set=0.6359736909429626, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6359736909429626\n[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n/opt/conda/lib/python3.10/site-packages/lightgbm/sklearn.py:736: UserWarning: 'verbose' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n  _log_warning(\"'verbose' argument is deprecated and will be removed in a future release of LightGBM. \"\n","output_type":"stream"},{"name":"stdout","text":"[100]\tvalid_0's binary_logloss: 0.468304\n[200]\tvalid_0's binary_logloss: 0.459608\n[300]\tvalid_0's binary_logloss: 0.457919\n[400]\tvalid_0's binary_logloss: 0.457052\n[500]\tvalid_0's binary_logloss: 0.455739\nFold 0 ==> LGBM oof ROC-AUC score is ==> 0.7093959519291587\n[0]\tvalidation_0-auc:0.62506\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/xgboost/sklearn.py:835: UserWarning: `eval_metric` in `fit` method is deprecated for better compatibility with scikit-learn, use `eval_metric` in constructor or`set_params` instead.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/xgboost/sklearn.py:835: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"[100]\tvalidation_0-auc:0.71015\n[162]\tvalidation_0-auc:0.70908\nFold 0 ==> XGB oof ROC-AUC score is ==> 0.7157827324478179\n0:\tlearn: 0.6868449\ttest: 0.6869006\tbest: 0.6869006 (0)\ttotal: 115ms\tremaining: 2m 17s\n100:\tlearn: 0.4476326\ttest: 0.4857462\tbest: 0.4857462 (100)\ttotal: 4.1s\tremaining: 44.4s\n200:\tlearn: 0.3764441\ttest: 0.4636184\tbest: 0.4636184 (200)\ttotal: 8.14s\tremaining: 40.3s\n300:\tlearn: 0.3294015\ttest: 0.4567743\tbest: 0.4567455 (299)\ttotal: 12.2s\tremaining: 36.2s\n400:\tlearn: 0.2955431\ttest: 0.4537018\tbest: 0.4537018 (400)\ttotal: 16.3s\tremaining: 32.3s\n500:\tlearn: 0.2669852\ttest: 0.4521899\tbest: 0.4521793 (493)\ttotal: 20.3s\tremaining: 28.2s\n600:\tlearn: 0.2406800\ttest: 0.4511089\tbest: 0.4511089 (600)\ttotal: 24.4s\tremaining: 24.1s\n700:\tlearn: 0.2168064\ttest: 0.4503129\tbest: 0.4502209 (690)\ttotal: 28.7s\tremaining: 20.3s\n800:\tlearn: 0.1968009\ttest: 0.4501061\tbest: 0.4500347 (791)\ttotal: 32.6s\tremaining: 16.1s\nStopped by overfitting detector  (100 iterations wait)\n\nbestTest = 0.4500347037\nbestIteration = 791\n\nShrink model to first 792 iterations.\nFold 0 ==> CatBoost oof ROC-AUC score is ==> 0.7309819734345351\nFold 0 ==> Average Ensemble oof ROC-AUC score is ==> 0.7267662871600253\n----------------------------------------------------------\n[LightGBM] [Warning] lambda_l1 is set=3.8476260070128565, reg_alpha=0.0 will be ignored. Current value: lambda_l1=3.8476260070128565\n[LightGBM] [Warning] bagging_fraction is set=0.4265533399132706, subsample=1.0 will be ignored. Current value: bagging_fraction=0.4265533399132706\n[LightGBM] [Warning] lambda_l2 is set=2.465060612958123, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.465060612958123\n[LightGBM] [Warning] feature_fraction is set=0.6359736909429626, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6359736909429626\n[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n/opt/conda/lib/python3.10/site-packages/lightgbm/sklearn.py:736: UserWarning: 'verbose' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n  _log_warning(\"'verbose' argument is deprecated and will be removed in a future release of LightGBM. \"\n","output_type":"stream"},{"name":"stdout","text":"[100]\tvalid_0's binary_logloss: 0.462922\n[200]\tvalid_0's binary_logloss: 0.452201\n[300]\tvalid_0's binary_logloss: 0.447959\n[400]\tvalid_0's binary_logloss: 0.446055\n[500]\tvalid_0's binary_logloss: 0.445265\n[600]\tvalid_0's binary_logloss: 0.444289\n[700]\tvalid_0's binary_logloss: 0.443458\nFold 1 ==> LGBM oof ROC-AUC score is ==> 0.7004411764705882\n[0]\tvalidation_0-auc:0.63570\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/xgboost/sklearn.py:835: UserWarning: `eval_metric` in `fit` method is deprecated for better compatibility with scikit-learn, use `eval_metric` in constructor or`set_params` instead.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/xgboost/sklearn.py:835: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"[100]\tvalidation_0-auc:0.73597\n[200]\tvalidation_0-auc:0.73868\n[228]\tvalidation_0-auc:0.73947\nFold 1 ==> XGB oof ROC-AUC score is ==> 0.6972659709044908\n0:\tlearn: 0.6867344\ttest: 0.6869135\tbest: 0.6869135 (0)\ttotal: 42.2ms\tremaining: 50.3s\n100:\tlearn: 0.4449822\ttest: 0.4821244\tbest: 0.4821244 (100)\ttotal: 3.98s\tremaining: 43.1s\n200:\tlearn: 0.3774917\ttest: 0.4568344\tbest: 0.4568344 (200)\ttotal: 8s\tremaining: 39.6s\n300:\tlearn: 0.3350005\ttest: 0.4475254\tbest: 0.4475254 (300)\ttotal: 12s\tremaining: 35.8s\n400:\tlearn: 0.3012027\ttest: 0.4422426\tbest: 0.4422407 (399)\ttotal: 16s\tremaining: 31.8s\n500:\tlearn: 0.2705010\ttest: 0.4386552\tbest: 0.4386552 (500)\ttotal: 20.1s\tremaining: 27.9s\n600:\tlearn: 0.2459627\ttest: 0.4362807\tbest: 0.4362807 (600)\ttotal: 24.2s\tremaining: 23.9s\n700:\tlearn: 0.2231232\ttest: 0.4350780\tbest: 0.4350428 (698)\ttotal: 28.5s\tremaining: 20.1s\n800:\tlearn: 0.2032213\ttest: 0.4335847\tbest: 0.4335609 (797)\ttotal: 32.5s\tremaining: 16s\n900:\tlearn: 0.1841639\ttest: 0.4326636\tbest: 0.4326463 (895)\ttotal: 36.5s\tremaining: 11.9s\n1000:\tlearn: 0.1676060\ttest: 0.4328475\tbest: 0.4324424 (977)\ttotal: 40.6s\tremaining: 7.87s\nStopped by overfitting detector  (100 iterations wait)\n\nbestTest = 0.4324424062\nbestIteration = 977\n\nShrink model to first 978 iterations.\nFold 1 ==> CatBoost oof ROC-AUC score is ==> 0.7162444655281468\nFold 1 ==> Average Ensemble oof ROC-AUC score is ==> 0.7125838077166351\n----------------------------------------------------------\n[LightGBM] [Warning] lambda_l1 is set=3.8476260070128565, reg_alpha=0.0 will be ignored. Current value: lambda_l1=3.8476260070128565\n[LightGBM] [Warning] bagging_fraction is set=0.4265533399132706, subsample=1.0 will be ignored. Current value: bagging_fraction=0.4265533399132706\n[LightGBM] [Warning] lambda_l2 is set=2.465060612958123, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.465060612958123\n[LightGBM] [Warning] feature_fraction is set=0.6359736909429626, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6359736909429626\n[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n/opt/conda/lib/python3.10/site-packages/lightgbm/sklearn.py:736: UserWarning: 'verbose' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n  _log_warning(\"'verbose' argument is deprecated and will be removed in a future release of LightGBM. \"\n","output_type":"stream"},{"name":"stdout","text":"[100]\tvalid_0's binary_logloss: 0.467022\n[200]\tvalid_0's binary_logloss: 0.457514\n[300]\tvalid_0's binary_logloss: 0.454234\n[400]\tvalid_0's binary_logloss: 0.45372\n[500]\tvalid_0's binary_logloss: 0.452465\n[600]\tvalid_0's binary_logloss: 0.451698\n[700]\tvalid_0's binary_logloss: 0.45204\nFold 2 ==> LGBM oof ROC-AUC score is ==> 0.7056625553447186\n[0]\tvalidation_0-auc:0.61860\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/xgboost/sklearn.py:835: UserWarning: `eval_metric` in `fit` method is deprecated for better compatibility with scikit-learn, use `eval_metric` in constructor or`set_params` instead.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/xgboost/sklearn.py:835: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"[100]\tvalidation_0-auc:0.71957\n[200]\tvalidation_0-auc:0.72350\n[300]\tvalidation_0-auc:0.72839\n[400]\tvalidation_0-auc:0.72900\n[437]\tvalidation_0-auc:0.72725\nFold 2 ==> XGB oof ROC-AUC score is ==> 0.7215812776723592\n0:\tlearn: 0.6869987\ttest: 0.6870965\tbest: 0.6870965 (0)\ttotal: 21.8ms\tremaining: 26s\n100:\tlearn: 0.4485392\ttest: 0.4825554\tbest: 0.4825554 (100)\ttotal: 3.91s\tremaining: 42.3s\n200:\tlearn: 0.3789922\ttest: 0.4593068\tbest: 0.4593068 (200)\ttotal: 7.95s\tremaining: 39.3s\n300:\tlearn: 0.3311194\ttest: 0.4517767\tbest: 0.4517767 (300)\ttotal: 12.3s\tremaining: 36.6s\n400:\tlearn: 0.2944890\ttest: 0.4476399\tbest: 0.4476399 (400)\ttotal: 16.4s\tremaining: 32.4s\n500:\tlearn: 0.2677140\ttest: 0.4449501\tbest: 0.4449501 (500)\ttotal: 20.4s\tremaining: 28.3s\n600:\tlearn: 0.2419516\ttest: 0.4434749\tbest: 0.4434749 (600)\ttotal: 24.5s\tremaining: 24.2s\n700:\tlearn: 0.2192758\ttest: 0.4422281\tbest: 0.4422281 (700)\ttotal: 28.5s\tremaining: 20.1s\n800:\tlearn: 0.1974320\ttest: 0.4414699\tbest: 0.4414699 (800)\ttotal: 32.5s\tremaining: 16s\n900:\tlearn: 0.1770364\ttest: 0.4417855\tbest: 0.4412954 (808)\ttotal: 36.5s\tremaining: 11.9s\nStopped by overfitting detector  (100 iterations wait)\n\nbestTest = 0.4412954133\nbestIteration = 808\n\nShrink model to first 809 iterations.\nFold 2 ==> CatBoost oof ROC-AUC score is ==> 0.7217947501581279\nFold 2 ==> Average Ensemble oof ROC-AUC score is ==> 0.7221979759645794\n----------------------------------------------------------\n[LightGBM] [Warning] lambda_l1 is set=3.8476260070128565, reg_alpha=0.0 will be ignored. Current value: lambda_l1=3.8476260070128565\n[LightGBM] [Warning] bagging_fraction is set=0.4265533399132706, subsample=1.0 will be ignored. Current value: bagging_fraction=0.4265533399132706\n[LightGBM] [Warning] lambda_l2 is set=2.465060612958123, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.465060612958123\n[LightGBM] [Warning] feature_fraction is set=0.6359736909429626, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6359736909429626\n[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n/opt/conda/lib/python3.10/site-packages/lightgbm/sklearn.py:736: UserWarning: 'verbose' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n  _log_warning(\"'verbose' argument is deprecated and will be removed in a future release of LightGBM. \"\n","output_type":"stream"},{"name":"stdout","text":"[100]\tvalid_0's binary_logloss: 0.461885\n[200]\tvalid_0's binary_logloss: 0.452664\n[300]\tvalid_0's binary_logloss: 0.449148\n[400]\tvalid_0's binary_logloss: 0.448947\nFold 3 ==> LGBM oof ROC-AUC score is ==> 0.7148180379746836\n[0]\tvalidation_0-auc:0.62096\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/xgboost/sklearn.py:835: UserWarning: `eval_metric` in `fit` method is deprecated for better compatibility with scikit-learn, use `eval_metric` in constructor or`set_params` instead.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/xgboost/sklearn.py:835: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"[100]\tvalidation_0-auc:0.70229\n[200]\tvalidation_0-auc:0.71295\n[300]\tvalidation_0-auc:0.71465\n[400]\tvalidation_0-auc:0.71537\n[500]\tvalidation_0-auc:0.71529\n[533]\tvalidation_0-auc:0.71468\nFold 3 ==> XGB oof ROC-AUC score is ==> 0.7251803797468355\n0:\tlearn: 0.6868294\ttest: 0.6869985\tbest: 0.6869985 (0)\ttotal: 38.8ms\tremaining: 46.3s\n100:\tlearn: 0.4475486\ttest: 0.4828829\tbest: 0.4828829 (100)\ttotal: 3.97s\tremaining: 43s\n200:\tlearn: 0.3814047\ttest: 0.4590317\tbest: 0.4590317 (200)\ttotal: 8.01s\tremaining: 39.6s\n300:\tlearn: 0.3335468\ttest: 0.4521232\tbest: 0.4521232 (300)\ttotal: 12.1s\tremaining: 35.9s\n400:\tlearn: 0.2985942\ttest: 0.4481280\tbest: 0.4481280 (400)\ttotal: 16.2s\tremaining: 32s\n500:\tlearn: 0.2716286\ttest: 0.4452090\tbest: 0.4452090 (500)\ttotal: 20.2s\tremaining: 28s\n600:\tlearn: 0.2454775\ttest: 0.4431939\tbest: 0.4431680 (599)\ttotal: 24.2s\tremaining: 23.9s\n700:\tlearn: 0.2234122\ttest: 0.4423268\tbest: 0.4422198 (684)\ttotal: 28.6s\tremaining: 20.2s\n800:\tlearn: 0.2023360\ttest: 0.4417446\tbest: 0.4416576 (797)\ttotal: 32.6s\tremaining: 16.1s\n900:\tlearn: 0.1849414\ttest: 0.4412952\tbest: 0.4412576 (872)\ttotal: 36.7s\tremaining: 12s\n1000:\tlearn: 0.1690797\ttest: 0.4415874\tbest: 0.4412037 (943)\ttotal: 40.8s\tremaining: 7.91s\nStopped by overfitting detector  (100 iterations wait)\n\nbestTest = 0.4412037396\nbestIteration = 943\n\nShrink model to first 944 iterations.\nFold 3 ==> CatBoost oof ROC-AUC score is ==> 0.7312753164556962\nFold 3 ==> Average Ensemble oof ROC-AUC score is ==> 0.730498417721519\n----------------------------------------------------------\n[LightGBM] [Warning] lambda_l1 is set=3.8476260070128565, reg_alpha=0.0 will be ignored. Current value: lambda_l1=3.8476260070128565\n[LightGBM] [Warning] bagging_fraction is set=0.4265533399132706, subsample=1.0 will be ignored. Current value: bagging_fraction=0.4265533399132706\n[LightGBM] [Warning] lambda_l2 is set=2.465060612958123, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.465060612958123\n[LightGBM] [Warning] feature_fraction is set=0.6359736909429626, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6359736909429626\n[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n/opt/conda/lib/python3.10/site-packages/lightgbm/sklearn.py:736: UserWarning: 'verbose' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n  _log_warning(\"'verbose' argument is deprecated and will be removed in a future release of LightGBM. \"\n","output_type":"stream"},{"name":"stdout","text":"[100]\tvalid_0's binary_logloss: 0.468085\n[200]\tvalid_0's binary_logloss: 0.461064\n[300]\tvalid_0's binary_logloss: 0.458915\n[400]\tvalid_0's binary_logloss: 0.459518\nFold 4 ==> LGBM oof ROC-AUC score is ==> 0.7155300632911392\n[0]\tvalidation_0-auc:0.60913\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/xgboost/sklearn.py:835: UserWarning: `eval_metric` in `fit` method is deprecated for better compatibility with scikit-learn, use `eval_metric` in constructor or`set_params` instead.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/xgboost/sklearn.py:835: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"[100]\tvalidation_0-auc:0.72816\n[200]\tvalidation_0-auc:0.72488\n[225]\tvalidation_0-auc:0.72406\nFold 4 ==> XGB oof ROC-AUC score is ==> 0.7000585443037974\n0:\tlearn: 0.6870816\ttest: 0.6871871\tbest: 0.6871871 (0)\ttotal: 41.5ms\tremaining: 49.6s\n100:\tlearn: 0.4518359\ttest: 0.4863430\tbest: 0.4863430 (100)\ttotal: 3.91s\tremaining: 42.4s\n200:\tlearn: 0.3780845\ttest: 0.4632672\tbest: 0.4632672 (200)\ttotal: 7.96s\tremaining: 39.3s\n300:\tlearn: 0.3302640\ttest: 0.4566884\tbest: 0.4566884 (300)\ttotal: 12s\tremaining: 35.6s\n400:\tlearn: 0.2924516\ttest: 0.4533045\tbest: 0.4532947 (397)\ttotal: 16s\tremaining: 31.6s\n500:\tlearn: 0.2607812\ttest: 0.4510175\tbest: 0.4510118 (499)\ttotal: 20s\tremaining: 27.7s\n600:\tlearn: 0.2349001\ttest: 0.4493334\tbest: 0.4492123 (595)\ttotal: 24s\tremaining: 23.7s\n700:\tlearn: 0.2109964\ttest: 0.4487695\tbest: 0.4486210 (694)\ttotal: 28.3s\tremaining: 19.9s\n800:\tlearn: 0.1881472\ttest: 0.4487002\tbest: 0.4485139 (786)\ttotal: 32.3s\tremaining: 15.9s\nStopped by overfitting detector  (100 iterations wait)\n\nbestTest = 0.4485138861\nbestIteration = 786\n\nShrink model to first 787 iterations.\nFold 4 ==> CatBoost oof ROC-AUC score is ==> 0.7253512658227848\nFold 4 ==> Average Ensemble oof ROC-AUC score is ==> 0.721511075949367\n----------------------------------------------------------\n[LightGBM] [Warning] lambda_l1 is set=3.8476260070128565, reg_alpha=0.0 will be ignored. Current value: lambda_l1=3.8476260070128565\n[LightGBM] [Warning] bagging_fraction is set=0.4265533399132706, subsample=1.0 will be ignored. Current value: bagging_fraction=0.4265533399132706\n[LightGBM] [Warning] lambda_l2 is set=2.465060612958123, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.465060612958123\n[LightGBM] [Warning] feature_fraction is set=0.6359736909429626, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6359736909429626\n[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n/opt/conda/lib/python3.10/site-packages/lightgbm/sklearn.py:736: UserWarning: 'verbose' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n  _log_warning(\"'verbose' argument is deprecated and will be removed in a future release of LightGBM. \"\n","output_type":"stream"},{"name":"stdout","text":"[100]\tvalid_0's binary_logloss: 0.470588\n[200]\tvalid_0's binary_logloss: 0.463815\n[300]\tvalid_0's binary_logloss: 0.461693\n[400]\tvalid_0's binary_logloss: 0.461197\n[500]\tvalid_0's binary_logloss: 0.461131\nFold 5 ==> LGBM oof ROC-AUC score is ==> 0.7356107594936708\n[0]\tvalidation_0-auc:0.59945\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/xgboost/sklearn.py:835: UserWarning: `eval_metric` in `fit` method is deprecated for better compatibility with scikit-learn, use `eval_metric` in constructor or`set_params` instead.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/xgboost/sklearn.py:835: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"[100]\tvalidation_0-auc:0.69805\n[200]\tvalidation_0-auc:0.70013\n[300]\tvalidation_0-auc:0.70128\n[400]\tvalidation_0-auc:0.70159\n[434]\tvalidation_0-auc:0.70144\nFold 5 ==> XGB oof ROC-AUC score is ==> 0.7266360759493671\n0:\tlearn: 0.6867374\ttest: 0.6869424\tbest: 0.6869424 (0)\ttotal: 40.5ms\tremaining: 48.3s\n100:\tlearn: 0.4473322\ttest: 0.4894586\tbest: 0.4894586 (100)\ttotal: 3.95s\tremaining: 42.8s\n200:\tlearn: 0.3790086\ttest: 0.4684789\tbest: 0.4684789 (200)\ttotal: 7.97s\tremaining: 39.4s\n300:\tlearn: 0.3309766\ttest: 0.4617597\tbest: 0.4617597 (300)\ttotal: 12s\tremaining: 35.6s\n400:\tlearn: 0.2966779\ttest: 0.4581618\tbest: 0.4581618 (400)\ttotal: 16s\tremaining: 31.7s\n500:\tlearn: 0.2673025\ttest: 0.4561764\tbest: 0.4561764 (500)\ttotal: 20s\tremaining: 27.8s\n600:\tlearn: 0.2406205\ttest: 0.4551096\tbest: 0.4550755 (590)\ttotal: 24.3s\tremaining: 24s\n700:\tlearn: 0.2161709\ttest: 0.4540551\tbest: 0.4540551 (700)\ttotal: 28.4s\tremaining: 20s\n800:\tlearn: 0.1950627\ttest: 0.4536990\tbest: 0.4536496 (798)\ttotal: 32.4s\tremaining: 15.9s\n900:\tlearn: 0.1767852\ttest: 0.4535814\tbest: 0.4533763 (871)\ttotal: 36.5s\tremaining: 11.9s\nStopped by overfitting detector  (100 iterations wait)\n\nbestTest = 0.4533762642\nbestIteration = 871\n\nShrink model to first 872 iterations.\nFold 5 ==> CatBoost oof ROC-AUC score is ==> 0.7527294303797468\nFold 5 ==> Average Ensemble oof ROC-AUC score is ==> 0.7476629746835444\n----------------------------------------------------------\n[LightGBM] [Warning] lambda_l1 is set=3.8476260070128565, reg_alpha=0.0 will be ignored. Current value: lambda_l1=3.8476260070128565\n[LightGBM] [Warning] bagging_fraction is set=0.4265533399132706, subsample=1.0 will be ignored. Current value: bagging_fraction=0.4265533399132706\n[LightGBM] [Warning] lambda_l2 is set=2.465060612958123, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.465060612958123\n[LightGBM] [Warning] feature_fraction is set=0.6359736909429626, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6359736909429626\n[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n/opt/conda/lib/python3.10/site-packages/lightgbm/sklearn.py:736: UserWarning: 'verbose' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n  _log_warning(\"'verbose' argument is deprecated and will be removed in a future release of LightGBM. \"\n","output_type":"stream"},{"name":"stdout","text":"[100]\tvalid_0's binary_logloss: 0.469825\n[200]\tvalid_0's binary_logloss: 0.462244\n[300]\tvalid_0's binary_logloss: 0.459729\n[400]\tvalid_0's binary_logloss: 0.460093\nFold 6 ==> LGBM oof ROC-AUC score is ==> 0.7350316455696202\n[0]\tvalidation_0-auc:0.58728\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/xgboost/sklearn.py:835: UserWarning: `eval_metric` in `fit` method is deprecated for better compatibility with scikit-learn, use `eval_metric` in constructor or`set_params` instead.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/xgboost/sklearn.py:835: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"[100]\tvalidation_0-auc:0.70858\n[200]\tvalidation_0-auc:0.70956\n[204]\tvalidation_0-auc:0.70899\nFold 6 ==> XGB oof ROC-AUC score is ==> 0.7255712025316456\n0:\tlearn: 0.6869543\ttest: 0.6871118\tbest: 0.6871118 (0)\ttotal: 39.4ms\tremaining: 47.1s\n100:\tlearn: 0.4508187\ttest: 0.4883369\tbest: 0.4883369 (100)\ttotal: 4.35s\tremaining: 47.1s\n200:\tlearn: 0.3789511\ttest: 0.4663792\tbest: 0.4663792 (200)\ttotal: 8.38s\tremaining: 41.4s\n300:\tlearn: 0.3304091\ttest: 0.4592494\tbest: 0.4592494 (300)\ttotal: 12.5s\tremaining: 37.1s\n400:\tlearn: 0.2942722\ttest: 0.4547976\tbest: 0.4547976 (400)\ttotal: 16.5s\tremaining: 32.7s\n500:\tlearn: 0.2647090\ttest: 0.4524843\tbest: 0.4524357 (496)\ttotal: 20.6s\tremaining: 28.5s\n600:\tlearn: 0.2388793\ttest: 0.4507755\tbest: 0.4507755 (600)\ttotal: 24.7s\tremaining: 24.4s\n700:\tlearn: 0.2169251\ttest: 0.4496923\tbest: 0.4495754 (696)\ttotal: 28.7s\tremaining: 20.2s\n800:\tlearn: 0.1954816\ttest: 0.4493669\tbest: 0.4493577 (798)\ttotal: 33s\tremaining: 16.2s\n900:\tlearn: 0.1771844\ttest: 0.4500496\tbest: 0.4493148 (815)\ttotal: 37.2s\tremaining: 12.1s\nStopped by overfitting detector  (100 iterations wait)\n\nbestTest = 0.4493148253\nbestIteration = 815\n\nShrink model to first 816 iterations.\nFold 6 ==> CatBoost oof ROC-AUC score is ==> 0.7418449367088608\nFold 6 ==> Average Ensemble oof ROC-AUC score is ==> 0.7404873417721518\nCPU times: user 23min 52s, sys: 1min 36s, total: 25min 29s\nWall time: 12min 46s\n","output_type":"stream"},{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"(0.1906354515050167, 0.7288154115668318)"},"metadata":{}}]},{"cell_type":"code","source":"results_df","metadata":{"execution":{"iopub.status.busy":"2023-10-12T15:30:13.038186Z","iopub.execute_input":"2023-10-12T15:30:13.038535Z","iopub.status.idle":"2023-10-12T15:30:13.051896Z","shell.execute_reply.started":"2023-10-12T15:30:13.038506Z","shell.execute_reply":"2023-10-12T15:30:13.051015Z"},"trusted":true},"execution_count":18,"outputs":[{"execution_count":18,"output_type":"execute_result","data":{"text/plain":"    Fold     Model   ROC AUC  Optimal Threshold  F1 Score\n0      0      LGBM  0.703652           0.294314  0.434515\n1      0       XGB  0.698606           0.294314  0.434515\n2      0  CatBoost  0.702623           0.294314  0.434515\n3      1      LGBM  0.676868           0.284281  0.411834\n4      1       XGB  0.673497           0.284281  0.411834\n5      1  CatBoost  0.681975           0.284281  0.411834\n6      2      LGBM  0.716152           0.267559  0.454194\n7      2       XGB  0.700759           0.267559  0.454194\n8      2  CatBoost  0.715045           0.267559  0.454194\n9      3      LGBM  0.717722           0.244147  0.465753\n10     3       XGB  0.710236           0.244147  0.465753\n11     3  CatBoost  0.722310           0.244147  0.465753\n12     4      LGBM  0.695088           0.237458  0.441441\n13     4       XGB  0.694691           0.237458  0.441441\n14     4  CatBoost  0.689806           0.237458  0.441441\n15     5      LGBM  0.695757           0.304348  0.434916\n16     5       XGB  0.696548           0.304348  0.434916\n17     5  CatBoost  0.672824           0.304348  0.434916\n18     6      LGBM  0.729472           0.254181  0.474534\n19     6       XGB  0.718555           0.254181  0.474534\n20     6  CatBoost  0.732417           0.254181  0.474534","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Fold</th>\n      <th>Model</th>\n      <th>ROC AUC</th>\n      <th>Optimal Threshold</th>\n      <th>F1 Score</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>LGBM</td>\n      <td>0.703652</td>\n      <td>0.294314</td>\n      <td>0.434515</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0</td>\n      <td>XGB</td>\n      <td>0.698606</td>\n      <td>0.294314</td>\n      <td>0.434515</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0</td>\n      <td>CatBoost</td>\n      <td>0.702623</td>\n      <td>0.294314</td>\n      <td>0.434515</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1</td>\n      <td>LGBM</td>\n      <td>0.676868</td>\n      <td>0.284281</td>\n      <td>0.411834</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1</td>\n      <td>XGB</td>\n      <td>0.673497</td>\n      <td>0.284281</td>\n      <td>0.411834</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>1</td>\n      <td>CatBoost</td>\n      <td>0.681975</td>\n      <td>0.284281</td>\n      <td>0.411834</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>2</td>\n      <td>LGBM</td>\n      <td>0.716152</td>\n      <td>0.267559</td>\n      <td>0.454194</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>2</td>\n      <td>XGB</td>\n      <td>0.700759</td>\n      <td>0.267559</td>\n      <td>0.454194</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>2</td>\n      <td>CatBoost</td>\n      <td>0.715045</td>\n      <td>0.267559</td>\n      <td>0.454194</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>3</td>\n      <td>LGBM</td>\n      <td>0.717722</td>\n      <td>0.244147</td>\n      <td>0.465753</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>3</td>\n      <td>XGB</td>\n      <td>0.710236</td>\n      <td>0.244147</td>\n      <td>0.465753</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>3</td>\n      <td>CatBoost</td>\n      <td>0.722310</td>\n      <td>0.244147</td>\n      <td>0.465753</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>4</td>\n      <td>LGBM</td>\n      <td>0.695088</td>\n      <td>0.237458</td>\n      <td>0.441441</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>4</td>\n      <td>XGB</td>\n      <td>0.694691</td>\n      <td>0.237458</td>\n      <td>0.441441</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>4</td>\n      <td>CatBoost</td>\n      <td>0.689806</td>\n      <td>0.237458</td>\n      <td>0.441441</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>5</td>\n      <td>LGBM</td>\n      <td>0.695757</td>\n      <td>0.304348</td>\n      <td>0.434916</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>5</td>\n      <td>XGB</td>\n      <td>0.696548</td>\n      <td>0.304348</td>\n      <td>0.434916</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>5</td>\n      <td>CatBoost</td>\n      <td>0.672824</td>\n      <td>0.304348</td>\n      <td>0.434916</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>6</td>\n      <td>LGBM</td>\n      <td>0.729472</td>\n      <td>0.254181</td>\n      <td>0.474534</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>6</td>\n      <td>XGB</td>\n      <td>0.718555</td>\n      <td>0.254181</td>\n      <td>0.474534</td>\n    </tr>\n    <tr>\n      <th>20</th>\n      <td>6</td>\n      <td>CatBoost</td>\n      <td>0.732417</td>\n      <td>0.254181</td>\n      <td>0.474534</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"results_df # this is new","metadata":{"execution":{"iopub.status.busy":"2023-10-12T19:11:29.099984Z","iopub.execute_input":"2023-10-12T19:11:29.100284Z","iopub.status.idle":"2023-10-12T19:11:29.117838Z","shell.execute_reply.started":"2023-10-12T19:11:29.100260Z","shell.execute_reply":"2023-10-12T19:11:29.116707Z"},"trusted":true},"execution_count":12,"outputs":[{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"    Fold     Model   ROC AUC  Optimal Threshold  F1 Score\n0      0      LGBM  0.709396           0.187291  0.452962\n1      0       XGB  0.715783           0.187291  0.452962\n2      0  CatBoost  0.730982           0.187291  0.452962\n3      1      LGBM  0.700441           0.173913  0.440183\n4      1       XGB  0.697266           0.173913  0.440183\n5      1  CatBoost  0.716244           0.173913  0.440183\n6      2      LGBM  0.705663           0.160535  0.446673\n7      2       XGB  0.721581           0.160535  0.446673\n8      2  CatBoost  0.721795           0.160535  0.446673\n9      3      LGBM  0.714818           0.173913  0.456863\n10     3       XGB  0.725180           0.173913  0.456863\n11     3  CatBoost  0.731275           0.173913  0.456863\n12     4      LGBM  0.715530           0.193980  0.448544\n13     4       XGB  0.700059           0.193980  0.448544\n14     4  CatBoost  0.725351           0.193980  0.448544\n15     5      LGBM  0.735611           0.183946  0.504219\n16     5       XGB  0.726636           0.183946  0.504219\n17     5  CatBoost  0.752729           0.183946  0.504219\n18     6      LGBM  0.735032           0.190635  0.464183\n19     6       XGB  0.725571           0.190635  0.464183\n20     6  CatBoost  0.741845           0.190635  0.464183","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Fold</th>\n      <th>Model</th>\n      <th>ROC AUC</th>\n      <th>Optimal Threshold</th>\n      <th>F1 Score</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>LGBM</td>\n      <td>0.709396</td>\n      <td>0.187291</td>\n      <td>0.452962</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0</td>\n      <td>XGB</td>\n      <td>0.715783</td>\n      <td>0.187291</td>\n      <td>0.452962</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0</td>\n      <td>CatBoost</td>\n      <td>0.730982</td>\n      <td>0.187291</td>\n      <td>0.452962</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1</td>\n      <td>LGBM</td>\n      <td>0.700441</td>\n      <td>0.173913</td>\n      <td>0.440183</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1</td>\n      <td>XGB</td>\n      <td>0.697266</td>\n      <td>0.173913</td>\n      <td>0.440183</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>1</td>\n      <td>CatBoost</td>\n      <td>0.716244</td>\n      <td>0.173913</td>\n      <td>0.440183</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>2</td>\n      <td>LGBM</td>\n      <td>0.705663</td>\n      <td>0.160535</td>\n      <td>0.446673</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>2</td>\n      <td>XGB</td>\n      <td>0.721581</td>\n      <td>0.160535</td>\n      <td>0.446673</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>2</td>\n      <td>CatBoost</td>\n      <td>0.721795</td>\n      <td>0.160535</td>\n      <td>0.446673</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>3</td>\n      <td>LGBM</td>\n      <td>0.714818</td>\n      <td>0.173913</td>\n      <td>0.456863</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>3</td>\n      <td>XGB</td>\n      <td>0.725180</td>\n      <td>0.173913</td>\n      <td>0.456863</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>3</td>\n      <td>CatBoost</td>\n      <td>0.731275</td>\n      <td>0.173913</td>\n      <td>0.456863</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>4</td>\n      <td>LGBM</td>\n      <td>0.715530</td>\n      <td>0.193980</td>\n      <td>0.448544</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>4</td>\n      <td>XGB</td>\n      <td>0.700059</td>\n      <td>0.193980</td>\n      <td>0.448544</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>4</td>\n      <td>CatBoost</td>\n      <td>0.725351</td>\n      <td>0.193980</td>\n      <td>0.448544</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>5</td>\n      <td>LGBM</td>\n      <td>0.735611</td>\n      <td>0.183946</td>\n      <td>0.504219</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>5</td>\n      <td>XGB</td>\n      <td>0.726636</td>\n      <td>0.183946</td>\n      <td>0.504219</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>5</td>\n      <td>CatBoost</td>\n      <td>0.752729</td>\n      <td>0.183946</td>\n      <td>0.504219</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>6</td>\n      <td>LGBM</td>\n      <td>0.735032</td>\n      <td>0.190635</td>\n      <td>0.464183</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>6</td>\n      <td>XGB</td>\n      <td>0.725571</td>\n      <td>0.190635</td>\n      <td>0.464183</td>\n    </tr>\n    <tr>\n      <th>20</th>\n      <td>6</td>\n      <td>CatBoost</td>\n      <td>0.741845</td>\n      <td>0.190635</td>\n      <td>0.464183</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"avg_ens_preds = np.mean(ens_preds, axis=0)\nfinal_predictions = (avg_ens_preds > optimal_threshold).astype(int)\nfinal_predictions.sum()","metadata":{"execution":{"iopub.status.busy":"2023-10-12T19:12:32.051930Z","iopub.execute_input":"2023-10-12T19:12:32.052394Z","iopub.status.idle":"2023-10-12T19:12:32.063107Z","shell.execute_reply.started":"2023-10-12T19:12:32.052362Z","shell.execute_reply":"2023-10-12T19:12:32.061785Z"},"trusted":true},"execution_count":13,"outputs":[{"execution_count":13,"output_type":"execute_result","data":{"text/plain":"1810"},"metadata":{}}]},{"cell_type":"code","source":"final_predictions.shape","metadata":{"execution":{"iopub.status.busy":"2023-10-12T19:12:32.758162Z","iopub.execute_input":"2023-10-12T19:12:32.758617Z","iopub.status.idle":"2023-10-12T19:12:32.766740Z","shell.execute_reply.started":"2023-10-12T19:12:32.758586Z","shell.execute_reply":"2023-10-12T19:12:32.765279Z"},"trusted":true},"execution_count":14,"outputs":[{"execution_count":14,"output_type":"execute_result","data":{"text/plain":"(5942,)"},"metadata":{}}]},{"cell_type":"code","source":"from sklearn.metrics import confusion_matrix\n\n# Теперь вы можете сравнить прогнозы с реальными значениями\ncm = confusion_matrix(Y_test_sim, final_predictions)\n\ncm","metadata":{"execution":{"iopub.status.busy":"2023-10-12T16:52:36.213931Z","iopub.execute_input":"2023-10-12T16:52:36.214289Z","iopub.status.idle":"2023-10-12T16:52:36.272467Z","shell.execute_reply.started":"2023-10-12T16:52:36.214259Z","shell.execute_reply":"2023-10-12T16:52:36.270969Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":80,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","Cell \u001b[0;32mIn[80], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m confusion_matrix\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Теперь вы можете сравнить прогнозы с реальными значениями\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m cm \u001b[38;5;241m=\u001b[39m \u001b[43mconfusion_matrix\u001b[49m\u001b[43m(\u001b[49m\u001b[43mY_test_sim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfinal_predictions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m cm\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:317\u001b[0m, in \u001b[0;36mconfusion_matrix\u001b[0;34m(y_true, y_pred, labels, sample_weight, normalize)\u001b[0m\n\u001b[1;32m    232\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mconfusion_matrix\u001b[39m(\n\u001b[1;32m    233\u001b[0m     y_true, y_pred, \u001b[38;5;241m*\u001b[39m, labels\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, sample_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, normalize\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    234\u001b[0m ):\n\u001b[1;32m    235\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Compute confusion matrix to evaluate the accuracy of a classification.\u001b[39;00m\n\u001b[1;32m    236\u001b[0m \n\u001b[1;32m    237\u001b[0m \u001b[38;5;124;03m    By definition a confusion matrix :math:`C` is such that :math:`C_{i, j}`\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    315\u001b[0m \u001b[38;5;124;03m    (0, 2, 1, 1)\u001b[39;00m\n\u001b[1;32m    316\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 317\u001b[0m     y_type, y_true, y_pred \u001b[38;5;241m=\u001b[39m \u001b[43m_check_targets\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    318\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m y_type \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbinary\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmulticlass\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    319\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m is not supported\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m y_type)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:86\u001b[0m, in \u001b[0;36m_check_targets\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_check_targets\u001b[39m(y_true, y_pred):\n\u001b[1;32m     60\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Check that y_true and y_pred belong to the same classification task.\u001b[39;00m\n\u001b[1;32m     61\u001b[0m \n\u001b[1;32m     62\u001b[0m \u001b[38;5;124;03m    This converts multiclass or binary types to a common shape, and raises a\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[38;5;124;03m    y_pred : array or indicator matrix\u001b[39;00m\n\u001b[1;32m     85\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 86\u001b[0m     \u001b[43mcheck_consistent_length\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     87\u001b[0m     type_true \u001b[38;5;241m=\u001b[39m type_of_target(y_true, input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my_true\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     88\u001b[0m     type_pred \u001b[38;5;241m=\u001b[39m type_of_target(y_pred, input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my_pred\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:397\u001b[0m, in \u001b[0;36mcheck_consistent_length\u001b[0;34m(*arrays)\u001b[0m\n\u001b[1;32m    395\u001b[0m uniques \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39munique(lengths)\n\u001b[1;32m    396\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(uniques) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m--> 397\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    398\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound input variables with inconsistent numbers of samples: \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    399\u001b[0m         \u001b[38;5;241m%\u001b[39m [\u001b[38;5;28mint\u001b[39m(l) \u001b[38;5;28;01mfor\u001b[39;00m l \u001b[38;5;129;01min\u001b[39;00m lengths]\n\u001b[1;32m    400\u001b[0m     )\n","\u001b[0;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [4159, 5942]"],"ename":"ValueError","evalue":"Found input variables with inconsistent numbers of samples: [4159, 5942]","output_type":"error"}]},{"cell_type":"code","source":"# 1. Прогнозирование с помощью каждой отдельной модели на новых данных\nlgb_new_pred = LGBM_md.predict_proba(X)[:, 1]\nxgb_new_pred = XGB_md.predict_proba(X)[:, 1]\ncat_new_pred = Cat_md.predict_proba(X)[:, 1]\n\n# 2. Усреднение прогнозов от разных моделей\nens_new_pred = (lgb_new_pred + xgb_new_pred + cat_new_pred) / 3\n\n# Если вам нужны бинарные прогнозы (0 или 1), вы можете применить порог, который был найден ранее\nens_new_binary_pred = (ens_new_pred > optimal_threshold).astype(int)\nens_new_binary_pred.shape","metadata":{"execution":{"iopub.status.busy":"2023-10-12T16:15:48.747436Z","iopub.execute_input":"2023-10-12T16:15:48.747796Z","iopub.status.idle":"2023-10-12T16:15:49.118506Z","shell.execute_reply.started":"2023-10-12T16:15:48.747769Z","shell.execute_reply":"2023-10-12T16:15:49.117502Z"},"trusted":true},"execution_count":73,"outputs":[{"execution_count":73,"output_type":"execute_result","data":{"text/plain":"(13863,)"},"metadata":{}}]},{"cell_type":"code","source":"tester_df = pd.DataFrame()\ntester_df['smoking'] = Y\ntester_df['smoking_pred'] = ens_new_binary_pred","metadata":{"execution":{"iopub.status.busy":"2023-10-12T19:12:37.252681Z","iopub.execute_input":"2023-10-12T19:12:37.253039Z","iopub.status.idle":"2023-10-12T19:12:37.285249Z","shell.execute_reply.started":"2023-10-12T19:12:37.253012Z","shell.execute_reply":"2023-10-12T19:12:37.283811Z"},"trusted":true},"execution_count":15,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[0;32mIn[15], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m tester_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame()\n\u001b[1;32m      2\u001b[0m tester_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msmoking\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m Y\n\u001b[0;32m----> 3\u001b[0m tester_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msmoking_pred\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mens_new_binary_pred\u001b[49m\n","\u001b[0;31mNameError\u001b[0m: name 'ens_new_binary_pred' is not defined"],"ename":"NameError","evalue":"name 'ens_new_binary_pred' is not defined","output_type":"error"}]},{"cell_type":"code","source":"tester_df_cm = confusion_matrix(tester_df['smoking'], tester_df['smoking_pred'])\ntester_df_cm","metadata":{"execution":{"iopub.status.busy":"2023-10-12T19:12:37.618590Z","iopub.execute_input":"2023-10-12T19:12:37.619657Z","iopub.status.idle":"2023-10-12T19:12:38.564764Z","shell.execute_reply.started":"2023-10-12T19:12:37.619622Z","shell.execute_reply":"2023-10-12T19:12:38.563201Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":16,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/core/indexes/base.py:3653\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3652\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3653\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3654\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/_libs/index.pyx:147\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/_libs/index.pyx:176\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n","File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7080\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n","File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7088\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n","\u001b[0;31mKeyError\u001b[0m: 'smoking_pred'","\nThe above exception was the direct cause of the following exception:\n","\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)","Cell \u001b[0;32mIn[16], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m tester_df_cm \u001b[38;5;241m=\u001b[39m confusion_matrix(tester_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msmoking\u001b[39m\u001b[38;5;124m'\u001b[39m], \u001b[43mtester_df\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43msmoking_pred\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m)\n\u001b[1;32m      2\u001b[0m tester_df_cm\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/core/frame.py:3761\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   3760\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[0;32m-> 3761\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3762\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[1;32m   3763\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/core/indexes/base.py:3655\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3653\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mget_loc(casted_key)\n\u001b[1;32m   3654\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m-> 3655\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m   3656\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m   3657\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3658\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3659\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3660\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n","\u001b[0;31mKeyError\u001b[0m: 'smoking_pred'"],"ename":"KeyError","evalue":"'smoking_pred'","output_type":"error"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission = pd.read_csv(r'/kaggle/input/leopard-challenge-classification/sample_submission.csv')","metadata":{"execution":{"iopub.status.busy":"2023-10-12T19:12:44.676535Z","iopub.execute_input":"2023-10-12T19:12:44.676993Z","iopub.status.idle":"2023-10-12T19:12:44.693352Z","shell.execute_reply.started":"2023-10-12T19:12:44.676960Z","shell.execute_reply":"2023-10-12T19:12:44.691975Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"submission['smoking'] = final_predictions\nsubmission.to_csv('Ensemble_submission_08.csv', index = False)","metadata":{"execution":{"iopub.status.busy":"2023-10-12T19:12:50.419322Z","iopub.execute_input":"2023-10-12T19:12:50.419756Z","iopub.status.idle":"2023-10-12T19:12:50.434749Z","shell.execute_reply.started":"2023-10-12T19:12:50.419722Z","shell.execute_reply":"2023-10-12T19:12:50.433656Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"submission['smoking'].sum()","metadata":{"execution":{"iopub.status.busy":"2023-10-12T19:12:46.208009Z","iopub.execute_input":"2023-10-12T19:12:46.208479Z","iopub.status.idle":"2023-10-12T19:12:46.220261Z","shell.execute_reply.started":"2023-10-12T19:12:46.208419Z","shell.execute_reply":"2023-10-12T19:12:46.219011Z"},"trusted":true},"execution_count":19,"outputs":[{"execution_count":19,"output_type":"execute_result","data":{"text/plain":"1810"},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}